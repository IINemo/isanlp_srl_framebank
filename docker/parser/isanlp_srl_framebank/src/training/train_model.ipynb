{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use only one GPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../isanlp/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress tensorflow memory appetites\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "# Check GPUs availability\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(31)\n",
    "\n",
    "import os\n",
    "import time\n",
    "import isanlp\n",
    "import json\n",
    "import pickle\n",
    "import vectorization\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/models_new/known_preds/tensors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['arg_lemma', 'pred_lemma', 'dist', 'arg_case', 'pred_pos', 'arg_pos', 'syn_link_name', 'prepos', 'Aspect_arg', 'Number_arg', 'Tense_arg', 'Valency_arg', 'VerbForm_arg', 'Animacy_arg', 'Gender_arg', 'rel_pos'])\n",
      "52701\n"
     ]
    }
   ],
   "source": [
    "data = vectorization.load_vectors(data_path)\n",
    "\n",
    "y = vectorization.VectorizedDataset({'role' : data._data['role']})\n",
    "del data._data['role']\n",
    "\n",
    "print(data._data.keys())\n",
    "print(data.size)\n",
    "\n",
    "indexes = np.array(list(range(data.size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make connectors between feature models and neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, LSTM, Convolution1D, Dropout, MaxPooling1D\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.layers import TimeDistributed\n",
    "from tensorflow.python.keras.layers import Activation\n",
    "from tensorflow.python.keras.layers import RepeatVector\n",
    "from tensorflow.python.keras.layers import Permute\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.layers import Concatenate\n",
    "from tensorflow.python.keras.layers import Bidirectional\n",
    "from tensorflow.python.keras.layers import Masking\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.python.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:59.798574",
     "start_time": "2017-02-18T12:22:59.779209"
    }
   },
   "outputs": [],
   "source": [
    "def construct_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(nb_filter=128, \n",
    "                            filter_length=2, \n",
    "                            border_mode='same', \n",
    "                            activation='relu', \n",
    "                            input_shape = (seq_embeded.shape[1], \n",
    "                                           get_embeddings_length(embeddings))))\n",
    "\n",
    "    #model.add(MaxPooling1D(pool_length=2))\n",
    "    model.add(LSTM(80))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(60, activation='tanh'))\n",
    "    model.add(Dense(number_of_roles, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:59.838778",
     "start_time": "2017-02-18T12:22:59.800378"
    }
   },
   "outputs": [],
   "source": [
    "def construct_simple_attentional_model():\n",
    "    units = 80\n",
    "    _input = Input(shape = (arg_context_embedded.shape[1], \n",
    "                            get_embeddings_length(embeddings)), dtype = 'float')\n",
    "\n",
    "    conv = Convolution1D(nb_filter=128, \n",
    "                        filter_length=2, \n",
    "                        border_mode='same', \n",
    "                        activation='relu')(_input)\n",
    "\n",
    "    activations = LSTM(units, return_sequences=True)(conv)\n",
    "\n",
    "    # compute importance for each step\n",
    "    attention = TimeDistributed(Dense(1, activation='tanh'))(activations) \n",
    "    #attention = Dense(6, activation='tanh')(activations) \n",
    "    attention = Flatten()(attention)\n",
    "    attention = Activation('softmax')(attention)\n",
    "    attention = RepeatVector(units)(attention)\n",
    "    attention = Permute([2, 1])(attention)\n",
    "\n",
    "    # apply the attention\n",
    "    sent_representation = merge([activations, attention], mode='mul')\n",
    "    sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n",
    "\n",
    "    #dn = Dense(100, activation = 'tanh')(sent_representation)\n",
    "    #probabilities = Dense(number_of_roles, activation='softmax')(dn)\n",
    "    probabilities = Dense(number_of_roles, activation='softmax')(sent_representation)\n",
    "\n",
    "    model = Model(input=_input, output=probabilities)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:59.886182",
     "start_time": "2017-02-18T12:22:59.840571"
    }
   },
   "outputs": [],
   "source": [
    "def construct_graph_bidirectional_model():\n",
    "    print('Bidirectional model.')\n",
    "    \n",
    "    arg_context_model = Sequential()\n",
    "    arg_context_model.add(Convolution1D(nb_filter=150, \n",
    "                                        filter_length=2, \n",
    "                                        border_mode='same', \n",
    "                                        activation='relu',\n",
    "                                        input_shape = (arg_context_embedded.shape[1], \n",
    "                                                       get_embeddings_length(embeddings))))\n",
    "    arg_context_model.add(Bidirectional(LSTM(100), merge_mode = 'sum'))\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    plain_model = Sequential()\n",
    "    plain_model.add(Dense(700, \n",
    "                          input_shape=(plain_features.shape[1],), \n",
    "                          activation = 'relu'))\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    final = Sequential()\n",
    "    final.add(Merge([arg_context_model, plain_model], mode = 'concat', concat_axis=1))\n",
    "    final.add(Dropout(0.3))\n",
    "    \n",
    "    #final.add(Dense(300, activation = 'relu'))\n",
    "    final.add(Dense(300))\n",
    "    final.add(BatchNormalization())\n",
    "    final.add(Activation('relu'))\n",
    "    final.add(Dropout(0.3))\n",
    "    \n",
    "    final.add(Dense(number_of_roles))\n",
    "    final.add(BatchNormalization())\n",
    "    final.add(Activation('softmax'))\n",
    "    \n",
    "    final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:59.952522",
     "start_time": "2017-02-18T12:22:59.887939"
    }
   },
   "outputs": [],
   "source": [
    "def construct_graph_attentional_model():\n",
    "    print('Context attentional model.')\n",
    "    \n",
    "    def construct_attentional_part(context_length):\n",
    "        _input = Input(shape = (context_length, \n",
    "                                get_embeddings_length(embeddings)), dtype = 'float')\n",
    "\n",
    "        conv = Convolution1D(nb_filter=200, \n",
    "                            filter_length=2, \n",
    "                            border_mode='same', \n",
    "                            activation='relu')(_input)\n",
    "\n",
    "        units = 100\n",
    "        activations = LSTM(units, return_sequences=True)(conv)\n",
    "\n",
    "        # compute importance for each step\n",
    "        attention = TimeDistributed(Dense(1, activation='tanh'))(activations)  \n",
    "        attention = Flatten()(attention)\n",
    "        attention = Activation('softmax')(attention)\n",
    "        attention = RepeatVector(units)(attention)\n",
    "        attention = Permute([2, 1])(attention)\n",
    "\n",
    "        # apply the attention\n",
    "        seq_repr = merge([activations, attention], mode='mul')\n",
    "        seq_repr = Lambda(lambda xin: K.sum(xin, axis=1))(seq_repr)\n",
    "        seq_model = Model(input=_input, output=seq_repr)\n",
    "        \n",
    "        return seq_model\n",
    "    \n",
    "    arg_context_model = construct_attentional_part(arg_context_embedded.shape[1])\n",
    "    pred_context_model = construct_attentional_part(pred_context_embedded.shape[1])\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    plain_model = Sequential()\n",
    "    plain_model.add(Dense(800, \n",
    "                          input_shape=(plain_features.shape[1],), \n",
    "                          activation = 'relu'))\n",
    "    \n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    final = Sequential()\n",
    "    final.add(Merge([arg_context_model, pred_context_model, plain_model], \n",
    "                    mode = 'concat', concat_axis=1))\n",
    "    final.add(Dropout(0.3))\n",
    "    \n",
    "    #final.add(Dense(300, activation = 'relu'))\n",
    "    final.add(Dense(400))\n",
    "    final.add(BatchNormalization())\n",
    "    final.add(Activation('relu'))\n",
    "    final.add(Dropout(0.3))\n",
    "    \n",
    "    final.add(Dense(number_of_roles))\n",
    "    final.add(BatchNormalization())\n",
    "    final.add(Activation('softmax'))\n",
    "    #final.add(Dense(number_of_roles, activation = 'softmax'))\n",
    "#    final.add(BatchNormalization())\n",
    "    #final.add(Activation('softmax'), W_regularizer=l2(0.01))\n",
    "    #final.add(Dense(number_of_roles, activation='softmax', W_regularizer = l2(0.01)))\n",
    "    \n",
    "    final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:23:00.015195",
     "start_time": "2017-02-18T12:22:59.954295"
    }
   },
   "outputs": [],
   "source": [
    "def construct_graph_lstm_model(plain_features_shape):\n",
    "    print('Context model.')\n",
    "    \n",
    "    def create_embed_model():\n",
    "        embed_model = Sequential()\n",
    "        embed_model.add(Dense(100, input_shape = (get_embeddings_length(embeddings), )))\n",
    "        embed_model.add(BatchNormalization())\n",
    "        embed_model.add(Activation('relu'))\n",
    "        return embed_model\n",
    "    \n",
    "    def construct_attentional_part(context_length):\n",
    "        seq_model = Sequential()\n",
    "        seq_model.add(Convolution1D(nb_filter=50, \n",
    "                                    filter_length=1, \n",
    "                                    border_mode='same', \n",
    "                                    activation='relu',\n",
    "                                    input_shape = (context_length, \n",
    "                                                   get_embeddings_length(embeddings))))\n",
    "#         seq_model.add(Masking(mask_value=0., input_shape = (context_length, \n",
    "#                                                             get_embeddings_length(embeddings))))\n",
    "        #seq_model.add(Masking(mask_value=1.))\n",
    "        seq_model.add(Bidirectional(LSTM(50), merge_mode='sum'))\n",
    "        #seq_model.add(LSTM(100))\n",
    "        seq_model.add(Dense(50))\n",
    "        seq_model.add(BatchNormalization())\n",
    "        seq_model.add(Activation('relu'))\n",
    "        \n",
    "        return seq_model\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    #arg_context_model = construct_attentional_part(arg_context_embedded.shape[1])\n",
    "    pred_context_model = construct_attentional_part(pred_context_embedded.shape[1])\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    plain_model = Sequential()\n",
    "    plain_model.add(Dense(400, input_shape = plain_features_shape))\n",
    "    plain_model.add(BatchNormalization())\n",
    "    plain_model.add(Activation('relu'))\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    arg_embed_model = create_embed_model()\n",
    "    pred_embed_model = create_embed_model()\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    final1 = Sequential()\n",
    "    final1.add(Merge([\n",
    "  #              arg_context_model, \n",
    "                     #pred_context_model,\n",
    "                     arg_embed_model,\n",
    "                     pred_embed_model,\n",
    "                     plain_model], \n",
    "                    mode = 'concat', concat_axis=1))\n",
    "    final1.add(Dropout(0.3))\n",
    "    \n",
    "    final1.add(Dense(400))\n",
    "    final1.add(BatchNormalization())\n",
    "    final1.add(Activation('relu'))\n",
    "    final1.add(Dropout(0.3))\n",
    "    \n",
    "    final = Sequential()\n",
    "    final.add(Merge([final1, pred_context_model], mode = 'concat', concat_axis = 1))\n",
    "    \n",
    "    final.add(Dense(number_of_roles))\n",
    "    final.add(BatchNormalization())\n",
    "    final.add(Activation('softmax'))\n",
    "    \n",
    "    final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:23:00.054095",
     "start_time": "2017-02-18T12:23:00.016955"
    }
   },
   "outputs": [],
   "source": [
    "def construct_plain_model(number_of_features, number_of_roles):\n",
    "    print('Plain model.')\n",
    "    \n",
    "    plain_model = Sequential()\n",
    "    plain_model.add(Dense(600, input_shape = (number_of_features,), activation = 'relu'))\n",
    "    plain_model.add(Dropout(0.3))\n",
    "    \n",
    "    plain_model.add(Dense(400))\n",
    "    plain_model.add(BatchNormalization())\n",
    "    plain_model.add(Activation('relu'))\n",
    "    plain_model.add(Dropout(0.3))\n",
    "    \n",
    "    plain_model.add(Dense(number_of_roles))\n",
    "    plain_model.add(BatchNormalization())\n",
    "    plain_model.add(Activation('softmax'))\n",
    "    \n",
    "    return plain_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:23:00.102016",
     "start_time": "2017-02-18T12:23:00.055842"
    }
   },
   "outputs": [],
   "source": [
    "def construct_plain_model_sparse(categ_size, emb_size, number_of_roles):    \n",
    "    input_plain = Input(shape=(categ_size,), name = 'input_categorical')\n",
    "    input_pred_embed = Input(shape=(emb_size,), name = 'pred_embed')\n",
    "    input_arg_embed = Input(shape=(emb_size,), name = 'arg_embed')\n",
    "    \n",
    "    plain = Dense(400)(input_plain)\n",
    "    plain = BatchNormalization()(plain)\n",
    "    plain = Activation('relu')(plain)\n",
    "    \n",
    "    def embed_submodel(inpt):\n",
    "        embed = Dense(100)(inpt)\n",
    "        embed = BatchNormalization()(embed)\n",
    "        embed = Activation('relu')(embed)\n",
    "        return embed\n",
    "    \n",
    "    embed_pred = embed_submodel(input_pred_embed)\n",
    "    embed_arg = embed_submodel(input_arg_embed)\n",
    "    \n",
    "    final = Concatenate(axis = 1)([embed_pred, embed_arg, plain])\n",
    "    final = Dropout(0.3)(final)\n",
    "    final = Dense(400)(final)\n",
    "    final = BatchNormalization()(final)\n",
    "    final = Activation('relu')(final)\n",
    "    final = Dropout(0.3)(final)\n",
    "    final = Dense(number_of_roles)(final)\n",
    "    final = BatchNormalization()(final)\n",
    "    final = Activation('softmax')(final)\n",
    "    \n",
    "    model = Model([input_arg_embed, input_pred_embed, input_plain], final)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import Sequence as KerasSequence\n",
    "\n",
    "\n",
    "class GeneratorSimple:\n",
    "    def __init__(self, indexes, data, batch_size, labels, one_hot_encoders = None):\n",
    "        self._data = vectorization.select_vectors({label : data[label] for label in labels}, indexes)\n",
    "        self._data_size = self._data[next(iter(self._data.keys()))].shape[0]\n",
    "        self._batch_size = batch_size\n",
    "        self._labels = labels\n",
    "        self._encs = one_hot_encoders\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(self._data_size / self._batch_size)\n",
    "    \n",
    "    def _get_chunk(self, label, idx):\n",
    "        return self._data[label][idx * self._batch_size : (idx + 1) * self._batch_size]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self._encs[k].transform(self._get_chunk(k, idx).reshape(-1, 1)) \n",
    "                if self._encs is not None and k in self._encs \n",
    "                else self._get_chunk(k, idx) \n",
    "                for k in self._labels]\n",
    "    \n",
    "\n",
    "class GeneratorUniversal(KerasSequence):\n",
    "    def __init__(self, gen_X, gen_y):\n",
    "        self._gen_X = gen_X\n",
    "        self._gen_y = gen_y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._gen_X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self._gen_X[idx], self._gen_y[idx])\n",
    "    \n",
    "\n",
    "class GeneratorZeros:\n",
    "    def __init__(self, data_size, shape, batch_size):\n",
    "        self._data_size = data_size\n",
    "        self._shape = shape\n",
    "        self._batch_size = batch_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return  math.ceil(self._data_size / self._batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return numpy.zeros((min(self._batch_size, self._data_size - idx * self._batch_size),) + self._shape)\n",
    "    \n",
    "\n",
    "class GeneratorConcat:\n",
    "    def __init__(self, generators):\n",
    "        self._generators = generators\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._generators[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        result = []\n",
    "        for gen in self._generators:\n",
    "            result += gen[idx]\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    \n",
    "class GeneratorConcatSingle:\n",
    "    def __init__(self, generator):\n",
    "        self._generator = generator\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._generator)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        lst = self._generator[idx]\n",
    "        return [np.concatenate(lst, axis=1)]\n",
    "    \n",
    "    def shape(self):\n",
    "        return self.__getitem__(0)[0].shape[1]\n",
    "    \n",
    "    \n",
    "class GeneratorLambdaDecorator:\n",
    "    def __init__(self, generator, lmbd):\n",
    "        self._generator = generator\n",
    "        self._lmbd = lmbd\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._generator)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self._lmbd(self._generator[idx])\n",
    "    \n",
    "    \n",
    "\n",
    "extract_one_hots = lambda dataset: {k : dataset.get_onehot(k) \n",
    "                                    for k in dataset._data.keys() \n",
    "                                    if dataset.get_onehot(k)}\n",
    "\n",
    "\n",
    "def construct_model(ctor, lr=0.1, batch_size=300):\n",
    "    model = ctor()\n",
    "    model.compile(optimizer=Adam(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_ctor(model_type):\n",
    "    def mk_model():\n",
    "        return construct_model(lambda: model_type)\n",
    "    \n",
    "    return mk_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 947\n",
      "Number of roles: 44\n"
     ]
    }
   ],
   "source": [
    "simple_features_generator_ctor = (lambda indexes, batch_size: \n",
    "                                  GeneratorUniversal(GeneratorConcatSingle(GeneratorSimple(indexes, \n",
    "                                                                            data, \n",
    "                                                                            batch_size, \n",
    "                                                                            list(data._data.keys()),\n",
    "                                                                            extract_one_hots(data))), \n",
    "                                                      GeneratorSimple(indexes, \n",
    "                                                                      y, \n",
    "                                                                      batch_size, \n",
    "                                                                      ['role'],\n",
    "                                                                      extract_one_hots(y))\n",
    "                                                    )\n",
    "                                 )\n",
    "\n",
    "\n",
    "simple_features_generator = simple_features_generator_ctor(indexes, data.size)\n",
    "number_of_features = simple_features_generator._gen_X.shape()\n",
    "number_of_roles = len(y._data['role']['encoder'])\n",
    "print('Number of features:', number_of_features)\n",
    "print('Number of roles:', number_of_roles)\n",
    "\n",
    "# We load everything in memory since dataset is rather small.\n",
    "batch = simple_features_generator[0]\n",
    "X_vec = batch[0]\n",
    "y_vec = batch[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = construct_model(lambda : construct_plain_model(number_of_features, \n",
    "                                                       number_of_roles))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit(X_vec, y_vec, \n",
    "          epochs=15, batch_size=batch_size, validation_split = 0.1, \n",
    "          shuffle=True, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features: 347\n",
      "Number of roles: 44\n"
     ]
    }
   ],
   "source": [
    "embedding_features = ['arg_lemma', 'pred_lemma']\n",
    "other_features = [k for k in data._data.keys() if k not in embedding_features]\n",
    "\n",
    "complex_features_generator_ctor = (lambda indexes, batch_size: \n",
    "                                  GeneratorUniversal(\n",
    "                                      GeneratorConcat(\n",
    "                                          [\n",
    "                                              GeneratorSimple(indexes, \n",
    "                                                           data, \n",
    "                                                           batch_size, \n",
    "                                                           embedding_features),\n",
    "                                              GeneratorConcatSingle(GeneratorSimple(indexes, \n",
    "                                                                            data, \n",
    "                                                                            batch_size, \n",
    "                                                                            other_features,\n",
    "                                                                            extract_one_hots(data)))\n",
    "                                          ]\n",
    "                                      ), \n",
    "                                      GeneratorSimple(indexes, \n",
    "                                                      y, \n",
    "                                                      batch_size, \n",
    "                                                      ['role'],\n",
    "                                                      extract_one_hots(y))\n",
    "                                  )\n",
    "                                 )\n",
    "\n",
    "\n",
    "complex_features_generator = complex_features_generator_ctor(indexes, data.size)\n",
    "number_of_categorical_features = complex_features_generator._gen_X._generators[1].shape()\n",
    "number_of_roles = len(y._data['role']['encoder'])\n",
    "print('Number of categorical features:', number_of_categorical_features)\n",
    "print('Number of roles:', number_of_roles)\n",
    "\n",
    "# We load everything in memory since dataset is rather small.\n",
    "batch = complex_features_generator[0]\n",
    "X_vec = batch[0]\n",
    "y_vec = batch[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = construct_model(lambda : construct_plain_model_sparse(number_of_categorical_features, \n",
    "                                                              300, \n",
    "                                                              number_of_roles))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit(X_vec, y_vec, \n",
    "          epochs=15, batch_size=batch_size, validation_split = 0.1, \n",
    "          shuffle=True, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, *args, **kwargs):\n",
    "    model.fit(X_train, y_train, *args, **kwargs)\n",
    "    \n",
    "    keras_eval = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    pred = model.predict(X_test).argmax(axis = 1)\n",
    "    f1_micro = f1_score(pred, y_test.argmax(axis = 1), average = 'micro')\n",
    "    f1_macro = f1_score(pred, y_test.argmax(axis = 1), average = 'macro')\n",
    "    accur = accuracy_score(pred, y_test.argmax(axis = 1))\n",
    "    \n",
    "    return list(keras_eval) + [f1_micro, f1_macro, accur]\n",
    "    \n",
    "\n",
    "def custom_cross_val(cr_f, X, y, cv, *args, **kwargs):\n",
    "    eval_res = list()\n",
    "    for i, (train, test) in enumerate(cv.split(y)):\n",
    "        model = cr_f()\n",
    "        print(\"Running Fold\", i+1, \"/\", cv.n_splits)\n",
    "        eval1 = train_and_evaluate_model(model, \n",
    "                                         [X[j][train] for j in range(len(X))], y[train], \n",
    "                                         [X[j][test] for j in range(len(X))], y[test], \n",
    "                                         *args, **kwargs)\n",
    "        \n",
    "        print()\n",
    "        print('Fold result: ', eval1)\n",
    "        eval_res.append(eval1)\n",
    "    \n",
    "    return np.array(eval_res)\n",
    "\n",
    "\n",
    "def describe_cv_result(cv_res):\n",
    "    print(cv_res)\n",
    "    mean_cv_res = cv_res.mean(axis = 0)\n",
    "    std_cv_res = cv_res.std(axis = 0)\n",
    "    print('Mean')\n",
    "    print(pd.DataFrame([mean_cv_res], columns = ['loss', 'keras_accur', 'micro_f1', 'macro_f1', 'accur']))\n",
    "    print('Std')\n",
    "    print(pd.DataFrame([std_cv_res], columns = ['loss', 'keras_accur', 'micro_f1', 'macro_f1', 'accur']))\n",
    "    #print 'Loss:', mean_cv_res[4], cv_res[:, 4].std()\n",
    "    #print 'Accur:', cv_res[:, 5].mean(), cv_res[:, 5].std()\n",
    "    \n",
    "    \n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = custom_cross_val(make_ctor(construct_plain_model_sparse(number_of_categorical_features, \n",
    "                                                                 300, \n",
    "                                                                 number_of_roles)),\n",
    "                          X_vec, y_vec[0], \n",
    "                          cv = cv, epochs=13, batch_size=64,\n",
    "                          validation_split = 0., shuffle=True, verbose = 0)\n",
    "\n",
    "describe_cv_result(cv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = custom_cross_val(make_ctor(construct_plain_model(number_of_features, \n",
    "                                                          number_of_roles)),\n",
    "                          X_vec, y_vec[0], \n",
    "                          cv = cv, epochs=13, batch_size=64,\n",
    "                          validation_split = 0., shuffle=True, verbose = 0)\n",
    "\n",
    "describe_cv_result(cv_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
