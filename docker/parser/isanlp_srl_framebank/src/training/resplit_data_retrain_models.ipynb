{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only one GPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../isanlp/src/')\n",
    "sys.path.append('../../src/isanlp_srl_framebank/')\n",
    "sys.path.append('../../libs/')\n",
    "sys.path.append('../../libs/pylingtools/')\n",
    "\n",
    "# Supress tensorflow memory appetites\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.log_device_placement=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "# Check available GPUs\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data and make the train/test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import isanlp\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_corpus_path = '../../data/cleared_corpus.json'\n",
    "\n",
    "with open(cleared_corpus_path, 'r') as f:\n",
    "    examples = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_data_path = '../../data/results_final_fixed.pckl'\n",
    "with open(ling_data_path, 'rb') as f:\n",
    "    ling_data_cache = pickle.load(f)\n",
    "\n",
    "ling_data_cache = {k: v for k,v in ling_data_cache}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ids, test_ids = train_test_split(list(ling_data_cache.keys()), test_size=0.2, random_state=42)\n",
    "train_ids = list(set(train_ids))\n",
    "test_ids = list(set(test_ids))\n",
    "\n",
    "data_path = '../../data/'\n",
    "main_model_path_root = '../../data/models_new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8dccd3386e58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexample\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexample\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_data.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8dccd3386e58>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexample\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexample\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_data.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = [example for example in examples if example[0] in train_ids]\n",
    "test_data = [example for example in examples if example[0] in test_ids]\n",
    "\n",
    "with open(os.path.join(data_path, 'train_data.json'), 'w') as f:\n",
    "    json.dump(train_data, f)\n",
    "\n",
    "with open(os.path.join(data_path, 'test_data.json'), 'w') as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../isanlp/src/')\n",
    "sys.path.append('../../src/isanlp_srl_framebank/')\n",
    "sys.path.append('../../libs/')\n",
    "sys.path.append('../../libs/pylingtools/')\n",
    "\n",
    "\n",
    "from isanlp.annotation_repr import CSentence\n",
    "from convert_corpus_to_brat import make_text\n",
    "\n",
    "\n",
    "def find_address_by_offset(offset, ling_ann):\n",
    "    for tok_num, tok in enumerate(ling_ann['tokens']):\n",
    "        if tok.begin <= offset and offset < tok.end:\n",
    "            break\n",
    "    \n",
    "    for sent_num, sent in enumerate(ling_ann['sentences']):\n",
    "        if sent.begin <= tok_num and tok_num < sent.end:\n",
    "            break\n",
    "    \n",
    "    return sent_num, tok_num - sent.begin\n",
    "\n",
    "\n",
    "error_examples = {}\n",
    "\n",
    "def process_arg_pred(feature_extractor, ling_cache, ex_id, pred, args, example):\n",
    "    feature_sets = list()\n",
    "    \n",
    "    text, offset_index = make_text(example, 0)\n",
    "    ling_ann = ling_cache[ex_id]\n",
    "    \n",
    "    pred_offset = offset_index[(pred[0], pred[1])]\n",
    "    pred_ling_sent, pred_ling_word = find_address_by_offset(pred_offset, ling_ann)\n",
    "    \n",
    "    for arg in args:\n",
    "        arg_offset = offset_index[(arg[0], arg[1])]\n",
    "        arg_ling_sent, arg_ling_word = find_address_by_offset(arg_offset, ling_ann)\n",
    "        \n",
    "        fb_pred_word = example[pred[0]][pred[1]]\n",
    "        fb_arg_word = example[arg[0]][arg[1]]\n",
    "        \n",
    "        if arg_ling_sent != pred_ling_sent:\n",
    "            error_examples[ex_id] = {\n",
    "                'reason': 'sent_mismatch',\n",
    "                'arg': arg_ling_sent,\n",
    "                'pred': pred_ling_sent\n",
    "            }\n",
    "            continue\n",
    "            \n",
    "        sentence = ling_ann['sentences'][pred_ling_sent]\n",
    "        tokens = [tok.text for tok in ling_ann['tokens']]\n",
    "        tokens = tokens[sentence.begin:sentence.end]\n",
    "        \n",
    "        role = fb_arg_word['rolepred1']\n",
    "\n",
    "        features = feature_extractor.extract_features(pred_ling_word, \n",
    "                                                      arg_ling_word, \n",
    "                                                      ling_ann['postag'][arg_ling_sent],\n",
    "                                                      ling_ann['morph'][arg_ling_sent],\n",
    "                                                      ling_ann['lemma'][arg_ling_sent],\n",
    "                                                      ling_ann['syntax_dep_tree'][arg_ling_sent])\n",
    "\n",
    "                    \n",
    "        feature_sets.append((features, role, ex_id, tokens, arg_ling_word, pred_ling_word))\n",
    "    \n",
    "    return feature_sets\n",
    "\n",
    "\n",
    "def process_example(feature_extractor, ling_cache, ex_id, sentences):\n",
    "    pred = None\n",
    "    args = list()\n",
    "    for sent_num, sent in enumerate(sentences):\n",
    "        for word_num, word in enumerate(sent):\n",
    "            if 'rank' in word and word['rank'] == 'Предикат':\n",
    "                pred = (sent_num, word_num)\n",
    "            elif 'rolepred1' in word:\n",
    "                args.append((sent_num, word_num))\n",
    "    \n",
    "    return process_arg_pred(feature_extractor, ling_cache, ex_id, pred, args, sentences)\n",
    "\n",
    "\n",
    "num_of_errors = 0\n",
    "def prepare_train_data(examples, ling_data_cache, feature_extractor):\n",
    "    feature_sets = []\n",
    "    for ex_num, (ex_id, ex) in tqdm(list(enumerate(examples))):                \n",
    "        feature_sets += process_example(feature_extractor, ling_data_cache, ex_id, ex)\n",
    "\n",
    "    print('Number of examples:', len(feature_sets))\n",
    "    return feature_sets\n",
    "\n",
    "\n",
    "def construct_features(examples, ling_data_cache, feature_model):\n",
    "    feature_sets = prepare_train_data(examples, ling_data_cache, feature_model)\n",
    "\n",
    "    data_for_pandas = []\n",
    "    for example in feature_sets:\n",
    "        data_for_pandas_ex = {}\n",
    "        data_for_pandas_ex['role'] = example[1]\n",
    "        data_for_pandas_ex['ex_id'] = example[2]\n",
    "        data_for_pandas_ex['tokens'] = example[3]\n",
    "        data_for_pandas_ex['arg_address'] = example[4]\n",
    "        data_for_pandas_ex['prd_address'] = example[5]\n",
    "        for elem in example[0]:\n",
    "            for subelem in elem:\n",
    "                if subelem is not None:\n",
    "                    data_for_pandas_ex.update(subelem)\n",
    "\n",
    "        data_for_pandas.append(data_for_pandas_ex)\n",
    "\n",
    "    return pd.DataFrame(data_for_pandas).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_preds = False  # Choose feature model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8759ee5dd7445daa9e26f1c5f1178f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32612), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of examples: 57552\n"
     ]
    }
   ],
   "source": [
    "if known_preds:\n",
    "    from isanlp_srl_framebank.processor_srl_framebank import FeatureModelDefault\n",
    "    feature_model = FeatureModelDefault()\n",
    "    main_model_path = os.path.join(main_model_path_root, 'known_preds')\n",
    "    pd_data = construct_features(examples, ling_data_cache, feature_model)\n",
    "\n",
    "else:\n",
    "    from isanlp_srl_framebank.processor_srl_framebank import FeatureModelUnknownPredicates\n",
    "    feature_model = FeatureModelUnknownPredicates()\n",
    "    main_model_path = os.path.join(main_model_path_root, 'unknown_preds')\n",
    "    pd_data = construct_features(examples, ling_data_cache, feature_model)\n",
    "    del pd_data['pred_lemma']\n",
    "\n",
    "with open(os.path.join(main_model_path, 'feature_model.pckl'), 'wb') as f:\n",
    "    pickle.dump(feature_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57552, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Argument position: 7\n",
      "Argument lemma: контрабас_NOUN\n",
      "--\n",
      "Predicat position: 4\n",
      "Predicat lemma: None\n",
      "--\n",
      "Distance 3\n",
      "--\n",
      "Sentence tokens: [(0, 'Зубря'), (1, 'заклинания'), (2, ','), (3, 'Таня'), (4, 'извлекла'), (5, 'из'), (6, 'футляра'), (7, 'контрабас'), (8, ','), (9, 'села'), (10, 'на'), (11, 'него'), (12, 'и'), (13, 'взяла'), (14, 'в'), (15, 'руку'), (16, 'смычок'), (17, '.')]\n"
     ]
    }
   ],
   "source": [
    "N_verify = 1\n",
    "for i in np.random.choice(len(pd_data), size=N_verify):\n",
    "    print(\"-\"*60)\n",
    "    obj = pd_data.iloc[i]\n",
    "    print(f\"Argument position: {obj.arg_address}\")\n",
    "    print(f\"Argument lemma: {obj.arg_lemma}\")\n",
    "    print(\"--\")\n",
    "    print(f\"Predicat position: {obj.prd_address}\")\n",
    "    print(f\"Predicat lemma: {obj.get('pred_lemma')}\")\n",
    "    print(\"--\")\n",
    "    print(f\"Distance {int(obj.dist)}\")\n",
    "    print(\"--\")\n",
    "    print(f\"Sentence tokens: {list(enumerate(obj.tokens))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Animacy_arg', 'Aspect_arg', 'Gender_arg', 'Number_arg', 'Tense_arg',\n",
       "       'Valency_arg', 'VerbForm_arg', 'arg_address', 'arg_case', 'arg_lemma',\n",
       "       'arg_pos', 'dist', 'ex_id', 'prd_address', 'pred_pos', 'prepos',\n",
       "       'rel_pos', 'role', 'syn_link_name', 'tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animacy_arg</th>\n",
       "      <th>Aspect_arg</th>\n",
       "      <th>Gender_arg</th>\n",
       "      <th>Number_arg</th>\n",
       "      <th>Tense_arg</th>\n",
       "      <th>Valency_arg</th>\n",
       "      <th>VerbForm_arg</th>\n",
       "      <th>arg_address</th>\n",
       "      <th>arg_case</th>\n",
       "      <th>arg_lemma</th>\n",
       "      <th>arg_pos</th>\n",
       "      <th>dist</th>\n",
       "      <th>ex_id</th>\n",
       "      <th>prd_address</th>\n",
       "      <th>pred_pos</th>\n",
       "      <th>prepos</th>\n",
       "      <th>rel_pos</th>\n",
       "      <th>role</th>\n",
       "      <th>syn_link_name</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8788</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Plur</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Nom</td>\n",
       "      <td>они_PRON</td>\n",
       "      <td>PRON</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40335</td>\n",
       "      <td>1</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>тема</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>[Они, появлялись, и, уходили, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Animacy_arg Aspect_arg Gender_arg Number_arg Tense_arg Valency_arg  \\\n",
       "8788                                         Plur                         \n",
       "\n",
       "     VerbForm_arg  arg_address arg_case arg_lemma arg_pos  dist  ex_id  \\\n",
       "8788                         0      Nom  они_PRON    PRON   1.0  40335   \n",
       "\n",
       "      prd_address pred_pos prepos  rel_pos  role syn_link_name  \\\n",
       "8788            1     VERB             1.0  тема         nsubj   \n",
       "\n",
       "                                tokens  \n",
       "8788  [Они, появлялись, и, уходили, .]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_stat = pd_data.role.value_counts()\n",
    "drop_ys = y_stat[y_stat < 180].index\n",
    "#pd_data = pd_data.drop(pd_data[pd_data.role.isin(drop_ys)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['субъект физиологического ощущения', 'агенс / каузатор',\n",
       "       'подвергающаяся воздействию часть пациенса',\n",
       "       'инструмент / квазиинструмент', 'посессор',\n",
       "       'субъект психологического состояния / часть субъекта психологического состояния',\n",
       "       'квазиинструмент', 'инструмент - место', 'запах',\n",
       "       'конечная точка - сфера',\n",
       "       ...\n",
       "       'инструмент-место', 'начальная точка - причина', 'оценка',\n",
       "       'способ - эффектор', 'пациенс перемещения / результат',\n",
       "       'начальная точка - цена',\n",
       "       'место / часть субъекта ментального состояния',\n",
       "       'конечная точка - содержание действия', 'звук метаф.',\n",
       "       'каузатор - субъект ментального состояния'],\n",
       "      dtype='object', length=239)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "агенс                                                 6147\n",
       "пациенс                                               5362\n",
       "тема                                                  3656\n",
       "субъект перемещения                                   3011\n",
       "субъект психологического состояния                    2973\n",
       "причина                                               2502\n",
       "говорящий                                             2365\n",
       "место                                                 1917\n",
       "содержание действия                                   1874\n",
       "содержание мысли                                      1817\n",
       "содержание высказывания                               1792\n",
       "конечная точка                                        1772\n",
       "пациенс перемещения                                   1356\n",
       "стимул                                                1271\n",
       "результат                                             1216\n",
       "субъект ментального состояния                          998\n",
       "адресат                                                941\n",
       "контрагент                                             831\n",
       "эффектор                                               739\n",
       "субъект восприятия                                     709\n",
       "субъект социального отношения                          598\n",
       "начальная точка                                        588\n",
       "предмет высказывания                                   548\n",
       "способ                                                 531\n",
       "конечный посессор                                      506\n",
       "цель                                                   454\n",
       "сфера                                                  376\n",
       "признак                                                366\n",
       "источник звука                                         359\n",
       "субъект поведения                                      339\n",
       "                                                      ... \n",
       "эвиденциальность                                         1\n",
       "контрагент метаф.                                        1\n",
       "начальная точка - тема                                   1\n",
       "источник метаф.                                          1\n",
       "место - способ                                           1\n",
       "свет                                                     1\n",
       "субъект восприятия / субъект ментального состояния       1\n",
       "инструмент - место - источник звука                      1\n",
       "предмет высказывания - причина                           1\n",
       "предмет оценки                                           1\n",
       "потенциальный агенс                                      1\n",
       "контроль сложный                                         1\n",
       "содержание высказывания - статус                         1\n",
       "объект подозрения                                        1\n",
       "конечный посессор метаф.                                 1\n",
       "причина фоновой ситуации                                 1\n",
       "агенс - тема                                             1\n",
       "средство - эффектор                                      1\n",
       "контрагент социального отношения - начальная точка       1\n",
       "стимул - субъект перемещения                             1\n",
       "инструмент-место                                         1\n",
       "начальная точка - причина                                1\n",
       "оценка                                                   1\n",
       "способ - эффектор                                        1\n",
       "пациенс перемещения / результат                          1\n",
       "начальная точка - цена                                   1\n",
       "место / часть субъекта ментального состояния             1\n",
       "конечная точка - содержание действия                     1\n",
       "звук метаф.                                              1\n",
       "каузатор - субъект ментального состояния                 1\n",
       "Name: role, Length: 288, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data.loc[:, 'role'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of roles:  45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "агенс                                 6147\n",
       "пациенс                               5362\n",
       "non_rel                               4801\n",
       "тема                                  3656\n",
       "субъект психологического состояния    3250\n",
       "субъект перемещения                   3011\n",
       "причина                               2502\n",
       "говорящий                             2365\n",
       "место                                 2185\n",
       "содержание действия                   1874\n",
       "содержание мысли                      1817\n",
       "содержание высказывания               1792\n",
       "конечная точка                        1772\n",
       "результат                             1452\n",
       "пациенс перемещения                   1356\n",
       "стимул                                1271\n",
       "субъект ментального состояния         1223\n",
       "адресат                                941\n",
       "субъект восприятия                     901\n",
       "контрагент                             831\n",
       "эффектор                               739\n",
       "субъект социального отношения          598\n",
       "начальная точка                        588\n",
       "предмет высказывания                   548\n",
       "способ                                 531\n",
       "конечный посессор                      506\n",
       "цель                                   454\n",
       "сфера                                  376\n",
       "признак                                366\n",
       "источник звука                         359\n",
       "субъект поведения                      339\n",
       "ситуация в фокусе                      322\n",
       "контрагент социального отношения       318\n",
       "субъект физиологической реакции        310\n",
       "предмет мысли                          303\n",
       "потенциальный пациенс                  290\n",
       "статус                                 265\n",
       "пациенс социального отношения          261\n",
       "срок                                   255\n",
       "эталон                                 255\n",
       "признак действия                       243\n",
       "каузатор                               223\n",
       "исходный посессор                      217\n",
       "потенциальная угроза                   197\n",
       "траектория                             180\n",
       "Name: role, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl_roles = {\n",
    "    'агенс - субъект восприятия' : 'субъект восприятия',\n",
    "    'агенс - субъект ментального состояния' : 'субъект ментального состояния',\n",
    "    'результат / цель' : 'результат',\n",
    "    'место - пациенс' : 'место',\n",
    "    'говорящий - субъект психологического состояния' : 'субъект психологического состояния',\n",
    "}\n",
    "pd_data['role'] = pd_data['role'].replace(repl_roles)\n",
    "\n",
    "non_rel_map = {rel: 'non_rel' for rel in drop_ys}\n",
    "pd_data['role'] = pd_data['role'].replace(non_rel_map) \n",
    "    \n",
    "number_of_roles = len(pd_data.role.unique())\n",
    "print('Number of roles: ', number_of_roles)\n",
    "pd_data.loc[:, 'role'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57552, 19)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_orig = pd_data.loc[:, 'role']\n",
    "X_orig = pd_data.drop('role', axis = 1)\n",
    "X_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_selector_pd = X_orig.ex_id.isin(train_ids)\n",
    "test_selector_pd = X_orig.ex_id.isin(test_ids)\n",
    "train_selector = train_selector_pd.values\n",
    "test_selector = test_selector_pd.values\n",
    "\n",
    "def select_from_nparray_list(nparray_list, selector):\n",
    "    return [e[selector] for e in nparray_list]\n",
    "\n",
    "X_train = select_from_nparray_list([X_orig], train_selector)[0]\n",
    "y_train = select_from_nparray_list([y_orig], train_selector)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = select_from_nparray_list([X_orig], test_selector)[0]\n",
    "y_test = select_from_nparray_list([y_orig], test_selector)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pickle\n",
    "\n",
    "label_encoder = LabelBinarizer()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "\n",
    "with open(main_model_path + '/label_encoder.pckl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_ommit = ['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category features:\n",
      " ['Animacy_arg', 'Aspect_arg', 'Gender_arg', 'Number_arg', 'Tense_arg', 'Valency_arg', 'VerbForm_arg', 'arg_case', 'arg_lemma', 'arg_pos', 'dist', 'prd_address', 'pred_pos', 'prepos', 'syn_link_name']\n",
      "Not category features:\n",
      " ['rel_pos']\n",
      "(57552, 10390)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#morph_feats = ['pos', 'case', 'anim', 'vform', 'zform', 'shform', 'pform', 'vvform', 'nform', 'time']\n",
    "\n",
    "# all_feats = (['pred_lemma', 'rel_pos'] + \n",
    "#              ['arg_' + e for e in morph_feats] + \n",
    "#              ['pred_' + e for e in morph_feats])\n",
    "\n",
    "# all_feats = (['pred_lemma', 'rel_pos', 'arg_prep'] + \n",
    "#              ['arg_' + e for e in morph_feats] + \n",
    "#              ['pred_' + e for e in morph_feats])\n",
    "\n",
    "# all_feats = (['pred_lemma', 'rel_pos', 'arg_prep', 'link_name'] + \n",
    "#              ['arg_' + e for e in morph_feats] + \n",
    "#              ['pred_' + e for e in morph_feats])\n",
    "\n",
    "#all_feats = ['pred_lemma', 'rel_pos', 'pred_pos', 'arg_case', 'syn_link_name', 'arg_pos', 'prepos', 'dist']\n",
    "\n",
    "#categ_feats = [e for e in all_feats if X_orig[e].dtype in [str, object]]\n",
    "#not_categ = [e for e in all_feats if e not in categ_feats]\n",
    "\n",
    "#pred_lemma_vectorizer.fit_transform(X_orig.loc[:, ['pred_lemma']].to_dict(orient = 'records'))\n",
    "\n",
    "if not known_preds and 'pred_lemma' in X_train.keys():\n",
    "    X_train = X_train.drop(columns=['pred_lemma'])\n",
    "    \n",
    "not_categ_features = {'arg_address', 'ex_id', 'rel_pos'}\n",
    "\n",
    "categ_feats = [name for name in X_train.drop(columns=columns_to_ommit).columns if name not in not_categ_features] \n",
    "not_categ = ['rel_pos']\n",
    "print('Category features:\\n', categ_feats)\n",
    "print('Not category features:\\n', not_categ)\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# X_train[categorical_cols] = X_train[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "# one_hot_feats = vectorizer.fit_transform(X_orig[categ_feats].to_dict(orient='records'))\n",
    "\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "vectorizer.fit(X_train[categ_feats].to_dict(orient='records'))\n",
    "one_hot_feats = vectorizer.transform(X_orig[categ_feats].to_dict(orient='records'))\n",
    "print(one_hot_feats.shape)\n",
    "\n",
    "with open(main_model_path + '/feature_encoder.pckl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../../data/labnpnpels.npy\", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57552, 10391)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_categ_columns = np.concatenate(tuple(X_orig.loc[:, e].values.reshape(-1, 1) for e in not_categ), axis =1)\n",
    "plain_features = np.concatenate((one_hot_feats, not_categ_columns), axis = 1)\n",
    "plain_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../../data/plain_features.npy\", plain_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add embedding features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "embeddings_path = '../../data/ruscorpora_upos_skipgram_300_5_2018.vec'\n",
    "embeddings = KeyedVectors.load_word2vec_format(embeddings_path, binary=False)\n",
    "print('Embedding size: ', embeddings.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def make_embeded_form(word):\n",
    "    if word:\n",
    "        #return word[1].encode('utf8')\n",
    "        return u\"{}_{}\".format(word[1], word[0])\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "\n",
    "class Embedder_map:\n",
    "    def __init__(self, embeddings, X):\n",
    "        self.X_ = X\n",
    "        self.embeddings_ = embeddings\n",
    "\n",
    "    def __call__(self, i):  \n",
    "        result = np.zeros(embeddings.vector_size)\n",
    "        \n",
    "        ARG_SPECIAL_TAG = None  # ??\n",
    "\n",
    "        word = self.X_[i]\n",
    "        if embeddings.vocab.get(word):\n",
    "            return embeddings[word]\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def embed(X):\n",
    "    pool = mp.Pool(4)\n",
    "    result = pool.map(Embedder_map(embeddings, X), list(range(len(X))), 1000)\n",
    "    pool.close()\n",
    "#     embedder = Embedder_map(embeddings, X)\n",
    "#     result =[embedder(i) for i in range(2)]\n",
    "#     #result = [embedder(i) for i in range(len(X))]\n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 s, sys: 4.96 s, total: 24.6 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "arg_embedded = embed(X_orig['arg_lemma'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.8 s, sys: 5.26 s, total: 25 s\n",
      "Wall time: 28.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred_embedded = embed(X_orig['pred_lemma'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../../data/w2v_verbs_whole.npy\", pred_embedded)\n",
    "np.save(\"../../data/w2v_args_whole.npy\", arg_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_embedded = np.load(\"../../data/w2v_verbs_whole.npy\")\n",
    "arg_embedded = np.load(\"../../data/w2v_args_whole.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0802 13:32:22.486564 139831569893120 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.models.embedders.elmo_embedder import ELMoEmbedder\n",
    "\n",
    "elmo = ELMoEmbedder(\"http://files.deeppavlov.ai/deeppavlov_data/elmo_ru-wiki_600k_steps.tar.gz\", elmo_output_names=['elmo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_embed(embeddings, tokens, word_idx1, word_idx2):\n",
    "    embedded = embeddings([tokens])[0]\n",
    "    return embedded[min(word_idx1, len(tokens)-1)], embedded[min(word_idx2, len(tokens)-1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test object\n",
    "obj = X_orig.iloc[38]\n",
    "verb_idx = obj.prd_address\n",
    "arg_idx = obj.arg_address\n",
    "tokens = obj.tokens\n",
    "embed_verb, embed_arg = elmo_embed(elmo, tokens, verb_idx, arg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e99c7ef2834bd5a7fc2ded7df1f2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=57552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "embedded_verbs = []\n",
    "embedded_args  = []\n",
    "for i in tqdm(range(len(X_orig))):\n",
    "    try:\n",
    "        if i % 100 == 0:\n",
    "            with open(\"./log.txt\", 'a', encoding='utf-8') as log:\n",
    "                print(f\"Processed {i} examples\", file=log)\n",
    "        obj = X_orig.iloc[i]\n",
    "        verb_idx = obj.prd_address\n",
    "        arg_idx = obj.arg_address\n",
    "        tokens = obj.tokens\n",
    "        embed_verb, embed_arg = elmo_embed(elmo, tokens, verb_idx, arg_idx)\n",
    "        embedded_verbs.append(embed_verb)\n",
    "        embedded_args.append(embed_arg)\n",
    "    except Exception as e:\n",
    "        with open(\"./log.txt\", 'a', encoding='utf-8') as log:\n",
    "            print(f\"Error while processing example {i}={X_orig.iloc[i]}: {e}\", file=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57552, 1024) (57552, 1024)\n"
     ]
    }
   ],
   "source": [
    "e_verbs = np.stack(embedded_verbs)\n",
    "e_args  = np.stack(embedded_args)\n",
    "\n",
    "print(e_verbs.shape, e_args.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../../data/elmo_verbs_whole.npy\", e_verbs)\n",
    "np.save(\"../../data/elmo_args_whole.npy\", e_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_verbs = np.load(\"../../data/elmo_verbs.npy\")\n",
    "e_args = np.load(\"../../data/elmo_args.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_verbs = np.load(\"../../data/elmo_verbs_whole.npy\")\n",
    "e_args = np.load(\"../../data/elmo_args_whole.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, LSTM, Convolution1D, Dropout, MaxPooling1D\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.layers import TimeDistributed\n",
    "from tensorflow.python.keras.layers import Activation\n",
    "from tensorflow.python.keras.layers import RepeatVector\n",
    "from tensorflow.python.keras.layers import Permute\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.layers import Concatenate\n",
    "from tensorflow.python.keras.layers import Bidirectional\n",
    "from tensorflow.python.keras.layers import Masking\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_plain_model(input_shape):\n",
    "    print('Plain model.')\n",
    "    \n",
    "    plain_model = Sequential()\n",
    "    plain_model.add(Dense(600, \n",
    "                          #input_shape=(plain_features.shape[1],), \n",
    "                          input_shape = input_shape,\n",
    "                          activation = 'relu'))\n",
    "    plain_model.add(Dropout(0.3))\n",
    "    \n",
    "    plain_model.add(Dense(400))\n",
    "    plain_model.add(BatchNormalization())\n",
    "    plain_model.add(Activation('relu'))\n",
    "    plain_model.add(Dropout(0.3))\n",
    "    \n",
    "    plain_model.add(Dense(number_of_roles))\n",
    "    plain_model.add(BatchNormalization())\n",
    "    plain_model.add(Activation('softmax'))\n",
    "    \n",
    "    plain_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return plain_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_plain_model_sparse(categ_size, emb_size, number_of_roles):    \n",
    "    input_plain = Input(shape=(categ_size,), name = 'input_categorical')\n",
    "    input_pred_embed = Input(shape=(emb_size,), name = 'pred_embed')\n",
    "    input_arg_embed = Input(shape=(emb_size,), name = 'arg_embed')\n",
    "    \n",
    "    plain = Dense(400)(input_plain)\n",
    "    plain = BatchNormalization()(plain)\n",
    "    plain = Activation('relu')(plain)\n",
    "    \n",
    "    def embed_submodel(inpt):\n",
    "        embed = Dense(100)(inpt)\n",
    "        embed = BatchNormalization()(embed)\n",
    "        embed = Activation('relu')(embed)\n",
    "        return embed\n",
    "    \n",
    "    embed_pred = embed_submodel(input_pred_embed)\n",
    "    embed_arg = embed_submodel(input_arg_embed)\n",
    "    \n",
    "    final = Concatenate(axis = 1)([embed_pred, embed_arg, plain])\n",
    "    final = Dropout(0.3)(final)\n",
    "    final = Dense(400)(final)\n",
    "    final = BatchNormalization()(final)\n",
    "    final = Activation('relu')(final)\n",
    "    final = Dropout(0.3)(final)\n",
    "    final = Dense(number_of_roles)(final)\n",
    "    final = BatchNormalization()(final)\n",
    "    final = Activation('softmax')(final)\n",
    "    \n",
    "    model = Model([input_arg_embed, input_pred_embed, input_plain], final)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_plain_model_sparse_unknown(categ_size, emb_size, number_of_roles):    \n",
    "    input_plain = Input(shape=(categ_size,), name = 'input_categorical')\n",
    "    input_pred_embed = Input(shape=(emb_size,), name = 'pred_embed')\n",
    "    input_arg_embed = Input(shape=(emb_size,), name = 'arg_embed')\n",
    "    \n",
    "    plain = Dense(400)(input_plain)\n",
    "    plain = BatchNormalization()(plain)\n",
    "    plain = Activation('relu')(plain)\n",
    "    \n",
    "    def embed_submodel(inpt, units):\n",
    "        embed = Dense(units)(inpt)\n",
    "        embed = BatchNormalization()(embed)\n",
    "        embed = Activation('relu')(embed)\n",
    "        return embed\n",
    "    \n",
    "    embed_pred = embed_submodel(input_pred_embed, 100)\n",
    "    embed_arg = embed_submodel(input_arg_embed, 400)\n",
    "    \n",
    "    final = Concatenate(axis = 1)([embed_pred, embed_arg, plain])\n",
    "    final = Dropout(0.3)(final)\n",
    "    final = Dense(400)(final)\n",
    "    final = BatchNormalization()(final)\n",
    "    final = Activation('relu')(final)\n",
    "    final = Dropout(0.3)(final)\n",
    "    final = Dense(number_of_roles)(final)\n",
    "    final = BatchNormalization()(final)\n",
    "    final = Activation('softmax')(final)\n",
    "    \n",
    "    model = Model([input_arg_embed, input_pred_embed, input_plain], final)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and save the models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For known preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_from_nparray_list(nparray_list, selector):\n",
    "    return [np.array(e)[selector] for e in nparray_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57552, 1024), (57552, 1024), (57552, 10391))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_args.shape, e_verbs.shape, plain_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46016"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "pred_embed (InputLayer)         (None, 1024)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "arg_embed (InputLayer)          (None, 1024)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_categorical (InputLayer)  (None, 10391)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          102500      pred_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          102500      arg_embed[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 400)          4156800     input_categorical[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 100)          400         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 100)          400         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 400)          1600        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 100)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 400)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 600)          0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 600)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 400)          240400      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400)          1600        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 45)           18045       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 45)           180         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 45)           0           batch_normalization_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 4,624,425\n",
      "Trainable params: 4,622,335\n",
      "Non-trainable params: 2,090\n",
      "__________________________________________________________________________________________________\n",
      "Train on 41414 samples, validate on 4602 samples\n",
      "Epoch 1/10\n",
      " 7232/41414 [====>.........................] - ETA: 7s - loss: 3.1626 - acc: 0.2405"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-bf46a44dd9f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m model.fit(select_from_nparray_list([e_args, e_verbs, plain_features], train_selector),\n\u001b[1;32m      7\u001b[0m           \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           epochs=10, batch_size=64, validation_split = 0.1, shuffle=True)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'test_model_elmo_45.h5'\n",
    "VEC_SIZE = e_verbs.shape[1]\n",
    "\n",
    "model = construct_plain_model_sparse(plain_features.shape[1], VEC_SIZE, y_train.shape[1])\n",
    "model.summary()\n",
    "model.fit(select_from_nparray_list([e_args, e_verbs, plain_features], train_selector),\n",
    "          y_train, \n",
    "          epochs=10, batch_size=64, validation_split = 0.1, shuffle=True)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate(select_from_nparray_list([e_args, e_verbs, plain_features], test_selector), \n",
    "               y_test))\n",
    "model.save(os.path.join(main_model_path, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.metrics_names)\n",
    "print(model.evaluate(select_from_nparray_list([e_args, e_verbs, plain_features], test_selector), \n",
    "               y_test))\n",
    "model.save(os.path.join(main_model_path, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'test_model_w2v_45.h5'\n",
    "VEC_SIZE = embeddings.vector_size\n",
    "\n",
    "model = construct_plain_model_sparse(plain_features.shape[1], embeddings.vector_size, y_train.shape[1])\n",
    "model.fit(select_from_nparray_list([arg_embedded, pred_embedded, plain_features], train_selector),\n",
    "          y_train, \n",
    "          epochs=15, batch_size=300, validation_split = 0.1, shuffle=True)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate(select_from_nparray_list([arg_embedded, pred_embedded, plain_features], test_selector), \n",
    "               y_test))\n",
    "model.save(os.path.join(main_model_path, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For unknown preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "pred_embed (InputLayer)         (None, 1024)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "arg_embed (InputLayer)          (None, 1024)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_categorical (InputLayer)  (None, 10391)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          102500      pred_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          102500      arg_embed[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 400)          4156800     input_categorical[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 100)          400         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 100)          400         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 400)          1600        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 100)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 400)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 600)          0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 600)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 400)          240400      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 400)          1600        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 45)           18045       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 45)           180         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 45)           0           batch_normalization_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 4,624,425\n",
      "Trainable params: 4,622,335\n",
      "Non-trainable params: 2,090\n",
      "__________________________________________________________________________________________________\n",
      "Train on 41414 samples, validate on 4602 samples\n",
      "Epoch 1/10\n",
      "41414/41414 [==============================] - 7s 170us/step - loss: 2.2172 - acc: 0.4703 - val_loss: 1.4926 - val_acc: 0.6521\n",
      "Epoch 2/10\n",
      "41414/41414 [==============================] - 6s 135us/step - loss: 1.4409 - acc: 0.6330 - val_loss: 1.1522 - val_acc: 0.6956\n",
      "Epoch 3/10\n",
      "41414/41414 [==============================] - 6s 141us/step - loss: 1.1664 - acc: 0.6923 - val_loss: 1.0506 - val_acc: 0.7171\n",
      "Epoch 4/10\n",
      "41414/41414 [==============================] - 6s 156us/step - loss: 0.9807 - acc: 0.7322 - val_loss: 0.9890 - val_acc: 0.7216\n",
      "Epoch 5/10\n",
      "41414/41414 [==============================] - 8s 197us/step - loss: 0.8513 - acc: 0.7646 - val_loss: 0.9919 - val_acc: 0.7225\n",
      "Epoch 6/10\n",
      "41414/41414 [==============================] - 6s 145us/step - loss: 0.7548 - acc: 0.7889 - val_loss: 0.9718 - val_acc: 0.7282\n",
      "Epoch 7/10\n",
      "41414/41414 [==============================] - 8s 192us/step - loss: 0.6757 - acc: 0.8087 - val_loss: 0.9724 - val_acc: 0.7353\n",
      "Epoch 8/10\n",
      "41414/41414 [==============================] - 7s 169us/step - loss: 0.6139 - acc: 0.8243 - val_loss: 0.9925 - val_acc: 0.7297\n",
      "Epoch 9/10\n",
      "41414/41414 [==============================] - 7s 180us/step - loss: 0.5576 - acc: 0.8406 - val_loss: 0.9835 - val_acc: 0.7275\n",
      "Epoch 10/10\n",
      "41414/41414 [==============================] - 8s 191us/step - loss: 0.5179 - acc: 0.8517 - val_loss: 0.9799 - val_acc: 0.7332\n",
      "['loss', 'acc']\n",
      "11536/11536 [==============================] - 1s 114us/step\n",
      "[1.0044298502674711, 0.7298890429958391]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'test_model_elmo_45.h5'\n",
    "VEC_SIZE = 1024 #elmo.dim\n",
    "\n",
    "model = construct_plain_model_sparse(plain_features.shape[1], VEC_SIZE, y_train.shape[1])\n",
    "model.summary()\n",
    "model.fit(select_from_nparray_list([e_args, e_verbs, plain_features], train_selector),\n",
    "          y_train, \n",
    "          epochs=10, batch_size=64, validation_split = 0.1, shuffle=True)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate(select_from_nparray_list([e_args, e_verbs, plain_features], test_selector), \n",
    "               y_test))\n",
    "#model.save(os.path.join(main_model_path, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "pred_embed (InputLayer)         (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "arg_embed (InputLayer)          (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_categorical (InputLayer)  (None, 10391)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 100)          30100       pred_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 100)          30100       arg_embed[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 400)          4156800     input_categorical[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 100)          400         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 100)          400         dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 400)          1600        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 100)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 100)          0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 400)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 600)          0           activation_16[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 600)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 400)          240400      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 400)          1600        dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 400)          0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400)          0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 45)           18045       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 45)           180         dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 45)           0           batch_normalization_19[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 4,479,625\n",
      "Trainable params: 4,477,535\n",
      "Non-trainable params: 2,090\n",
      "__________________________________________________________________________________________________\n",
      "Train on 41414 samples, validate on 4602 samples\n",
      "Epoch 1/15\n",
      "41414/41414 [==============================] - 3s 72us/step - loss: 2.6695 - acc: 0.3861 - val_loss: 3.1281 - val_acc: 0.4611\n",
      "Epoch 2/15\n",
      "41414/41414 [==============================] - 2s 44us/step - loss: 1.7488 - acc: 0.6157 - val_loss: 2.4234 - val_acc: 0.5750\n",
      "Epoch 3/15\n",
      "41414/41414 [==============================] - 2s 45us/step - loss: 1.3868 - acc: 0.6902 - val_loss: 1.7249 - val_acc: 0.6758\n",
      "Epoch 4/15\n",
      "41414/41414 [==============================] - 2s 44us/step - loss: 1.1662 - acc: 0.7340 - val_loss: 1.3323 - val_acc: 0.6908\n",
      "Epoch 5/15\n",
      "41414/41414 [==============================] - 2s 43us/step - loss: 0.9827 - acc: 0.7735 - val_loss: 1.1960 - val_acc: 0.7003\n",
      "Epoch 6/15\n",
      "41414/41414 [==============================] - 2s 45us/step - loss: 0.8610 - acc: 0.7968 - val_loss: 1.1236 - val_acc: 0.7021\n",
      "Epoch 7/15\n",
      "41414/41414 [==============================] - 2s 45us/step - loss: 0.7659 - acc: 0.8163 - val_loss: 1.0990 - val_acc: 0.7114\n",
      "Epoch 8/15\n",
      "41414/41414 [==============================] - 2s 43us/step - loss: 0.7026 - acc: 0.8288 - val_loss: 1.0752 - val_acc: 0.7103\n",
      "Epoch 9/15\n",
      "41414/41414 [==============================] - 2s 47us/step - loss: 0.6419 - acc: 0.8395 - val_loss: 1.0732 - val_acc: 0.7071\n",
      "Epoch 10/15\n",
      "41414/41414 [==============================] - 2s 44us/step - loss: 0.5990 - acc: 0.8476 - val_loss: 1.0681 - val_acc: 0.7095\n",
      "Epoch 11/15\n",
      "41414/41414 [==============================] - 2s 44us/step - loss: 0.5630 - acc: 0.8544 - val_loss: 1.1047 - val_acc: 0.6953\n",
      "Epoch 12/15\n",
      "41414/41414 [==============================] - 2s 46us/step - loss: 0.5386 - acc: 0.8597 - val_loss: 1.0533 - val_acc: 0.7119\n",
      "Epoch 13/15\n",
      "41414/41414 [==============================] - 2s 44us/step - loss: 0.5067 - acc: 0.8658 - val_loss: 1.0339 - val_acc: 0.7149\n",
      "Epoch 14/15\n",
      "41414/41414 [==============================] - 2s 46us/step - loss: 0.4865 - acc: 0.8713 - val_loss: 1.0474 - val_acc: 0.7093\n",
      "Epoch 15/15\n",
      "41414/41414 [==============================] - 2s 43us/step - loss: 0.4677 - acc: 0.8738 - val_loss: 1.0384 - val_acc: 0.7138\n",
      "['loss', 'acc']\n",
      "11536/11536 [==============================] - 1s 82us/step\n",
      "[1.0573356527726627, 0.7100381414701803]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'test_model_w2v.h5'\n",
    "VEC_SIZE = arg_embedded.shape[1]\n",
    "\n",
    "model = construct_plain_model_sparse(plain_features.shape[1], VEC_SIZE, y_train.shape[1])\n",
    "model.summary()\n",
    "model.fit(select_from_nparray_list([arg_embedded, pred_embedded, plain_features], train_selector),\n",
    "          y_train, \n",
    "          epochs=15, batch_size=300, validation_split = 0.1, shuffle=True)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate(select_from_nparray_list([arg_embedded, pred_embedded, plain_features], test_selector), \n",
    "               y_test))\n",
    "model.save(os.path.join(main_model_path, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate latex table with per-role performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map roles as given in https://github.com/olesar/framebank/blob/master/framebank_roles_ru_eng.md "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab = {\n",
    "    'avg': 'avg',\n",
    "    'non_rel': 'non_rel',\n",
    "    'предмет мысли': 'topic of thought',\n",
    "    'результат': 'result',\n",
    "    'потенциальная угроза': 'potential threat',\n",
    "    'контрагент': 'counteragent',\n",
    "    'агенс': 'agent',\n",
    "    'каузатор': 'causer',\n",
    "    'пациенс': 'patient',\n",
    "    'ситуация в фокусе': 'situation in focus',\n",
    "    'конечный посессор': 'recipient',\n",
    "    'тема': 'theme',\n",
    "    'эффектор': 'effector',\n",
    "    'способ': 'manner',\n",
    "    'сфера': 'field',\n",
    "    'траектория': 'path',\n",
    "    'цель': 'goal',\n",
    "    'признак': 'attribute',\n",
    "    'субъект социального отношения': 'subject of social attitude',\n",
    "    'пациенс социального отношения': 'patient of social attitude',\n",
    "    'субъект поведения': 'behaver',\n",
    "    'статус': 'status',\n",
    "    'исходный посессор': 'initial possessor',\n",
    "    'контрагент социального отношения': 'counteragent of social attitude',\n",
    "    'потенциальный пациенс': 'potential patient',\n",
    "    'пациенс перемещения': 'patient of motion',\n",
    "    'содержание мысли': 'content of thought',\n",
    "    'содержание действия': 'content of action',\n",
    "    'субъект ментального состояния': 'cognizer',\n",
    "    'стимул': 'stimulus',\n",
    "    'признак действия': 'attribute of action',\n",
    "    'эталон': 'standard',\n",
    "    'субъект психологического состояния': 'sbj of psychol. state',\n",
    "    'срок': 'term',\n",
    "    'субъект перемещения': 'goer',\n",
    "    'говорящий': 'speaker',\n",
    "    'конечная точка': 'final destination',\n",
    "    'причина': 'cause',\n",
    "    'источник звука': 'source of sound',\n",
    "    'предмет высказывания': 'topic of speech',\n",
    "    'адресат': 'addressee',\n",
    "    'место': 'location',\n",
    "    'субъект восприятия': 'perceiver',\n",
    "    'субъект физиологической реакции': 'sbj of physiol. reaction',\n",
    "    'начальная точка': 'initial point',\n",
    "    'содержание высказывания': 'content of speech'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numbers of examples per each role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles_counts = dict(pd_data.loc[:, 'role'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate report table with sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(select_from_nparray_list([e_args, e_verbs, plain_features], test_selector))\n",
    "report = classification_report(label_encoder.inverse_transform(y_test), label_encoder.inverse_transform(y_pred), digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91380686"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0].max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non_rel', 'агенс', 'адресат', 'говорящий', 'источник звука',\n",
       "       'исходный посессор', 'каузатор', 'конечная точка',\n",
       "       'конечный посессор', 'контрагент',\n",
       "       'контрагент социального отношения', 'место', 'начальная точка',\n",
       "       'пациенс', 'пациенс перемещения', 'пациенс социального отношения',\n",
       "       'потенциальная угроза', 'потенциальный пациенс',\n",
       "       'предмет высказывания', 'предмет мысли', 'признак',\n",
       "       'признак действия', 'причина', 'результат', 'ситуация в фокусе',\n",
       "       'содержание высказывания', 'содержание действия',\n",
       "       'содержание мысли', 'способ', 'срок', 'статус', 'стимул',\n",
       "       'субъект восприятия', 'субъект ментального состояния',\n",
       "       'субъект перемещения', 'субъект поведения',\n",
       "       'субъект психологического состояния',\n",
       "       'субъект социального отношения', 'субъект физиологической реакции',\n",
       "       'сфера', 'тема', 'траектория', 'цель', 'эталон', 'эффектор'],\n",
       "      dtype='<U34')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label_encoder.inverse_transform(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate latex table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{l|c|c|c}\n",
      "\\hline\n",
      "\\bf Class & \\bf Precision & \\bf Recall & \\bf F-score \\\\\n",
      "\\hline\n",
      "agent (10.7\\%) & 73.7 & 73.6 & 73.7\\\\\n",
      "patient (9.3\\%) & 62.2 & 75.9 & 68.3\\\\\n",
      "non_rel (8.3\\%) & 56.1 & 55.4 & 55.7\\\\\n",
      "theme (6.4\\%) & 68.5 & 72.4 & 70.4\\\\\n",
      "sbj of psychol. state (5.6\\%) & 86.4 & 86.0 & 86.2\\\\\n",
      "goer (5.2\\%) & 81.5 & 82.0 & 81.7\\\\\n",
      "cause (4.3\\%) & 75.0 & 84.2 & 79.3\\\\\n",
      "speaker (4.1\\%) & 81.0 & 78.6 & 79.8\\\\\n",
      "location (3.8\\%) & 72.9 & 70.6 & 71.7\\\\\n",
      "content of action (3.3\\%) & 75.6 & 67.5 & 71.3\\\\\n",
      "content of thought (3.2\\%) & 66.8 & 72.4 & 69.5\\\\\n",
      "content of speech (3.1\\%) & 73.2 & 68.5 & 70.8\\\\\n",
      "final destination (3.1\\%) & 69.2 & 85.9 & 76.6\\\\\n",
      "result (2.5\\%) & 66.3 & 68.3 & 67.3\\\\\n",
      "patient of motion (2.4\\%) & 68.0 & 62.9 & 65.4\\\\\n",
      "stimulus (2.2\\%) & 73.9 & 69.9 & 71.8\\\\\n",
      "cognizer (2.1\\%) & 77.8 & 65.5 & 71.1\\\\\n",
      "addressee (1.6\\%) & 75.0 & 71.0 & 72.9\\\\\n",
      "perceiver (1.6\\%) & 81.0 & 82.3 & 81.7\\\\\n",
      "counteragent (1.4\\%) & 66.9 & 66.9 & 66.9\\\\\n",
      "effector (1.3\\%) & 47.8 & 44.6 & 46.2\\\\\n",
      "subject of social attitude (1.0\\%) & 72.4 & 66.7 & 69.4\\\\\n",
      "initial point (1.0\\%) & 73.6 & 71.4 & 72.5\\\\\n",
      "topic of speech (1.0\\%) & 79.3 & 75.2 & 77.2\\\\\n",
      "manner (0.9\\%) & 49.3 & 35.7 & 41.4\\\\\n",
      "recipient (0.9\\%) & 66.3 & 61.9 & 64.0\\\\\n",
      "goal (0.8\\%) & 79.3 & 70.4 & 74.6\\\\\n",
      "field (0.7\\%) & 54.7 & 42.0 & 47.5\\\\\n",
      "attribute (0.6\\%) & 81.6 & 50.6 & 62.5\\\\\n",
      "source of sound (0.6\\%) & 79.0 & 69.2 & 73.8\\\\\n",
      "behaver (0.6\\%) & 84.8 & 52.0 & 64.5\\\\\n",
      "situation in focus (0.6\\%) & 73.7 & 43.1 & 54.4\\\\\n",
      "counteragent of social attitude (0.6\\%) & 73.8 & 67.2 & 70.3\\\\\n",
      "sbj of physiol. reaction (0.5\\%) & 85.7 & 77.1 & 81.2\\\\\n",
      "topic of thought (0.5\\%) & 87.5 & 53.8 & 66.7\\\\\n",
      "potential patient (0.5\\%) & 58.7 & 74.6 & 65.7\\\\\n",
      "status (0.5\\%) & 70.4 & 38.8 & 50.0\\\\\n",
      "patient of social attitude (0.5\\%) & 63.3 & 32.2 & 42.7\\\\\n",
      "term (0.4\\%) & 85.2 & 83.6 & 84.4\\\\\n",
      "standard (0.4\\%) & 82.3 & 79.2 & 80.8\\\\\n",
      "attribute of action (0.4\\%) & 77.8 & 67.3 & 72.2\\\\\n",
      "causer (0.4\\%) & 77.3 & 34.0 & 47.2\\\\\n",
      "initial possessor (0.4\\%) & 58.7 & 58.7 & 58.7\\\\\n",
      "potential threat (0.3\\%) & 66.0 & 73.8 & 69.7\\\\\n",
      "path (0.3\\%) & 57.6 & 59.4 & 58.5\\\\\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "def parse_classification_report(clfreport):\n",
    "    \"\"\"\n",
    "    Parse a sklearn classification report into a dict keyed by class name\n",
    "    and containing a tuple (precision, recall, fscore, support) for each class\n",
    "    \"\"\"\n",
    "    lines = clfreport.split('\\n')\n",
    "    # Remove empty lines\n",
    "    lines = list(filter(lambda l: not len(l.strip()) == 0, lines))\n",
    "\n",
    "    # Starts with a header, then score for each class and finally an average\n",
    "    header = lines[0]\n",
    "    cls_lines = lines[1:-3]\n",
    "    avg_line = lines[-1]\n",
    "    #print(avg_line)\n",
    "\n",
    "    assert header.split() == ['precision', 'recall', 'f1-score', 'support']\n",
    "    #assert avg_line.split()[1] == 'avg'\n",
    "\n",
    "    # We cannot simply use split because class names can have spaces. So instead\n",
    "    # figure the width of the class field by looking at the indentation of the\n",
    "    # precision header\n",
    "    cls_field_width = len(header) - len(header.lstrip())\n",
    "    # Now, collect all the class names and score in a dict\n",
    "    def parse_line(l):\n",
    "        \"\"\"Parse a line of classification_report\"\"\"\n",
    "        cls_name = l[:cls_field_width].strip() \n",
    "        precision, recall, fscore, support = l[cls_field_width:].split()\n",
    "        precision = float(precision)\n",
    "        recall = float(recall)\n",
    "        fscore = float(fscore)\n",
    "        support = roles_counts[cls_name]/len(pd_data)\n",
    "        return (cls_name, precision, recall, fscore, support)\n",
    "\n",
    "    data = collections.OrderedDict()\n",
    "    for l in cls_lines:\n",
    "        ret = parse_line(l)\n",
    "        cls_name = ret[0]\n",
    "        scores = [score * 100. for score in ret[1:]]\n",
    "        data[cls_name] = scores\n",
    "        #print(f'data[{cls_name}] = {scores}')\n",
    "    \n",
    "    # Apply sort by column\n",
    "    # Column#2 - F1, Column#3 - quantity\n",
    "    listofTuples = sorted(data.items(), key=lambda x: x[1][-1], reverse=True)\n",
    "    _data = collections.OrderedDict()\n",
    " \n",
    "    for elem in listofTuples:\n",
    "        if elem[0] != 'avg':\n",
    "            _data[elem[0]] = elem[1]\n",
    "\n",
    "    # average\n",
    "    # data['avg'] = parse_line(avg_line)[1:]\n",
    "\n",
    "    return _data\n",
    "\n",
    "def report_to_latex_table(data, percentage=True):\n",
    "    out = \"\"\n",
    "    out += \"\\\\begin{tabular}{l|c|c|c}\\n\"\n",
    "    out += \"\\hline\\n\"\n",
    "    out += \"\\\\bf Class & \\\\bf Precision & \\\\bf Recall & \\\\bf F-score \\\\\\\\\\n\"\n",
    "    out += \"\\hline\\n\"\n",
    "    for cls, scores in data.items():\n",
    "        scores = scores[:-1]\n",
    "        if percentage:\n",
    "            out += en_vocab[cls] + f\" ({round(roles_counts[cls]/len(pd_data)*100, 1)}\\%)\" + \" & \" + \" & \".join([str(round(s, 1)) for s in scores])\n",
    "        else:\n",
    "            out += en_vocab[cls] + \" & \" + \" & \".join([str(round(s, 1)) for s in scores])\n",
    "        out += \"\\\\\\\\\\n\"\n",
    "    out += \"\\\\end{tabular}\"\n",
    "    return out\n",
    "\n",
    "data = parse_classification_report(report)\n",
    "print(report_to_latex_table(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
