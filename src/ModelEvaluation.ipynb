{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from training_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(file=\"../data/labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_features = np.load(file=\"../data/plain_features.npy\")\n",
    "verb_embed = np.load(file=\"../data/verb_embedded.npy\")\n",
    "arg_embed = np.load(file=\"../data/arg_embedded.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_factory = SimpleModelFactory(942)\n",
    "sparse_factory = SparseModelFactory([942, 300, 300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_126 (Dense)            (None, 600)               565800    \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_126 ( (None, 600)               2400      \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_127 ( (None, 400)               1600      \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 34)                13634     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_128 ( (None, 34)                136       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 34)                0         \n",
      "=================================================================\n",
      "Total params: 823,970\n",
      "Trainable params: 821,902\n",
      "Non-trainable params: 2,068\n",
      "_________________________________________________________________\n",
      "Running Fold 1 / 5\n",
      "6075/6075 [==============================] - 0s 78us/sample - loss: 0.8768 - accuracy: 0.7631\n",
      "\n",
      "Fold result:  [0.8768366976726202, 0.76312757, 0.7631275720164609, 0.745737765246007, 0.7631275720164609]\n",
      "Running Fold 2 / 5\n",
      "6074/6074 [==============================] - 1s 97us/sample - loss: 0.8164 - accuracy: 0.7728\n",
      "\n",
      "Fold result:  [0.8164145145755399, 0.7728021, 0.7728021073427725, 0.7518810973725653, 0.7728021073427724]\n",
      "Running Fold 3 / 5\n",
      "6074/6074 [==============================] - 0s 77us/sample - loss: 0.8455 - accuracy: 0.7764\n",
      "\n",
      "Fold result:  [0.8455080464555905, 0.7764241, 0.77642410273296, 0.7430824856897242, 0.7764241027329601]\n",
      "Running Fold 4 / 5\n",
      "6074/6074 [==============================] - 1s 83us/sample - loss: 0.8319 - accuracy: 0.7642\n",
      "\n",
      "Fold result:  [0.8318588136350947, 0.76424104, 0.7642410273296015, 0.7368297435771297, 0.7642410273296015]\n",
      "Running Fold 5 / 5\n",
      "6074/6074 [==============================] - 1s 83us/sample - loss: 0.8740 - accuracy: 0.7680\n",
      "\n",
      "Fold result:  [0.8740035915280551, 0.76802766, 0.7680276588738887, 0.7438744111848196, 0.7680276588738887]\n",
      "[[0.8768367  0.76312757 0.76312757 0.74573777 0.76312757]\n",
      " [0.81641451 0.77280211 0.77280211 0.7518811  0.77280211]\n",
      " [0.84550805 0.77642411 0.7764241  0.74308249 0.7764241 ]\n",
      " [0.83185881 0.76424104 0.76424103 0.73682974 0.76424103]\n",
      " [0.87400359 0.76802766 0.76802766 0.74387441 0.76802766]]\n",
      "Mean\n",
      "       loss  keras_accur  micro_f1  macro_f1     accur\n",
      "0  0.848924     0.768924  0.768924  0.744281  0.768924\n",
      "Std\n",
      "       loss  keras_accur  micro_f1  macro_f1     accur\n",
      "0  0.023528     0.005052  0.005052  0.004837  0.005052\n"
     ]
    }
   ],
   "source": [
    "cv_res_simple = custom_cross_val(simple_factory.create_and_compile, [plain_features], labels, cv=DEFAULT_CV, epochs=13, batch_size=64, validation_split = 0., shuffle=True, verbose = 0)\n",
    "describe_cv_result(cv_res_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input-predicate-embeddings (Inp [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input-argument-embeddings (Inpu [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input-categorical (InputLayer)  [(None, 942)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_145 (Dense)               (None, 100)          30100       input-predicate-embeddings[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_146 (Dense)               (None, 100)          30100       input-argument-embeddings[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_144 (Dense)               (None, 400)          377200      input-categorical[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_145 (Bat (None, 100)          400         dense_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_146 (Bat (None, 100)          400         dense_146[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_144 (Bat (None, 400)          1600        dense_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 100)          0           batch_normalization_v2_145[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 100)          0           batch_normalization_v2_146[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 400)          0           batch_normalization_v2_144[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 600)          0           activation_127[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "                                                                 activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 600)          0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_147 (Dense)               (None, 400)          240400      dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_147 (Bat (None, 400)          1600        dense_147[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 400)          0           batch_normalization_v2_147[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 400)          0           activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_148 (Dense)               (None, 34)           13634       dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_148 (Bat (None, 34)           136         dense_148[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 34)           0           batch_normalization_v2_148[0][0] \n",
      "==================================================================================================\n",
      "Total params: 695,570\n",
      "Trainable params: 693,502\n",
      "Non-trainable params: 2,068\n",
      "__________________________________________________________________________________________________\n",
      "Running Fold 1 / 5\n",
      "6075/6075 [==============================] - 1s 95us/sample - loss: 0.7712 - accuracy: 0.7858\n",
      "\n",
      "Fold result:  [0.7712049133983659, 0.7858436, 0.7858436213991771, 0.7665723276770372, 0.785843621399177]\n",
      "Running Fold 2 / 5\n",
      "6074/6074 [==============================] - 1s 91us/sample - loss: 0.7114 - accuracy: 0.8044\n",
      "\n",
      "Fold result:  [0.7113669765674641, 0.80441225, 0.804412248929865, 0.7851218467067324, 0.804412248929865]\n",
      "Running Fold 3 / 5\n",
      "6074/6074 [==============================] - 1s 93us/sample - loss: 0.7329 - accuracy: 0.8018\n",
      "\n",
      "Fold result:  [0.7329480691807106, 0.8017781, 0.801778070464274, 0.7725206900858749, 0.801778070464274]\n",
      "Running Fold 4 / 5\n",
      "6074/6074 [==============================] - 1s 93us/sample - loss: 0.7491 - accuracy: 0.7955\n",
      "\n",
      "Fold result:  [0.7490799977055576, 0.7955219, 0.7955218966084951, 0.7702690390376327, 0.7955218966084953]\n",
      "Running Fold 5 / 5\n",
      "6074/6074 [==============================] - 1s 90us/sample - loss: 0.7664 - accuracy: 0.7939\n",
      "\n",
      "Fold result:  [0.7663900830614594, 0.7938755, 0.7938755350675009, 0.774701729564626, 0.7938755350675009]\n",
      "[[0.8768367  0.76312757 0.76312757 0.74573777 0.76312757]\n",
      " [0.81641451 0.77280211 0.77280211 0.7518811  0.77280211]\n",
      " [0.84550805 0.77642411 0.7764241  0.74308249 0.7764241 ]\n",
      " [0.83185881 0.76424104 0.76424103 0.73682974 0.76424103]\n",
      " [0.87400359 0.76802766 0.76802766 0.74387441 0.76802766]]\n",
      "Mean\n",
      "       loss  keras_accur  micro_f1  macro_f1     accur\n",
      "0  0.848924     0.768924  0.768924  0.744281  0.768924\n",
      "Std\n",
      "       loss  keras_accur  micro_f1  macro_f1     accur\n",
      "0  0.023528     0.005052  0.005052  0.004837  0.005052\n"
     ]
    }
   ],
   "source": [
    "cv_res_sparse = custom_cross_val(sparse_factory.create_and_compile, [plain_features, verb_embed, arg_embed], labels, cv=DEFAULT_CV, epochs=13, batch_size=300, validation_split = 0., shuffle=True, verbose = 0)\n",
    "describe_cv_result(cv_res_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
