{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:14:55.909843",
     "start_time": "2017-02-18T12:14:54.905927"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use only one GPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../isanlp/src/')\n",
    "sys.path.append('../../src/isanlp_srl_framebank/')\n",
    "sys.path.append('../../libs/')\n",
    "sys.path.append('../../libs/pylingtools/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Supress tensorflow memory appetites\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.log_device_placement=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0516 08:00:38.633061 139896968771328 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.models.embedders.elmo_embedder import ELMoEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:14:56.607418",
     "start_time": "2017-02-18T12:14:55.911842"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0', '/device:GPU:1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check available GPUs\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 18336177674727777836, name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 10953945507323820453\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 1494602712782881369\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5534449664\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 17497484290762556171\n",
       " physical_device_desc: \"device: 0, name: Tesla K20Xm, pci bus id: 0000:03:00.0, compute capability: 3.5\", name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 3224567808\n",
       " locality {\n",
       "   bus_id: 2\n",
       "   numa_node: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 7068813728541990903\n",
       " physical_device_desc: \"device: 1, name: Tesla K20Xm, pci bus id: 0000:84:00.0, compute capability: 3.5\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import isanlp\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(31)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_corpus_path = '../../data/cleared_corpus.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cleared_corpus_path, 'r') as f:\n",
    "    examples = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_data_path = '../../data/results_final_fixed.pckl'\n",
    "with open(ling_data_path, 'rb') as f:\n",
    "    ling_data = pickle.load(f)\n",
    "\n",
    "ling_data_cache = {k: v for k,v in ling_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_examples = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp.annotation_repr import CSentence\n",
    "from convert_corpus_to_brat import make_text\n",
    "\n",
    "\n",
    "def find_address_by_offset(offset, ling_ann):\n",
    "    for tok_num, tok in enumerate(ling_ann['tokens']):\n",
    "        if tok.begin <= offset and offset < tok.end:\n",
    "            break\n",
    "    \n",
    "    for sent_num, sent in enumerate(ling_ann['sentences']):\n",
    "        if sent.begin <= tok_num and tok_num < sent.end:\n",
    "            break\n",
    "    \n",
    "    return sent_num, tok_num - sent.begin\n",
    "\n",
    "\n",
    "def process_arg_pred(feature_extractor, ling_cache, ex_id, pred, args, example):\n",
    "    feature_sets = list()\n",
    "    \n",
    "    text, offset_index = make_text(example, 0)\n",
    "    ling_ann = ling_cache[ex_id]\n",
    "    \n",
    "    pred_offset = offset_index[(pred[0], pred[1])]\n",
    "    pred_ling_sent, pred_ling_word = find_address_by_offset(pred_offset, ling_ann)\n",
    "    \n",
    "    for arg in args:\n",
    "        arg_offset = offset_index[(arg[0], arg[1])]\n",
    "        arg_ling_sent, arg_ling_word = find_address_by_offset(arg_offset, ling_ann)\n",
    "        \n",
    "        fb_pred_word = example[pred[0]][pred[1]]\n",
    "        fb_arg_word = example[arg[0]][arg[1]]\n",
    "        \n",
    "        role = fb_arg_word['rolepred1']\n",
    "\n",
    "        if arg_ling_sent != pred_ling_sent:\n",
    "            global num_of_errors\n",
    "            num_of_errors += 1\n",
    "            # We miss some examples due to mistakes in framebank or discrepancy in \n",
    "            # automatica annotation of sentences.\n",
    "            print('Error #{}'.format(num_of_errors))\n",
    "            continue\n",
    "        features = feature_extractor.extract_features(pred_ling_word, \n",
    "                                                      arg_ling_word, \n",
    "                                                      ling_ann['postag'][arg_ling_sent],\n",
    "                                                      ling_ann['morph'][arg_ling_sent],\n",
    "                                                      ling_ann['lemma'][arg_ling_sent],\n",
    "                                                      ling_ann['syntax_dep_tree'][arg_ling_sent])\n",
    "\n",
    "                    \n",
    "        feature_sets.append((features, role, ex_id, [tok.text for tok in ling_ann['tokens']], arg, pred, offset_index))\n",
    "    \n",
    "    return feature_sets\n",
    "\n",
    "\n",
    "def process_example(feature_extractor, ling_cache, ex_id, sentences):\n",
    "    pred = None\n",
    "    args = list()\n",
    "    for sent_num, sent in enumerate(sentences):\n",
    "        for word_num, word in enumerate(sent):\n",
    "            if 'rank' in word and word['rank'] == 'Предикат':\n",
    "                pred = (sent_num, word_num)\n",
    "            elif 'rolepred1' in word:\n",
    "                args.append((sent_num, word_num))\n",
    "    \n",
    "    return process_arg_pred(feature_extractor, ling_cache, ex_id, pred, args, sentences)\n",
    "\n",
    "\n",
    "num_of_errors = 0\n",
    "def prepare_train_data(examples, ling_data_cache, feature_extractor):\n",
    "    feature_sets = []\n",
    "    for ex_num, (ex_id, ex) in enumerate(examples):    \n",
    "        if ex_num % 100 == 0:\n",
    "            print('{0:.2f}%'.format((ex_num / len(examples)) * 100.))\n",
    "            \n",
    "        feature_sets += process_example(feature_extractor, ling_data_cache, ex_id, ex)\n",
    "\n",
    "    print('Number of training examples:', len(feature_sets))\n",
    "    return feature_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model_path_root = '../../data/models_new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!: Choose feature model here\n",
    "from isanlp_srl_framebank.processor_srl_framebank import FeatureModelDefault\n",
    "feature_model = FeatureModelDefault()\n",
    "main_model_path = os.path.join(main_model_path_root, 'known_preds')\n",
    "\n",
    "# from isanlp_srl_framebank.processor_srl_framebank import FeatureModelUnknownPredicates\n",
    "# feature_model = FeatureModelUnknownPredicates()\n",
    "# main_model_path = os.path.join(main_model_path_root, 'unknown_preds')\n",
    "\n",
    "#with open(os.path.join(main_model_path, 'feature_model.pckl'), 'wb') as f:\n",
    "#    pickle.dump(feature_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n",
      "Error #415\n",
      "0.31%\n",
      "Error #416\n",
      "0.61%\n",
      "0.92%\n",
      "1.23%\n",
      "1.53%\n",
      "1.84%\n",
      "2.15%\n",
      "Error #417\n",
      "2.45%\n",
      "2.76%\n",
      "3.07%\n",
      "3.37%\n",
      "3.68%\n",
      "3.99%\n",
      "4.29%\n",
      "4.60%\n",
      "4.91%\n",
      "Error #418\n",
      "Error #419\n",
      "5.21%\n",
      "5.52%\n",
      "5.83%\n",
      "Error #420\n",
      "Error #421\n",
      "Error #422\n",
      "Error #423\n",
      "Error #424\n",
      "Error #425\n",
      "Error #426\n",
      "Error #427\n",
      "Error #428\n",
      "Error #429\n",
      "Error #430\n",
      "Error #431\n",
      "Error #432\n",
      "Error #433\n",
      "Error #434\n",
      "Error #435\n",
      "Error #436\n",
      "Error #437\n",
      "Error #438\n",
      "Error #439\n",
      "Error #440\n",
      "Error #441\n",
      "Error #442\n",
      "Error #443\n",
      "Error #444\n",
      "Error #445\n",
      "Error #446\n",
      "Error #447\n",
      "Error #448\n",
      "6.13%\n",
      "Error #449\n",
      "Error #450\n",
      "Error #451\n",
      "Error #452\n",
      "Error #453\n",
      "Error #454\n",
      "Error #455\n",
      "Error #456\n",
      "Error #457\n",
      "Error #458\n",
      "Error #459\n",
      "Error #460\n",
      "Error #461\n",
      "Error #462\n",
      "Error #463\n",
      "Error #464\n",
      "Error #465\n",
      "Error #466\n",
      "Error #467\n",
      "Error #468\n",
      "Error #469\n",
      "Error #470\n",
      "Error #471\n",
      "Error #472\n",
      "Error #473\n",
      "Error #474\n",
      "Error #475\n",
      "Error #476\n",
      "Error #477\n",
      "Error #478\n",
      "Error #479\n",
      "Error #480\n",
      "Error #481\n",
      "Error #482\n",
      "Error #483\n",
      "Error #484\n",
      "Error #485\n",
      "Error #486\n",
      "Error #487\n",
      "Error #488\n",
      "Error #489\n",
      "Error #490\n",
      "Error #491\n",
      "Error #492\n",
      "Error #493\n",
      "Error #494\n",
      "Error #495\n",
      "Error #496\n",
      "Error #497\n",
      "Error #498\n",
      "Error #499\n",
      "Error #500\n",
      "Error #501\n",
      "Error #502\n",
      "Error #503\n",
      "Error #504\n",
      "Error #505\n",
      "Error #506\n",
      "Error #507\n",
      "Error #508\n",
      "Error #509\n",
      "Error #510\n",
      "Error #511\n",
      "Error #512\n",
      "Error #513\n",
      "Error #514\n",
      "Error #515\n",
      "6.44%\n",
      "Error #516\n",
      "6.75%\n",
      "Error #517\n",
      "7.05%\n",
      "Error #518\n",
      "7.36%\n",
      "7.67%\n",
      "Error #519\n",
      "7.97%\n",
      "8.28%\n",
      "8.59%\n",
      "Error #520\n",
      "Error #521\n",
      "8.89%\n",
      "9.20%\n",
      "9.51%\n",
      "Error #522\n",
      "9.81%\n",
      "Error #523\n",
      "10.12%\n",
      "10.43%\n",
      "Error #524\n",
      "10.73%\n",
      "Error #525\n",
      "11.04%\n",
      "Error #526\n",
      "11.35%\n",
      "11.65%\n",
      "11.96%\n",
      "12.27%\n",
      "Error #527\n",
      "Error #528\n",
      "Error #529\n",
      "12.57%\n",
      "Error #530\n",
      "12.88%\n",
      "Error #531\n",
      "13.19%\n",
      "Error #532\n",
      "Error #533\n",
      "13.49%\n",
      "Error #534\n",
      "13.80%\n",
      "Error #535\n",
      "14.11%\n",
      "Error #536\n",
      "Error #537\n",
      "Error #538\n",
      "Error #539\n",
      "Error #540\n",
      "Error #541\n",
      "Error #542\n",
      "Error #543\n",
      "Error #544\n",
      "Error #545\n",
      "Error #546\n",
      "Error #547\n",
      "14.41%\n",
      "Error #548\n",
      "Error #549\n",
      "14.72%\n",
      "15.03%\n",
      "15.33%\n",
      "15.64%\n",
      "Error #550\n",
      "Error #551\n",
      "15.95%\n",
      "Error #552\n",
      "Error #553\n",
      "Error #554\n",
      "16.25%\n",
      "Error #555\n",
      "16.56%\n",
      "Error #556\n",
      "16.86%\n",
      "17.17%\n",
      "Error #557\n",
      "17.48%\n",
      "17.78%\n",
      "Error #558\n",
      "18.09%\n",
      "Error #559\n",
      "Error #560\n",
      "Error #561\n",
      "Error #562\n",
      "18.40%\n",
      "18.70%\n",
      "19.01%\n",
      "19.32%\n",
      "19.62%\n",
      "Error #563\n",
      "Error #564\n",
      "Error #565\n",
      "Error #566\n",
      "Error #567\n",
      "Error #568\n",
      "19.93%\n",
      "Error #569\n",
      "Error #570\n",
      "20.24%\n",
      "20.54%\n",
      "20.85%\n",
      "Error #571\n",
      "Error #572\n",
      "21.16%\n",
      "Error #573\n",
      "21.46%\n",
      "21.77%\n",
      "22.08%\n",
      "22.38%\n",
      "22.69%\n",
      "Error #574\n",
      "23.00%\n",
      "23.30%\n",
      "Error #575\n",
      "Error #576\n",
      "23.61%\n",
      "23.92%\n",
      "Error #577\n",
      "Error #578\n",
      "24.22%\n",
      "Error #579\n",
      "24.53%\n",
      "24.84%\n",
      "25.14%\n",
      "25.45%\n",
      "25.76%\n",
      "26.06%\n",
      "26.37%\n",
      "Error #580\n",
      "Error #581\n",
      "26.68%\n",
      "Error #582\n",
      "26.98%\n",
      "Error #583\n",
      "27.29%\n",
      "27.60%\n",
      "27.90%\n",
      "Error #584\n",
      "Error #585\n",
      "Error #586\n",
      "Error #587\n",
      "Error #588\n",
      "Error #589\n",
      "Error #590\n",
      "Error #591\n",
      "28.21%\n",
      "28.52%\n",
      "28.82%\n",
      "Error #592\n",
      "29.13%\n",
      "Error #593\n",
      "29.44%\n",
      "29.74%\n",
      "30.05%\n",
      "Error #594\n",
      "Error #595\n",
      "Error #596\n",
      "Error #597\n",
      "30.36%\n",
      "Error #598\n",
      "Error #599\n",
      "30.66%\n",
      "Error #600\n",
      "30.97%\n",
      "31.28%\n",
      "Error #601\n",
      "31.58%\n",
      "31.89%\n",
      "32.20%\n",
      "Error #602\n",
      "32.50%\n",
      "Error #603\n",
      "Error #604\n",
      "Error #605\n",
      "Error #606\n",
      "Error #607\n",
      "Error #608\n",
      "Error #609\n",
      "Error #610\n",
      "Error #611\n",
      "32.81%\n",
      "Error #612\n",
      "Error #613\n",
      "Error #614\n",
      "Error #615\n",
      "Error #616\n",
      "33.12%\n",
      "Error #617\n",
      "33.42%\n",
      "Error #618\n",
      "Error #619\n",
      "33.73%\n",
      "34.04%\n",
      "34.34%\n",
      "34.65%\n",
      "34.96%\n",
      "35.26%\n",
      "35.57%\n",
      "35.88%\n",
      "36.18%\n",
      "36.49%\n",
      "Error #620\n",
      "Error #621\n",
      "36.80%\n",
      "37.10%\n",
      "Error #622\n",
      "Error #623\n",
      "37.41%\n",
      "37.72%\n",
      "38.02%\n",
      "38.33%\n",
      "38.64%\n",
      "38.94%\n",
      "Error #624\n",
      "Error #625\n",
      "Error #626\n",
      "Error #627\n",
      "39.25%\n",
      "Error #628\n",
      "39.56%\n",
      "39.86%\n",
      "Error #629\n",
      "40.17%\n",
      "40.48%\n",
      "Error #630\n",
      "Error #631\n",
      "Error #632\n",
      "Error #633\n",
      "Error #634\n",
      "40.78%\n",
      "41.09%\n",
      "Error #635\n",
      "41.40%\n",
      "41.70%\n",
      "42.01%\n",
      "42.32%\n",
      "Error #636\n",
      "42.62%\n",
      "42.93%\n",
      "43.24%\n",
      "Error #637\n",
      "43.54%\n",
      "43.85%\n",
      "Error #638\n",
      "Error #639\n",
      "44.16%\n",
      "Error #640\n",
      "Error #641\n",
      "Error #642\n",
      "44.46%\n",
      "44.77%\n",
      "45.08%\n",
      "45.38%\n",
      "Error #643\n",
      "Error #644\n",
      "Error #645\n",
      "45.69%\n",
      "46.00%\n",
      "46.30%\n",
      "46.61%\n",
      "Error #646\n",
      "46.92%\n",
      "Error #647\n",
      "47.22%\n",
      "47.53%\n",
      "Error #648\n",
      "Error #649\n",
      "Error #650\n",
      "Error #651\n",
      "Error #652\n",
      "Error #653\n",
      "Error #654\n",
      "Error #655\n",
      "47.84%\n",
      "Error #656\n",
      "48.14%\n",
      "Error #657\n",
      "Error #658\n",
      "48.45%\n",
      "Error #659\n",
      "Error #660\n",
      "48.76%\n",
      "Error #661\n",
      "49.06%\n",
      "Error #662\n",
      "49.37%\n",
      "49.67%\n",
      "Error #663\n",
      "49.98%\n",
      "Error #664\n",
      "50.29%\n",
      "50.59%\n",
      "50.90%\n",
      "Error #665\n",
      "Error #666\n",
      "Error #667\n",
      "Error #668\n",
      "51.21%\n",
      "51.51%\n",
      "51.82%\n",
      "Error #669\n",
      "52.13%\n",
      "Error #670\n",
      "Error #671\n",
      "52.43%\n",
      "Error #672\n",
      "52.74%\n",
      "53.05%\n",
      "Error #673\n",
      "53.35%\n",
      "Error #674\n",
      "53.66%\n",
      "53.97%\n",
      "Error #675\n",
      "54.27%\n",
      "54.58%\n",
      "Error #676\n",
      "54.89%\n",
      "55.19%\n",
      "Error #677\n",
      "55.50%\n",
      "Error #678\n",
      "55.81%\n",
      "56.11%\n",
      "Error #679\n",
      "56.42%\n",
      "Error #680\n",
      "56.73%\n",
      "57.03%\n",
      "Error #681\n",
      "57.34%\n",
      "57.65%\n",
      "Error #682\n",
      "Error #683\n",
      "Error #684\n",
      "Error #685\n",
      "Error #686\n",
      "Error #687\n",
      "Error #688\n",
      "57.95%\n",
      "58.26%\n",
      "58.57%\n",
      "58.87%\n",
      "59.18%\n",
      "Error #689\n",
      "59.49%\n",
      "Error #690\n",
      "59.79%\n",
      "60.10%\n",
      "Error #691\n",
      "60.41%\n",
      "Error #692\n",
      "60.71%\n",
      "Error #693\n",
      "61.02%\n",
      "61.33%\n",
      "Error #694\n",
      "61.63%\n",
      "Error #695\n",
      "61.94%\n",
      "Error #696\n",
      "Error #697\n",
      "Error #698\n",
      "62.25%\n",
      "62.55%\n",
      "62.86%\n",
      "Error #699\n",
      "Error #700\n",
      "63.17%\n",
      "63.47%\n",
      "63.78%\n",
      "64.09%\n",
      "Error #701\n",
      "64.39%\n",
      "64.70%\n",
      "65.01%\n",
      "Error #702\n",
      "Error #703\n",
      "65.31%\n",
      "65.62%\n",
      "65.93%\n",
      "66.23%\n",
      "Error #704\n",
      "Error #705\n",
      "Error #706\n",
      "Error #707\n",
      "Error #708\n",
      "Error #709\n",
      "Error #710\n",
      "Error #711\n",
      "Error #712\n",
      "Error #713\n",
      "Error #714\n",
      "Error #715\n",
      "66.54%\n",
      "66.85%\n",
      "67.15%\n",
      "67.46%\n",
      "Error #716\n",
      "67.77%\n",
      "68.07%\n",
      "Error #717\n",
      "Error #718\n",
      "68.38%\n",
      "Error #719\n",
      "Error #720\n",
      "Error #721\n",
      "Error #722\n",
      "Error #723\n",
      "Error #724\n",
      "Error #725\n",
      "Error #726\n",
      "Error #727\n",
      "Error #728\n",
      "Error #729\n",
      "Error #730\n",
      "Error #731\n",
      "Error #732\n",
      "Error #733\n",
      "Error #734\n",
      "68.69%\n",
      "Error #735\n",
      "Error #736\n",
      "Error #737\n",
      "68.99%\n",
      "69.30%\n",
      "69.61%\n",
      "69.91%\n",
      "70.22%\n",
      "70.53%\n",
      "Error #738\n",
      "Error #739\n",
      "70.83%\n",
      "71.14%\n",
      "Error #740\n",
      "Error #741\n",
      "Error #742\n",
      "71.45%\n",
      "71.75%\n",
      "72.06%\n",
      "Error #743\n",
      "72.37%\n",
      "72.67%\n",
      "Error #744\n",
      "72.98%\n",
      "73.29%\n",
      "73.59%\n",
      "73.90%\n",
      "Error #745\n",
      "Error #746\n",
      "74.21%\n",
      "74.51%\n",
      "Error #747\n",
      "74.82%\n",
      "75.13%\n",
      "Error #748\n",
      "Error #749\n",
      "Error #750\n",
      "Error #751\n",
      "75.43%\n",
      "Error #752\n",
      "75.74%\n",
      "76.05%\n",
      "Error #753\n",
      "Error #754\n",
      "76.35%\n",
      "Error #755\n",
      "Error #756\n",
      "76.66%\n",
      "Error #757\n",
      "76.97%\n",
      "Error #758\n",
      "77.27%\n",
      "Error #759\n",
      "77.58%\n",
      "Error #760\n",
      "Error #761\n",
      "Error #762\n",
      "77.89%\n",
      "78.19%\n",
      "78.50%\n",
      "78.81%\n",
      "Error #763\n",
      "79.11%\n",
      "79.42%\n",
      "79.73%\n",
      "80.03%\n",
      "80.34%\n",
      "Error #764\n",
      "80.65%\n",
      "80.95%\n",
      "81.26%\n",
      "Error #765\n",
      "Error #766\n",
      "81.57%\n",
      "Error #767\n",
      "81.87%\n",
      "Error #768\n",
      "82.18%\n",
      "82.48%\n",
      "82.79%\n",
      "Error #769\n",
      "Error #770\n",
      "83.10%\n",
      "Error #771\n",
      "Error #772\n",
      "Error #773\n",
      "Error #774\n",
      "Error #775\n",
      "83.40%\n",
      "83.71%\n",
      "84.02%\n",
      "Error #776\n",
      "84.32%\n",
      "84.63%\n",
      "Error #777\n",
      "84.94%\n",
      "Error #778\n",
      "Error #779\n",
      "85.24%\n",
      "85.55%\n",
      "Error #780\n",
      "85.86%\n",
      "86.16%\n",
      "Error #781\n",
      "86.47%\n",
      "86.78%\n",
      "87.08%\n",
      "87.39%\n",
      "Error #782\n",
      "Error #783\n",
      "87.70%\n",
      "Error #784\n",
      "Error #785\n",
      "88.00%\n",
      "Error #786\n",
      "88.31%\n",
      "Error #787\n",
      "88.62%\n",
      "88.92%\n",
      "Error #788\n",
      "89.23%\n",
      "Error #789\n",
      "89.54%\n",
      "89.84%\n",
      "90.15%\n",
      "90.46%\n",
      "Error #790\n",
      "Error #791\n",
      "90.76%\n",
      "91.07%\n",
      "91.38%\n",
      "Error #792\n",
      "Error #793\n",
      "91.68%\n",
      "91.99%\n",
      "Error #794\n",
      "Error #795\n",
      "92.30%\n",
      "92.60%\n",
      "92.91%\n",
      "Error #796\n",
      "Error #797\n",
      "93.22%\n",
      "93.52%\n",
      "Error #798\n",
      "93.83%\n",
      "Error #799\n",
      "94.14%\n",
      "Error #800\n",
      "Error #801\n",
      "94.44%\n",
      "Error #802\n",
      "Error #803\n",
      "Error #804\n",
      "Error #805\n",
      "94.75%\n",
      "Error #806\n",
      "Error #807\n",
      "95.06%\n",
      "Error #808\n",
      "95.36%\n",
      "Error #809\n",
      "Error #810\n",
      "Error #811\n",
      "Error #812\n",
      "95.67%\n",
      "95.98%\n",
      "Error #813\n",
      "Error #814\n",
      "Error #815\n",
      "96.28%\n",
      "96.59%\n",
      "Error #816\n",
      "Error #817\n",
      "96.90%\n",
      "Error #818\n",
      "97.20%\n",
      "97.51%\n",
      "Error #819\n",
      "Error #820\n",
      "Error #821\n",
      "97.82%\n",
      "Error #822\n",
      "98.12%\n",
      "Error #823\n",
      "98.43%\n",
      "Error #824\n",
      "98.74%\n",
      "Error #825\n",
      "99.04%\n",
      "Error #826\n",
      "Error #827\n",
      "Error #828\n",
      "99.35%\n",
      "99.66%\n",
      "99.96%\n",
      "Number of training examples: 57552\n"
     ]
    }
   ],
   "source": [
    "feature_sets = prepare_train_data(examples, ling_data_cache, feature_model)\n",
    "\n",
    "data_for_pandas = []\n",
    "for example in feature_sets:\n",
    "    data_for_pandas_ex = {}\n",
    "    data_for_pandas_ex['role'] = example[1]\n",
    "    data_for_pandas_ex['ex_id'] = example[2]\n",
    "    data_for_pandas_ex['tokens'] = example[3]\n",
    "    idxmapping = {v:i for i,v in enumerate(example[6].keys())}\n",
    "    data_for_pandas_ex['offsets'] = idxmapping\n",
    "    data_for_pandas_ex['arg_address'] = idxmapping[example[4]]\n",
    "    data_for_pandas_ex['pred_offset'] = idxmapping[example[5]]\n",
    "    for elem in example[0]:\n",
    "        for subelem in elem:\n",
    "            if subelem is not None:\n",
    "                data_for_pandas_ex.update(subelem)\n",
    "    \n",
    "    data_for_pandas.append(data_for_pandas_ex)\n",
    "    \n",
    "pd_data = pd.DataFrame(data_for_pandas)\n",
    "pd_data = pd_data.sample(frac=1)\n",
    "pd_data[:10]\n",
    "del data_for_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animacy_arg                                                   Anim\n",
      "Aspect_arg                                                        \n",
      "Gender_arg                                                    Masc\n",
      "Number_arg                                                    Sing\n",
      "Tense_arg                                                         \n",
      "Valency_arg                                                       \n",
      "VerbForm_arg                                                      \n",
      "arg_address                                                    163\n",
      "arg_case                                                       Acc\n",
      "arg_lemma                                              старик_NOUN\n",
      "arg_pos                                                       NOUN\n",
      "dist                                                             1\n",
      "ex_id                                                       104470\n",
      "offsets          {(0, 0): 0, (0, 1): 1, (0, 2): 2, (0, 3): 3, (...\n",
      "pred_lemma                                           радовать_VERB\n",
      "pred_offset                                                    162\n",
      "pred_pos                                                      VERB\n",
      "prepos                                                            \n",
      "rel_pos                                                         -1\n",
      "role                            субъект психологического состояния\n",
      "syn_link_name                                                nsubj\n",
      "tokens           [В, течение, многих, лет, у, него, служил, кам...\n",
      "Name: 3568, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(pd_data.iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): 0,\n",
      " (0, 1): 1,\n",
      " (0, 2): 2,\n",
      " (0, 3): 3,\n",
      " (0, 4): 4,\n",
      " (0, 5): 5,\n",
      " (0, 6): 6,\n",
      " (0, 7): 7,\n",
      " (0, 8): 8,\n",
      " (0, 9): 9,\n",
      " (0, 10): 10,\n",
      " (0, 11): 11,\n",
      " (0, 12): 12,\n",
      " (0, 13): 13,\n",
      " (0, 14): 14,\n",
      " (0, 15): 15,\n",
      " (0, 16): 16,\n",
      " (0, 17): 17,\n",
      " (0, 18): 18,\n",
      " (1, 0): 19,\n",
      " (1, 1): 20,\n",
      " (1, 2): 21,\n",
      " (1, 3): 22,\n",
      " (1, 4): 23,\n",
      " (1, 5): 24,\n",
      " (1, 6): 25,\n",
      " (1, 7): 26,\n",
      " (1, 8): 27,\n",
      " (1, 9): 28,\n",
      " (1, 10): 29,\n",
      " (1, 11): 30,\n",
      " (1, 12): 31,\n",
      " (1, 13): 32,\n",
      " (1, 14): 33,\n",
      " (1, 15): 34,\n",
      " (1, 16): 35,\n",
      " (1, 17): 36,\n",
      " (1, 18): 37,\n",
      " (1, 19): 38,\n",
      " (1, 20): 39,\n",
      " (1, 21): 40,\n",
      " (1, 22): 41,\n",
      " (1, 23): 42,\n",
      " (1, 24): 43,\n",
      " (1, 25): 44,\n",
      " (1, 26): 45,\n",
      " (1, 27): 46,\n",
      " (1, 28): 47,\n",
      " (1, 29): 48,\n",
      " (1, 30): 49,\n",
      " (1, 31): 50,\n",
      " (1, 32): 51,\n",
      " (1, 33): 52,\n",
      " (1, 34): 53,\n",
      " (1, 35): 54,\n",
      " (1, 36): 55,\n",
      " (1, 37): 56,\n",
      " (1, 38): 57,\n",
      " (1, 39): 58,\n",
      " (1, 40): 59,\n",
      " (1, 41): 60,\n",
      " (1, 42): 61,\n",
      " (1, 43): 62,\n",
      " (1, 44): 63,\n",
      " (1, 45): 64,\n",
      " (1, 46): 65,\n",
      " (1, 47): 66,\n",
      " (1, 48): 67,\n",
      " (1, 49): 68,\n",
      " (1, 50): 69,\n",
      " (1, 51): 70,\n",
      " (1, 52): 71,\n",
      " (2, 0): 72,\n",
      " (2, 1): 73,\n",
      " (2, 2): 74,\n",
      " (2, 3): 75,\n",
      " (2, 4): 76,\n",
      " (2, 5): 77,\n",
      " (2, 6): 78,\n",
      " (2, 7): 79,\n",
      " (2, 8): 80,\n",
      " (2, 9): 81,\n",
      " (2, 10): 82,\n",
      " (2, 11): 83,\n",
      " (2, 12): 84,\n",
      " (2, 13): 85,\n",
      " (2, 14): 86,\n",
      " (2, 15): 87,\n",
      " (2, 16): 88,\n",
      " (2, 17): 89,\n",
      " (2, 18): 90,\n",
      " (2, 19): 91,\n",
      " (2, 20): 92,\n",
      " (2, 21): 93,\n",
      " (2, 22): 94,\n",
      " (2, 23): 95,\n",
      " (2, 24): 96,\n",
      " (2, 25): 97,\n",
      " (2, 26): 98,\n",
      " (2, 27): 99,\n",
      " (2, 28): 100,\n",
      " (2, 29): 101,\n",
      " (2, 30): 102,\n",
      " (2, 31): 103,\n",
      " (2, 32): 104,\n",
      " (3, 0): 105,\n",
      " (3, 1): 106,\n",
      " (3, 2): 107,\n",
      " (3, 3): 108,\n",
      " (3, 4): 109,\n",
      " (3, 5): 110,\n",
      " (3, 6): 111,\n",
      " (3, 7): 112,\n",
      " (3, 8): 113,\n",
      " (3, 9): 114,\n",
      " (3, 10): 115,\n",
      " (3, 11): 116,\n",
      " (3, 12): 117,\n",
      " (3, 13): 118,\n",
      " (3, 14): 119,\n",
      " (3, 15): 120,\n",
      " (3, 16): 121,\n",
      " (3, 17): 122,\n",
      " (3, 18): 123,\n",
      " (3, 19): 124,\n",
      " (3, 20): 125,\n",
      " (3, 21): 126,\n",
      " (3, 22): 127,\n",
      " (3, 23): 128,\n",
      " (3, 24): 129,\n",
      " (3, 25): 130,\n",
      " (3, 26): 131,\n",
      " (3, 27): 132,\n",
      " (3, 28): 133,\n",
      " (3, 29): 134,\n",
      " (3, 30): 135,\n",
      " (3, 31): 136,\n",
      " (3, 32): 137,\n",
      " (3, 33): 138,\n",
      " (3, 34): 139,\n",
      " (4, 0): 140,\n",
      " (4, 1): 141,\n",
      " (4, 2): 142,\n",
      " (4, 3): 143,\n",
      " (4, 4): 144,\n",
      " (4, 5): 145,\n",
      " (4, 6): 146,\n",
      " (4, 7): 147,\n",
      " (4, 8): 148,\n",
      " (4, 9): 149,\n",
      " (4, 10): 150,\n",
      " (4, 11): 151,\n",
      " (4, 12): 152,\n",
      " (4, 13): 153,\n",
      " (4, 14): 154,\n",
      " (4, 15): 155,\n",
      " (4, 16): 156,\n",
      " (4, 17): 157,\n",
      " (4, 18): 158,\n",
      " (4, 19): 159,\n",
      " (4, 20): 160,\n",
      " (4, 21): 161,\n",
      " (4, 22): 162,\n",
      " (4, 23): 163,\n",
      " (4, 24): 164,\n",
      " (4, 25): 165,\n",
      " (4, 26): 166,\n",
      " (4, 27): 167,\n",
      " (4, 28): 168,\n",
      " (4, 29): 169,\n",
      " (4, 30): 170,\n",
      " (4, 31): 171,\n",
      " (4, 32): 172,\n",
      " (4, 33): 173,\n",
      " (4, 34): 174,\n",
      " (4, 35): 175,\n",
      " (4, 36): 176,\n",
      " (4, 37): 177,\n",
      " (4, 38): 178,\n",
      " (4, 39): 179,\n",
      " (5, 0): 180,\n",
      " (5, 1): 181,\n",
      " (5, 2): 182,\n",
      " (5, 3): 183,\n",
      " (5, 4): 184,\n",
      " (5, 5): 185,\n",
      " (5, 6): 186,\n",
      " (5, 7): 187,\n",
      " (5, 8): 188,\n",
      " (5, 9): 189,\n",
      " (5, 10): 190,\n",
      " (5, 11): 191,\n",
      " (6, 0): 192,\n",
      " (6, 1): 193,\n",
      " (6, 2): 194,\n",
      " (6, 3): 195,\n",
      " (6, 4): 196,\n",
      " (6, 5): 197,\n",
      " (6, 6): 198,\n",
      " (6, 7): 199,\n",
      " (6, 8): 200,\n",
      " (6, 9): 201,\n",
      " (6, 10): 202,\n",
      " (6, 11): 203,\n",
      " (6, 12): 204,\n",
      " (6, 13): 205,\n",
      " (6, 14): 206,\n",
      " (6, 15): 207,\n",
      " (6, 16): 208,\n",
      " (6, 17): 209,\n",
      " (6, 18): 210,\n",
      " (6, 19): 211,\n",
      " (6, 20): 212,\n",
      " (6, 21): 213,\n",
      " (6, 22): 214,\n",
      " (6, 23): 215,\n",
      " (6, 24): 216,\n",
      " (6, 25): 217,\n",
      " (6, 26): 218,\n",
      " (6, 27): 219,\n",
      " (6, 28): 220,\n",
      " (6, 29): 221,\n",
      " (6, 30): 222,\n",
      " (6, 31): 223,\n",
      " (7, 0): 224,\n",
      " (7, 1): 225,\n",
      " (7, 2): 226,\n",
      " (7, 3): 227,\n",
      " (7, 4): 228,\n",
      " (7, 5): 229,\n",
      " (7, 6): 230,\n",
      " (7, 7): 231,\n",
      " (7, 8): 232,\n",
      " (7, 9): 233,\n",
      " (7, 10): 234,\n",
      " (7, 11): 235,\n",
      " (7, 12): 236,\n",
      " (7, 13): 237,\n",
      " (7, 14): 238,\n",
      " (7, 15): 239,\n",
      " (7, 16): 240,\n",
      " (7, 17): 241,\n",
      " (7, 18): 242,\n",
      " (7, 19): 243,\n",
      " (8, 0): 244,\n",
      " (8, 1): 245,\n",
      " (8, 2): 246,\n",
      " (8, 3): 247,\n",
      " (8, 4): 248,\n",
      " (8, 5): 249,\n",
      " (8, 6): 250,\n",
      " (8, 7): 251,\n",
      " (8, 8): 252,\n",
      " (8, 9): 253,\n",
      " (8, 10): 254,\n",
      " (8, 11): 255,\n",
      " (8, 12): 256,\n",
      " (8, 13): 257}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as print_\n",
    "print_(pd_data.iloc[5].offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'В'),\n",
      " (1, 'течение'),\n",
      " (2, 'многих'),\n",
      " (3, 'лет'),\n",
      " (4, 'у'),\n",
      " (5, 'него'),\n",
      " (6, 'служил'),\n",
      " (7, 'камердинером'),\n",
      " (8, 'и'),\n",
      " (9, 'заведовал'),\n",
      " (10, 'его'),\n",
      " (11, 'домашним'),\n",
      " (12, 'хозяйством'),\n",
      " (13, 'честный'),\n",
      " (14, 'и'),\n",
      " (15, 'усердный'),\n",
      " (16, 'курляндский'),\n",
      " (17, 'уроженец'),\n",
      " (18, '.'),\n",
      " (19, 'В'),\n",
      " (20, 'конце'),\n",
      " (21, 'шестидесятых'),\n",
      " (22, 'годов'),\n",
      " (23, 'он'),\n",
      " (24, 'умер'),\n",
      " (25, 'скоропостижно'),\n",
      " (26, ','),\n",
      " (27, 'и'),\n",
      " (28, 'Иван'),\n",
      " (29, 'Александрович'),\n",
      " (30, ','),\n",
      " (31, 'соболезнуя'),\n",
      " (32, 'положению'),\n",
      " (33, 'его'),\n",
      " (34, 'вдовы'),\n",
      " (35, 'с'),\n",
      " (36, 'тремя'),\n",
      " (37, 'малолетними'),\n",
      " (38, 'детьми'),\n",
      " (39, ','),\n",
      " (40, 'оставил'),\n",
      " (41, 'её'),\n",
      " (42, 'служить'),\n",
      " (43, 'у'),\n",
      " (44, 'себя'),\n",
      " (45, ','),\n",
      " (46, 'предоставив'),\n",
      " (47, 'ей'),\n",
      " (48, 'маленькое'),\n",
      " (49, 'помещение'),\n",
      " (50, 'через'),\n",
      " (51, 'площадку'),\n",
      " (52, 'лестницы'),\n",
      " (53, 'своей'),\n",
      " (54, 'квартиры'),\n",
      " (55, ','),\n",
      " (56, 'и'),\n",
      " (57, 'заменил'),\n",
      " (58, 'ею'),\n",
      " (59, 'умершего'),\n",
      " (60, 'её'),\n",
      " (61, 'мужа'),\n",
      " (62, 'в'),\n",
      " (63, 'домашнем'),\n",
      " (64, 'услужении'),\n",
      " (65, 'при'),\n",
      " (66, 'своём'),\n",
      " (67, 'маленьком'),\n",
      " (68, 'хозяйстве'),\n",
      " (69, 'старого'),\n",
      " (70, 'холостяка'),\n",
      " (71, '.'),\n",
      " (72, 'С'),\n",
      " (73, 'годами'),\n",
      " (74, ','),\n",
      " (75, 'когда'),\n",
      " (76, 'стали'),\n",
      " (77, 'подрастать'),\n",
      " (78, 'дети'),\n",
      " (79, ','),\n",
      " (80, 'сердце'),\n",
      " (81, 'Ивана'),\n",
      " (82, 'Александровича'),\n",
      " (83, 'откликнулось'),\n",
      " (84, 'на'),\n",
      " (85, 'их'),\n",
      " (86, 'чистую'),\n",
      " (87, 'ласку'),\n",
      " (88, ','),\n",
      " (89, 'и'),\n",
      " (90, 'он'),\n",
      " (91, 'привязался'),\n",
      " (92, 'к'),\n",
      " (93, 'ним'),\n",
      " (94, ','),\n",
      " (95, 'и'),\n",
      " (96, 'особенно'),\n",
      " (97, 'к'),\n",
      " (98, 'старшей'),\n",
      " (99, 'девочке'),\n",
      " (100, ','),\n",
      " (101, 'глубоко'),\n",
      " (102, 'и'),\n",
      " (103, 'трогательно'),\n",
      " (104, '.'),\n",
      " (105, 'Его'),\n",
      " (106, 'заботам'),\n",
      " (107, ','),\n",
      " (108, 'просьбам'),\n",
      " (109, ','),\n",
      " (110, 'материальным'),\n",
      " (111, 'жертвам'),\n",
      " (112, ','),\n",
      " (113, 'ходатайствам'),\n",
      " (114, ','),\n",
      " (115, 'письменным'),\n",
      " (116, 'и'),\n",
      " (117, 'словесным'),\n",
      " (118, ','),\n",
      " (119, 'эти'),\n",
      " (120, 'дети'),\n",
      " (121, 'были'),\n",
      " (122, 'обязаны'),\n",
      " (123, 'своим'),\n",
      " (124, 'воспитанием'),\n",
      " (125, 'и'),\n",
      " (126, 'образованием'),\n",
      " (127, 'в'),\n",
      " (128, 'средних'),\n",
      " (129, 'учебных'),\n",
      " (130, 'заведениях'),\n",
      " (131, ','),\n",
      " (132, 'за'),\n",
      " (133, 'которым'),\n",
      " (134, 'он'),\n",
      " (135, 'следил'),\n",
      " (136, 'с'),\n",
      " (137, 'исключительным'),\n",
      " (138, 'вниманием'),\n",
      " (139, '.'),\n",
      " (140, 'Возможность'),\n",
      " (141, 'дать'),\n",
      " (142, 'им'),\n",
      " (143, 'средства'),\n",
      " (144, ','),\n",
      " (145, 'чтобы'),\n",
      " (146, 'подышать'),\n",
      " (147, 'свежим'),\n",
      " (148, 'воздухом'),\n",
      " (149, 'и'),\n",
      " (150, 'укрепить'),\n",
      " (151, 'свои'),\n",
      " (152, 'силы'),\n",
      " (153, 'где'),\n",
      " (154, '-'),\n",
      " (155, 'нибудь'),\n",
      " (156, 'на'),\n",
      " (157, 'даче'),\n",
      " (158, 'или'),\n",
      " (159, 'на'),\n",
      " (160, 'берегу'),\n",
      " (161, 'моря'),\n",
      " (162, ','),\n",
      " (163, 'сердечно'),\n",
      " (164, 'радовала'),\n",
      " (165, 'старика'),\n",
      " (166, ','),\n",
      " (167, 'которому'),\n",
      " (168, 'в'),\n",
      " (169, 'этом'),\n",
      " (170, 'нередко'),\n",
      " (171, 'помогали'),\n",
      " (172, 'дочери'),\n",
      " (173, 'его'),\n",
      " (174, 'старого'),\n",
      " (175, 'друга'),\n",
      " (176, 'А'),\n",
      " (177, '.'),\n",
      " (178, 'В'),\n",
      " (179, '.'),\n",
      " (180, 'Никитенко'),\n",
      " (181, '.'),\n",
      " (182, 'И'),\n",
      " (183, 'в'),\n",
      " (184, 'этой'),\n",
      " (185, 'вполне'),\n",
      " (186, 'бескорыстной'),\n",
      " (187, 'привязанности'),\n",
      " (188, 'Гончаров'),\n",
      " (189, 'дошёл'),\n",
      " (190, 'до'),\n",
      " (191, 'крайних'),\n",
      " (192, 'пределов'),\n",
      " (193, '.'),\n",
      " (194, 'Заботы'),\n",
      " (195, 'о'),\n",
      " (196, 'детях'),\n",
      " (197, ','),\n",
      " (198, 'их'),\n",
      " (199, 'мысли'),\n",
      " (200, ','),\n",
      " (201, 'чувства'),\n",
      " (202, ','),\n",
      " (203, 'привычки'),\n",
      " (204, ','),\n",
      " (205, 'складывавшиеся'),\n",
      " (206, 'особенности'),\n",
      " (207, 'характера'),\n",
      " (208, ','),\n",
      " (209, 'шутливые'),\n",
      " (210, 'и'),\n",
      " (211, 'нежные'),\n",
      " (212, 'прозвища'),\n",
      " (213, ','),\n",
      " (214, 'им'),\n",
      " (215, 'даваемые'),\n",
      " (216, ','),\n",
      " (217, 'наполняли'),\n",
      " (218, 'его'),\n",
      " (219, 'жизнь'),\n",
      " (220, ','),\n",
      " (221, 'вплетались'),\n",
      " (222, 'в'),\n",
      " (223, 'его'),\n",
      " (224, 'беседу'),\n",
      " (225, '.'),\n",
      " (226, 'Внимание'),\n",
      " (227, 'к'),\n",
      " (228, 'ним'),\n",
      " (229, ','),\n",
      " (230, 'ласка'),\n",
      " (231, 'Сани'),\n",
      " (232, '('),\n",
      " (233, 'так'),\n",
      " (234, 'звали'),\n",
      " (235, 'старшую'),\n",
      " (236, 'из'),\n",
      " (237, 'них'),\n",
      " (238, ')'),\n",
      " (239, 'вызывали'),\n",
      " (240, 'горячую'),\n",
      " (241, 'благодарность'),\n",
      " (242, 'с'),\n",
      " (243, 'его'),\n",
      " (244, 'стороны'),\n",
      " (245, '.'),\n",
      " (246, 'Мало'),\n",
      " (247, '-'),\n",
      " (248, 'помалу'),\n",
      " (249, 'их'),\n",
      " (250, 'жизнь'),\n",
      " (251, 'пустила'),\n",
      " (252, 'в'),\n",
      " (253, 'его'),\n",
      " (254, 'существование'),\n",
      " (255, 'крепкие'),\n",
      " (256, ','),\n",
      " (257, 'неразрывные'),\n",
      " (258, 'корни'),\n",
      " (259, '...')]\n"
     ]
    }
   ],
   "source": [
    "print_(list(enumerate(pd_data.iloc[5].tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:28.046180",
     "start_time": "2017-02-18T12:16:27.932519"
    }
   },
   "outputs": [],
   "source": [
    "y_stat = pd_data.loc[:, 'role'].value_counts()\n",
    "drop_ys = y_stat[y_stat < 180].index\n",
    "clear_data = pd_data.drop(pd_data[pd_data.loc[:, 'role'].isin(drop_ys)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:28.523645",
     "start_time": "2017-02-18T12:16:28.047978"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of roles:  44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "агенс                                 6147\n",
       "пациенс                               5362\n",
       "тема                                  3656\n",
       "субъект психологического состояния    3250\n",
       "субъект перемещения                   3011\n",
       "причина                               2502\n",
       "говорящий                             2365\n",
       "место                                 2185\n",
       "содержание действия                   1874\n",
       "содержание мысли                      1817\n",
       "содержание высказывания               1792\n",
       "конечная точка                        1772\n",
       "результат                             1452\n",
       "пациенс перемещения                   1356\n",
       "стимул                                1271\n",
       "субъект ментального состояния         1223\n",
       "адресат                                941\n",
       "субъект восприятия                     901\n",
       "контрагент                             831\n",
       "эффектор                               739\n",
       "субъект социального отношения          598\n",
       "начальная точка                        588\n",
       "предмет высказывания                   548\n",
       "способ                                 531\n",
       "конечный посессор                      506\n",
       "цель                                   454\n",
       "сфера                                  376\n",
       "признак                                366\n",
       "источник звука                         359\n",
       "субъект поведения                      339\n",
       "ситуация в фокусе                      322\n",
       "контрагент социального отношения       318\n",
       "субъект физиологической реакции        310\n",
       "предмет мысли                          303\n",
       "потенциальный пациенс                  290\n",
       "статус                                 265\n",
       "пациенс социального отношения          261\n",
       "срок                                   255\n",
       "эталон                                 255\n",
       "признак действия                       243\n",
       "каузатор                               223\n",
       "исходный посессор                      217\n",
       "потенциальная угроза                   197\n",
       "траектория                             180\n",
       "Name: role, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl_roles = {\n",
    "    'агенс - субъект восприятия' : 'субъект восприятия',\n",
    "    'агенс - субъект ментального состояния' : 'субъект ментального состояния',\n",
    "    'результат / цель' : 'результат',\n",
    "    'место - пациенс' : 'место',\n",
    "    'говорящий - субъект психологического состояния' : 'субъект психологического состояния'\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_single_region(data, rep, val):\n",
    "    data.loc[:, 'role'] = data.loc[:, 'role'].str.replace(rep, val)\n",
    "\n",
    "\n",
    "for rep, val in repl_roles.items():\n",
    "    normalize_single_region(clear_data, rep, val)\n",
    "    \n",
    "number_of_roles = len(clear_data.loc[:, 'role'].value_counts().index)\n",
    "print('Number of roles: ', number_of_roles)\n",
    "clear_data.loc[:, 'role'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['содержание высказывания',\n",
       " 'говорящий',\n",
       " 'субъект социального отношения',\n",
       " 'субъект психологического состояния',\n",
       " 'содержание действия',\n",
       " 'агенс',\n",
       " 'тема',\n",
       " 'конечная точка',\n",
       " 'сфера',\n",
       " 'контрагент',\n",
       " 'субъект перемещения',\n",
       " 'причина',\n",
       " 'субъект поведения',\n",
       " 'ситуация в фокусе',\n",
       " 'исходный посессор',\n",
       " 'субъект физиологической реакции',\n",
       " 'адресат',\n",
       " 'пациенс',\n",
       " 'срок',\n",
       " 'источник звука',\n",
       " 'место',\n",
       " 'признак',\n",
       " 'потенциальная угроза',\n",
       " 'субъект ментального состояния',\n",
       " 'конечный посессор',\n",
       " 'результат',\n",
       " 'стимул',\n",
       " 'субъект восприятия',\n",
       " 'эффектор',\n",
       " 'траектория',\n",
       " 'содержание мысли',\n",
       " 'пациенс перемещения',\n",
       " 'каузатор',\n",
       " 'предмет высказывания',\n",
       " 'начальная точка',\n",
       " 'способ',\n",
       " 'пациенс социального отношения',\n",
       " 'статус',\n",
       " 'предмет мысли',\n",
       " 'цель',\n",
       " 'потенциальный пациенс',\n",
       " 'контрагент социального отношения',\n",
       " 'эталон',\n",
       " 'признак действия']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(clear_data.loc[:, 'role'].drop_duplicates().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:28.578144",
     "start_time": "2017-02-18T12:16:28.525204"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52751, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_orig = clear_data.loc[:, 'role']\n",
    "X_orig = clear_data.drop('role', axis = 1)\n",
    "X_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:29.690583",
     "start_time": "2017-02-18T12:16:28.580765"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pickle\n",
    "\n",
    "label_encoder = LabelBinarizer()\n",
    "y = label_encoder.fit_transform(y_orig)\n",
    "\n",
    "with open(main_model_path + '/label_encoder.pckl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52751, 44)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:36.643690",
     "start_time": "2017-02-18T12:16:29.701186"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size:  300\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "embeddings_path = '../../data/embeddings/ruscorpora_upos_skipgram_300_5_2018.vec'\n",
    "embeddings = KeyedVectors.load_word2vec_format(embeddings_path, binary=False)\n",
    "print('Embedding size: ', embeddings.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:36.671658",
     "start_time": "2017-02-18T12:16:36.645470"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def make_embeded_form(word):\n",
    "    if word:\n",
    "        #return word[1].encode('utf8')\n",
    "        return u\"{}_{}\".format(word[1], word[0])\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "\n",
    "class Embedder_map:\n",
    "    def __init__(self, embeddings, X):\n",
    "        self.X_ = X\n",
    "        self.embeddings_ = embeddings\n",
    "\n",
    "    def __call__(self, i):  \n",
    "        result = np.zeros((len(self.X_[0]), \n",
    "                           self.embeddings_.vector_size))\n",
    "\n",
    "        for j in range(len(self.X_[0])):\n",
    "            word = self.X_[i][j]\n",
    "            tag = word[0] if word else str()\n",
    "            \n",
    "            if tag == ARG_SPECIAL_TAG or tag == ARG_SPECIAL_TAG:\n",
    "                result[j, :] = np.ones(self.embeddings_.vector_size)\n",
    "            elif word and word in embeddings:\n",
    "                result[j, :] = self.embeddings_[word]\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def embed(X):\n",
    "    pool = mp.Pool(4)\n",
    "    result = pool.map(Embedder_map(embeddings, X), X.index, 1000)\n",
    "    pool.close()\n",
    "    return np.asarray(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Animacy_arg', 'Aspect_arg', 'Gender_arg', 'Number_arg', 'Tense_arg',\n",
       "       'Valency_arg', 'VerbForm_arg', 'arg_address', 'arg_case', 'arg_lemma',\n",
       "       'arg_pos', 'dist', 'ex_id', 'pred_lemma', 'pred_pos', 'prepos',\n",
       "       'rel_pos', 'syn_link_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_orig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:18:10.418972",
     "start_time": "2017-02-18T12:16:36.673158"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'the label [arg_context_lemmas] is not in the [columns]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m                     \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1784\u001b[0m                                .format(key=key,\n\u001b[0;32m-> 1785\u001b[0;31m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [arg_context_lemmas] is not in the [columns]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                 \u001b[0;31m# we have yielded a scalar ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1796\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m                 \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 raise KeyError(u\"the label [{key}] is not in the [{axis}]\"\n\u001b[1;32m   1784\u001b[0m                                .format(key=key,\n\u001b[0;32m-> 1785\u001b[0;31m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [arg_context_lemmas] is not in the [columns]'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "arg_context_embedded = embed(X_orig.loc[:, 'arg_context_lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:33.028839",
     "start_time": "2017-02-18T12:18:10.420741"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pred_context_embedded = embed(X_orig.loc[:, 'pred_context_lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:33.045522",
     "start_time": "2017-02-18T12:22:33.030953"
    }
   },
   "outputs": [],
   "source": [
    "class Embedder_single_map:\n",
    "    def __init__(self, embeddings, X):\n",
    "        self.X_ = X\n",
    "        self.embeddings_ = embeddings\n",
    "\n",
    "    def __call__(self, i):\n",
    "        #word = make_embeded_form(self.X_[i])\n",
    "        word = self.X_[i]\n",
    "        if word in self.embeddings_:\n",
    "            return self.embeddings_[word]\n",
    "        else:\n",
    "            return np.zeros((self.embeddings_.vector_size,))\n",
    "\n",
    "        \n",
    "def embed_single(embeddings, X):\n",
    "    pool = mp.Pool(4)\n",
    "    result = pool.map(Embedder_single_map(embeddings, X), X.index, 1000)\n",
    "    pool.close()\n",
    "        \n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0516 08:04:56.965393 139896968771328 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "elmo = ELMoEmbedder(\"http://files.deeppavlov.ai/deeppavlov_data/elmo_ru-wiki_600k_steps.tar.gz\", elmo_output_names=['elmo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_embed(embeddings, tokens, word_idx):\n",
    "    embedded = embeddings([tokens])[0]\n",
    "    return embedded[min(word_idx, len(tokens)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(obj):\n",
    "    verb_idx = obj.pred_offset\n",
    "    tokens = obj.tokens\n",
    "    return elmo_embed(elmo, tokens, verb_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_verbs = np.stack(embedded_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../../data/elmo_verbs.npy\", e_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 17335/52751 [2:31:41<5:09:53,  1.90it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-25b1026c3afb>\u001b[0m in \u001b[0;36melmo_embed\u001b[0;34m(embeddings, tokens, word_idx)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0melmo_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/deeppavlov/models/embedders/elmo_embedder.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch, *args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0melmo_output_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0melmo_output_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mini_batch_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/deeppavlov/core/models/tf_backend.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/deeppavlov/models/embedders/elmo_embedder.py\u001b[0m in \u001b[0;36m_mini_batch_fit\u001b[0;34m(self, batch, *args, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m         elmo_outputs = self.sess.run(self.elmo_outputs,\n\u001b[1;32m    244\u001b[0m                                      feed_dict={self.tokens_ph: batch,\n\u001b[0;32m--> 245\u001b[0;31m                                                 self.tokens_length_ph: tokens_length})\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'default'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo_output_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedded_verbs = []\n",
    "for i in tqdm(range(len(X_orig))):\n",
    "    obj = X_orig.iloc[i]\n",
    "    verb_idx = obj.pred_offset\n",
    "    tokens = obj.tokens\n",
    "    embedded_verbs.append(elmo_embed(elmo, tokens, verb_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:40.521526",
     "start_time": "2017-02-18T12:22:33.047988"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30371, 300)\n",
      "362\n",
      "(41,)\n",
      "CPU times: user 32 ms, sys: 68 ms, total: 100 ms\n",
      "Wall time: 99.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embedded_verbs = embed_single(pd.Series(list(zip(X_orig.pred_pos, X_orig.pred_lemma)), \n",
    "                                         index = X_orig.index))\n",
    "\n",
    "print(embedded_verbs.shape)\n",
    "print((np.linalg.norm(embedded_verbs, axis = 1) < 0.001).sum())\n",
    "print(clear_data[(np.linalg.norm(embedded_verbs, axis = 1) < 0.001)].pred_lemma.value_counts().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:48.662074",
     "start_time": "2017-02-18T12:22:40.817873"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30371, 300)\n",
      "10342\n",
      "CPU times: user 22 s, sys: 14.3 s, total: 36.3 s\n",
      "Wall time: 42.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# embedded_args = embed_single(pd.Series(list(zip(X_orig.arg_pos, X_orig.arg_lemma)), \n",
    "#                                        index = X_orig.index))\n",
    "embedded_args = embed_single(embeddings, X_orig.arg_lemma)\n",
    "print(embedded_args.shape)\n",
    "print((np.linalg.norm(embedded_args, axis = 1) < 0.001).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing categorial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Animacy_arg', 'Aspect_arg', 'Gender_arg', 'Number_arg', 'Tense_arg',\n",
       "       'Valency_arg', 'VerbForm_arg', 'arg_address', 'arg_case', 'arg_lemma',\n",
       "       'arg_pos', 'dist', 'ex_id', 'pred_lemma', 'pred_pos', 'prepos',\n",
       "       'rel_pos', 'syn_link_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_orig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:52.653831",
     "start_time": "2017-02-18T12:22:48.759036"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category features:\n",
      " ['Animacy_arg', 'Aspect_arg', 'Gender_arg', 'Number_arg', 'Tense_arg', 'Valency_arg', 'VerbForm_arg', 'arg_case', 'arg_pos', 'dist', 'pred_lemma', 'pred_pos', 'prepos', 'syn_link_name']\n",
      "Not category features:\n",
      " ['rel_pos']\n",
      "(30371, 941)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "#morph_feats = ['pos', 'case', 'anim', 'vform', 'zform', 'shform', 'pform', 'vvform', 'nform', 'time']\n",
    "\n",
    "# all_feats = (['pred_lemma', 'rel_pos'] + \n",
    "#              ['arg_' + e for e in morph_feats] + \n",
    "#              ['pred_' + e for e in morph_feats])\n",
    "\n",
    "# all_feats = (['pred_lemma', 'rel_pos', 'arg_prep'] + \n",
    "#              ['arg_' + e for e in morph_feats] + \n",
    "#              ['pred_' + e for e in morph_feats])\n",
    "\n",
    "# all_feats = (['pred_lemma', 'rel_pos', 'arg_prep', 'link_name'] + \n",
    "#              ['arg_' + e for e in morph_feats] + \n",
    "#              ['pred_' + e for e in morph_feats])\n",
    "\n",
    "#all_feats = ['pred_lemma', 'rel_pos', 'pred_pos', 'arg_case', 'syn_link_name', 'arg_pos', 'prepos', 'dist']\n",
    "\n",
    "#categ_feats = [e for e in all_feats if X_orig[e].dtype in [str, object]]\n",
    "#not_categ = [e for e in all_feats if e not in categ_feats]\n",
    "\n",
    "#pred_lemma_vectorizer.fit_transform(X_orig.loc[:, ['pred_lemma']].to_dict(orient = 'records'))\n",
    "\n",
    "not_categ_features = {'arg_address', 'ex_id', 'rel_pos', 'arg_lemma'}\n",
    "categ_feats = [name for name in X_orig.columns if name not in not_categ_features] \n",
    "not_categ = ['rel_pos']\n",
    "print('Category features:\\n', categ_feats)\n",
    "print('Not category features:\\n', not_categ)\n",
    "\n",
    "vectorizer = DictVectorizer(sparse = False)\n",
    "one_hot_feats = vectorizer.fit_transform(X_orig.loc[:, categ_feats].to_dict(orient = 'records'))\n",
    "print(one_hot_feats.shape)\n",
    "\n",
    "with open(main_model_path + '/feature_encoder.pckl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:52.924596",
     "start_time": "2017-02-18T12:22:52.655580"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.4/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30371, 942)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_categ_columns = np.concatenate(tuple(X_orig.loc[:, e].as_matrix().reshape(-1, 1) for e in not_categ), axis =1)\n",
    "plain_features = np.concatenate((one_hot_feats, not_categ_columns), axis = 1)\n",
    "plain_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:52.938339",
     "start_time": "2017-02-18T12:22:52.926218"
    }
   },
   "outputs": [],
   "source": [
    "del not_categ_columns\n",
    "del one_hot_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, LSTM, Convolution1D, Dropout, MaxPooling1D\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.layers import TimeDistributed\n",
    "from tensorflow.python.keras.layers import Activation\n",
    "from tensorflow.python.keras.layers import RepeatVector\n",
    "from tensorflow.python.keras.layers import Permute\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.layers import Concatenate\n",
    "from tensorflow.python.keras.layers import Bidirectional\n",
    "from tensorflow.python.keras.layers import Masking\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:23:00.054095",
     "start_time": "2017-02-18T12:23:00.016955"
    }
   },
   "outputs": [],
   "source": [
    "def construct_plain_model(input_shape):\n",
    "    print('Plain model.')\n",
    "    \n",
    "    plain_model = Sequential()\n",
    "    plain_model.add(Dense(600, \n",
    "                          #input_shape=(plain_features.shape[1],), \n",
    "                          input_shape = input_shape,\n",
    "                          activation = 'relu'))\n",
    "    plain_model.add(Dropout(0.3))\n",
    "    \n",
    "    plain_model.add(Dense(400))\n",
    "    plain_model.add(BatchNormalization())\n",
    "    plain_model.add(Activation('relu'))\n",
    "    plain_model.add(Dropout(0.3))\n",
    "    \n",
    "    plain_model.add(Dense(number_of_roles))\n",
    "    plain_model.add(BatchNormalization())\n",
    "    plain_model.add(Activation('softmax'))\n",
    "    \n",
    "    plain_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return plain_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:23:00.102016",
     "start_time": "2017-02-18T12:23:00.055842"
    }
   },
   "outputs": [],
   "source": [
    "def construct_plain_model_sparse(categ_size, emb_size, number_of_roles):    \n",
    "    input_plain = Input(shape=(categ_size,), name = 'input_categorical')\n",
    "    input_pred_embed = Input(shape=(emb_size,), name = 'pred_embed')\n",
    "    input_arg_embed = Input(shape=(emb_size,), name = 'arg_embed')\n",
    "    \n",
    "    plain = Dense(400)(input_plain)\n",
    "    plain = BatchNormalization()(plain)\n",
    "    plain = Activation('relu')(plain)\n",
    "    \n",
    "    def embed_submodel(inpt):\n",
    "        embed = Dense(100)(inpt)\n",
    "        embed = BatchNormalization()(embed)\n",
    "        embed = Activation('relu')(embed)\n",
    "        return embed\n",
    "    \n",
    "    embed_pred = embed_submodel(input_pred_embed)\n",
    "    embed_arg = embed_submodel(input_arg_embed)\n",
    "    \n",
    "    final = Concatenate(axis = 1)([embed_pred, embed_arg, plain])\n",
    "    final = Dropout(0.3)(final)\n",
    "    final = Dense(400)(final)\n",
    "    final = BatchNormalization()(final)\n",
    "    final = Activation('relu')(final)\n",
    "    final = Dropout(0.3)(final)\n",
    "    final = Dense(number_of_roles)(final)\n",
    "    final = BatchNormalization()(final)\n",
    "    final = Activation('softmax')(final)\n",
    "    \n",
    "    model = Model([input_arg_embed, input_pred_embed, input_plain], final)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with in-domain test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only for experiments with in-domain test. Do not use for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-15T10:45:48.365172",
     "start_time": "2017-02-15T10:45:04.358434"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 600)               565800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 400)               1600      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 34)                13634     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 34)                136       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 34)                0         \n",
      "=================================================================\n",
      "Total params: 821,570\n",
      "Trainable params: 820,702\n",
      "Non-trainable params: 868\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 27333 samples, validate on 3038 samples\n",
      "Epoch 1/15\n",
      "27333/27333 [==============================] - 3s 106us/step - loss: 2.7752 - acc: 0.2854 - val_loss: 3.0371 - val_acc: 0.5148\n",
      "Epoch 2/15\n",
      "27333/27333 [==============================] - 2s 65us/step - loss: 1.6398 - acc: 0.6511 - val_loss: 2.7154 - val_acc: 0.6593\n",
      "Epoch 3/15\n",
      "27333/27333 [==============================] - 2s 62us/step - loss: 1.1899 - acc: 0.7470 - val_loss: 2.3325 - val_acc: 0.7284\n",
      "Epoch 4/15\n",
      "27333/27333 [==============================] - 2s 62us/step - loss: 1.0063 - acc: 0.7740 - val_loss: 1.8452 - val_acc: 0.7587\n",
      "Epoch 5/15\n",
      "27333/27333 [==============================] - 2s 63us/step - loss: 0.8779 - acc: 0.7972 - val_loss: 1.3480 - val_acc: 0.7725\n",
      "Epoch 6/15\n",
      "27333/27333 [==============================] - 2s 64us/step - loss: 0.7952 - acc: 0.8080 - val_loss: 1.0419 - val_acc: 0.7844\n",
      "Epoch 7/15\n",
      "27333/27333 [==============================] - 2s 64us/step - loss: 0.7227 - acc: 0.8252 - val_loss: 0.9011 - val_acc: 0.7867\n",
      "Epoch 8/15\n",
      "27333/27333 [==============================] - 2s 63us/step - loss: 0.6609 - acc: 0.8355 - val_loss: 0.8176 - val_acc: 0.7893\n",
      "Epoch 9/15\n",
      "27333/27333 [==============================] - 2s 66us/step - loss: 0.6094 - acc: 0.8451 - val_loss: 0.8021 - val_acc: 0.7907\n",
      "Epoch 10/15\n",
      "27333/27333 [==============================] - 2s 64us/step - loss: 0.5778 - acc: 0.8514 - val_loss: 0.7808 - val_acc: 0.7897\n",
      "Epoch 11/15\n",
      "27333/27333 [==============================] - 2s 64us/step - loss: 0.5332 - acc: 0.8628 - val_loss: 0.7747 - val_acc: 0.7883\n",
      "Epoch 12/15\n",
      "27333/27333 [==============================] - 2s 63us/step - loss: 0.5096 - acc: 0.8665 - val_loss: 0.7709 - val_acc: 0.7897\n",
      "Epoch 13/15\n",
      "27333/27333 [==============================] - 2s 62us/step - loss: 0.4808 - acc: 0.8718 - val_loss: 0.7695 - val_acc: 0.7880\n",
      "Epoch 14/15\n",
      "27333/27333 [==============================] - 2s 64us/step - loss: 0.4525 - acc: 0.8783 - val_loss: 0.7638 - val_acc: 0.7887\n",
      "Epoch 15/15\n",
      "27333/27333 [==============================] - 2s 64us/step - loss: 0.4258 - acc: 0.8820 - val_loss: 0.7678 - val_acc: 0.7874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f8b5e515470>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = construct_plain_model((plain_features.shape[1],))\n",
    "print(model.summary())\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit(plain_features, y, epochs=15, batch_size=300, validation_split = 0.1, \n",
    "          shuffle=True, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-16T10:49:20.090543",
     "start_time": "2017-02-16T10:49:19.585615"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27333 samples, validate on 3038 samples\n",
      "Epoch 1/16\n",
      "27333/27333 [==============================] - 3s 119us/step - loss: 2.4430 - acc: 0.4180 - val_loss: 2.9355 - val_acc: 0.5803\n",
      "Epoch 2/16\n",
      "27333/27333 [==============================] - 2s 67us/step - loss: 1.5145 - acc: 0.6868 - val_loss: 2.4724 - val_acc: 0.7090\n",
      "Epoch 3/16\n",
      "27333/27333 [==============================] - 2s 65us/step - loss: 1.1851 - acc: 0.7509 - val_loss: 1.9051 - val_acc: 0.7475\n",
      "Epoch 4/16\n",
      "27333/27333 [==============================] - 2s 65us/step - loss: 1.0031 - acc: 0.7803 - val_loss: 1.4031 - val_acc: 0.7765\n",
      "Epoch 5/16\n",
      "27333/27333 [==============================] - 2s 66us/step - loss: 0.8881 - acc: 0.7987 - val_loss: 1.0735 - val_acc: 0.7831\n",
      "Epoch 6/16\n",
      "27333/27333 [==============================] - 2s 67us/step - loss: 0.7945 - acc: 0.8140 - val_loss: 0.9006 - val_acc: 0.7930\n",
      "Epoch 7/16\n",
      "27333/27333 [==============================] - 2s 65us/step - loss: 0.7277 - acc: 0.8258 - val_loss: 0.7991 - val_acc: 0.8035\n",
      "Epoch 8/16\n",
      "27333/27333 [==============================] - 2s 67us/step - loss: 0.6625 - acc: 0.8393 - val_loss: 0.7502 - val_acc: 0.8074\n",
      "Epoch 9/16\n",
      "27333/27333 [==============================] - 2s 67us/step - loss: 0.6210 - acc: 0.8446 - val_loss: 0.7317 - val_acc: 0.8088\n",
      "Epoch 10/16\n",
      "27333/27333 [==============================] - 2s 67us/step - loss: 0.5771 - acc: 0.8552 - val_loss: 0.7251 - val_acc: 0.7995\n",
      "Epoch 11/16\n",
      "27333/27333 [==============================] - 2s 66us/step - loss: 0.5321 - acc: 0.8652 - val_loss: 0.7165 - val_acc: 0.8068\n",
      "Epoch 12/16\n",
      "27333/27333 [==============================] - 2s 65us/step - loss: 0.5004 - acc: 0.8726 - val_loss: 0.7020 - val_acc: 0.8081\n",
      "Epoch 13/16\n",
      "27333/27333 [==============================] - 2s 66us/step - loss: 0.4720 - acc: 0.8775 - val_loss: 0.6924 - val_acc: 0.8084\n",
      "Epoch 14/16\n",
      "27333/27333 [==============================] - 2s 66us/step - loss: 0.4469 - acc: 0.8833 - val_loss: 0.6901 - val_acc: 0.8071\n",
      "Epoch 15/16\n",
      "27333/27333 [==============================] - 2s 68us/step - loss: 0.4283 - acc: 0.8854 - val_loss: 0.6999 - val_acc: 0.8028\n",
      "Epoch 16/16\n",
      "27333/27333 [==============================] - 2s 67us/step - loss: 0.4007 - acc: 0.8935 - val_loss: 0.6945 - val_acc: 0.8018\n"
     ]
    }
   ],
   "source": [
    "model = construct_plain_model_sparse(plain_features.shape[1], embeddings.vector_size, y.shape[1])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit([embedded_args, embedded_verbs, plain_features], y, epochs=16, batch_size=300, \n",
    "          validation_split = 0.1, shuffle=True, callbacks = [early_stopping])\n",
    "model.save(os.path.join(main_model_path, 'neural_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-15T23:18:09.873456",
     "start_time": "2017-02-15T23:07:16.496170"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context model.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pred_context_embedded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-bb3db1ae881b>\u001b[0m in \u001b[0;36mconstruct_graph_lstm_model\u001b[0;34m(plain_features_shape)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#arg_context_model = construct_attentional_part(arg_context_embedded.shape[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mpred_context_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_attentional_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_context_embedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m###############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_context_embedded' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = construct_graph_lstm_model((plain_features.shape[1],))\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit([arg_context_embedded, pred_context_embedded, embedded_args, embedded_verbs, plain_features], y, \n",
    "          epochs=15, batch_size=64, validation_split = 0.1, \n",
    "          shuffle=True, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiements with out-of-domain test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only for out of domain experiments. Do not use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T14:21:13.954628",
     "start_time": "2017-02-17T14:21:13.936038"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_out_of_domain(model, X_train, y_train, X_test, y_test):\n",
    "    final_res = list()\n",
    "    N_ITERATIONS = 5\n",
    "    for i in xrange(N_ITERATIONS):\n",
    "        print('Eval iter:', i + 1, '/', N_ITERATIONS)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, \n",
    "                                       patience=2, verbose=0, mode='auto')\n",
    "        model.fit(X_train, y_train, nb_epoch=15, \n",
    "                  batch_size=64, validation_split = 0.1, \n",
    "                  shuffle=True, callbacks = [early_stopping],\n",
    "                 verbose = 0)\n",
    "\n",
    "        ev_res = evaluate_model(model, X_test, y_test)\n",
    "        print()\n",
    "        print(pd.DataFrame([ev_res], columns = ['keras_accur', 'keras_loss', 'f1_micro', 'f1_macro', 'accur']))\n",
    "        final_res.append(ev_res)\n",
    "    \n",
    "    return np.array(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:26:02.646008",
     "start_time": "2017-02-18T12:26:02.630666"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    keras_eval = model.evaluate(X_test, y_test)\n",
    "    pred = model.predict(X_test).argmax(axis = 1)\n",
    "    f1_micro = f1_score(pred, y_test.argmax(axis = 1), average = 'micro')\n",
    "    f1_macro = f1_score(pred, y_test.argmax(axis = 1), average = 'macro')\n",
    "    accur = accuracy_score(pred, y_test.argmax(axis = 1))\n",
    "    \n",
    "    return np.array(list(keras_eval) + [f1_micro, f1_macro, accur])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T10:15:31.636957",
     "start_time": "2017-02-17T10:13:07.614626"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ind_plain_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-1c86164ffa53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_plain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_plain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model.fit(ind_plain_features, ind_y, nb_epoch=15, batch_size=64, validation_split = 0.1, \n\u001b[1;32m      4\u001b[0m           shuffle=True, callbacks = [early_stopping])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ind_plain_features' is not defined"
     ]
    }
   ],
   "source": [
    "model = construct_plain_model((ind_plain_features.shape[1],))\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit(ind_plain_features, ind_y, nb_epoch=15, batch_size=64, validation_split = 0.1, \n",
    "          shuffle=True, callbacks = [early_stopping])\n",
    "\n",
    "#model.evaluate(ood_plain_features, ood_y)\n",
    "ev_res = evaluate_model(model, [ood_plain_features], ood_y)\n",
    "print()\n",
    "print(pd.DataFrame([ev_res], columns = ['keras_accur', 'keras_loss', 'f1_micro', 'f1_macro', 'accur']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T11:32:19.012435",
     "start_time": "2017-02-17T11:26:21.034200"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ind_plain_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-3d528230dc12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_plain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_plain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_out_of_domain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_plain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mood_plain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mood_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdescribe_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ind_plain_features' is not defined"
     ]
    }
   ],
   "source": [
    "model = construct_plain_model((ind_plain_features.shape[1],))\n",
    "model_eval = evaluate_out_of_domain(model, ind_plain_features, ind_y, ood_plain_features, ood_y)\n",
    "print(model_eval)\n",
    "describe_cv_result(model_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T11:51:12.792397",
     "start_time": "2017-02-17T11:50:35.226172"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ind_plain_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-4d5f4251cadb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_plain_model_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_plain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model.fit([ind_arg_embed, ind_pred_embed, ind_plain_features], ind_y, nb_epoch=20, batch_size=64, validation_split = 0.1, \n\u001b[1;32m      5\u001b[0m           shuffle=True, callbacks = [early_stopping])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ind_plain_features' is not defined"
     ]
    }
   ],
   "source": [
    "model = construct_plain_model_sparse((ind_plain_features.shape[1],))\n",
    "model.summary()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit([ind_arg_embed, ind_pred_embed, ind_plain_features], ind_y, nb_epoch=20, batch_size=64, validation_split = 0.1, \n",
    "          shuffle=True, callbacks = [early_stopping])\n",
    "#model.evaluate([ood_arg_embed, ood_pred_embed, ood_plain_features], ood_y)\n",
    "\n",
    "ev_res = evaluate_model(model, [ood_arg_embed, ood_pred_embed, ood_plain_features], ood_y)\n",
    "print()\n",
    "print(pd.DataFrame([ev_res], columns = ['keras_accur', 'keras_loss', 'f1_micro', 'f1_macro', 'accur']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T16:02:37.654028",
     "start_time": "2017-02-17T15:54:39.172343"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ind_plain_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-3bc4dc908d2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_plain_model_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_plain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model_eval = evaluate_out_of_domain(model, \n\u001b[1;32m      4\u001b[0m                                     \u001b[0;34m[\u001b[0m\u001b[0mind_arg_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_pred_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_plain_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     [ood_arg_embed, ood_pred_embed, ood_plain_features], ood_y)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ind_plain_features' is not defined"
     ]
    }
   ],
   "source": [
    "model = construct_plain_model_sparse((ind_plain_features.shape[1],))\n",
    "model.summary()\n",
    "model_eval = evaluate_out_of_domain(model, \n",
    "                                    [ind_arg_embed, ind_pred_embed, ind_plain_features], ind_y, \n",
    "                                    [ood_arg_embed, ood_pred_embed, ood_plain_features], ood_y)\n",
    "print(model_eval)\n",
    "describe_cv_result(model_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T13:21:40.582402",
     "start_time": "2017-02-17T13:21:21.643939"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ind_plain_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-37510d149ba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_graph_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_plain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model.fit([\n\u001b[1;32m      5\u001b[0m            \u001b[0;31m#ind_arg_context,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ind_plain_features' is not defined"
     ]
    }
   ],
   "source": [
    "model = construct_graph_lstm_model((ind_plain_features.shape[1],))\n",
    "model.summary()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit([\n",
    "           #ind_arg_context, \n",
    "        #ind_pred_context,   \n",
    "        ind_arg_embed, \n",
    "        ind_pred_embed, \n",
    "        ind_plain_features,\n",
    "        ind_pred_context], \n",
    "#model.fit([ind_arg_context, ind_pred_context, ind_arg_embed, ind_pred_embed, ind_plain_features], \n",
    "           ind_y, nb_epoch=6, batch_size=64, validation_split = 0.1, \n",
    "          shuffle=True, callbacks = [early_stopping])\n",
    "\n",
    "#model.evaluate([ood_arg_context, ood_pred_context, ood_arg_embed, ood_pred_embed, ood_plain_features], ood_y)\n",
    "model.evaluate([\n",
    "    #    ood_arg_context, \n",
    "    #    ood_pred_context,\n",
    "        ood_arg_embed, \n",
    "        ood_pred_embed,\n",
    "        ood_plain_features,\n",
    "        ood_pred_context\n",
    "    ], ood_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T15:41:36.049234",
     "start_time": "2017-02-17T15:25:34.248413"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ind_plain_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-40f22d132761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_graph_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_plain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model_eval = evaluate_out_of_domain(model, \n\u001b[1;32m      4\u001b[0m                                     \u001b[0;34m[\u001b[0m\u001b[0mind_arg_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_pred_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_plain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_pred_context\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     [ood_arg_embed, ood_pred_embed, ood_plain_features, ood_pred_context], ood_y)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ind_plain_features' is not defined"
     ]
    }
   ],
   "source": [
    "model = construct_graph_lstm_model((ind_plain_features.shape[1],))\n",
    "model.summary()\n",
    "model_eval = evaluate_out_of_domain(model, \n",
    "                                    [ind_arg_embed, ind_pred_embed, ind_plain_features, ind_pred_context], ind_y, \n",
    "                                    [ood_arg_embed, ood_pred_embed, ood_plain_features, ood_pred_context], ood_y)\n",
    "print(model_eval)\n",
    "describe_cv_result(model_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only for model comparision. Do not use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T11:43:55.066960",
     "start_time": "2017-02-17T11:43:54.950449"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, *args, **kwargs):\n",
    "    model.fit(X_train, y_train, *args, **kwargs)\n",
    "    \n",
    "    keras_eval = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    pred = model.predict(X_test).argmax(axis = 1)\n",
    "    f1_micro = f1_score(pred, y_test.argmax(axis = 1), average = 'micro')\n",
    "    f1_macro = f1_score(pred, y_test.argmax(axis = 1), average = 'macro')\n",
    "    accur = accuracy_score(pred, y_test.argmax(axis = 1))\n",
    "    \n",
    "    return list(keras_eval) + [f1_micro, f1_macro, accur]\n",
    "    \n",
    "\n",
    "def custom_cross_val(cr_f, X, y, cv, *args, **kwargs):\n",
    "    cr_f().summary()\n",
    "    eval_res = list()\n",
    "    for i, (train, test) in enumerate(cv.split(y)):\n",
    "        model = cr_f()\n",
    "        print('Running Fold', i+1, '/', cv.n_splits)\n",
    "        eval1 = train_and_evaluate_model(model, \n",
    "                                         [X[j][train] for j in range(len(X))], y[train], \n",
    "                                         [X[j][test] for j in range(len(X))], y[test], \n",
    "                                         *args, **kwargs)\n",
    "        \n",
    "        print()\n",
    "        print('Fold result: ', eval1)\n",
    "        eval_res.append(eval1)\n",
    "    \n",
    "    return np.array(eval_res)\n",
    "\n",
    "\n",
    "def describe_cv_result(cv_res):\n",
    "    print(cv_res)\n",
    "    mean_cv_res = cv_res.mean(axis = 0)\n",
    "    std_cv_res = cv_res.std(axis = 0)\n",
    "    print('Mean')\n",
    "    print(pd.DataFrame([mean_cv_res], columns = ['loss', 'keras_accur', 'micro_f1', 'macro_f1', 'accur']))\n",
    "    print('Std')\n",
    "    print(pd.DataFrame([std_cv_res], columns = ['loss', 'keras_accur', 'micro_f1', 'macro_f1', 'accur']))\n",
    "    \n",
    "    \n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-16T16:16:18.702196",
     "start_time": "2017-02-16T16:07:42.457676"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'no_lemma_plain_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-34c687a37e26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcurr_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_lemma_plain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedded_verbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m cv_res = custom_cross_val(lambda : construct_plain_model((curr_features.shape[1],)), \n\u001b[1;32m      3\u001b[0m                           \u001b[0;34m[\u001b[0m\u001b[0mcurr_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                           \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           validation_split = 0., shuffle=True, verbose = 0)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'no_lemma_plain_features' is not defined"
     ]
    }
   ],
   "source": [
    "curr_features = np.concatenate((no_lemma_plain_features, embedded_verbs), axis = 1)\n",
    "cv_res = custom_cross_val(lambda : construct_plain_model((curr_features.shape[1],)), \n",
    "                          [curr_features], \n",
    "                          y, cv = cv, epochs=13, batch_size=64,\n",
    "                          validation_split = 0., shuffle=True, verbose = 0)\n",
    "\n",
    "describe_cv_result(cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-16T15:36:12.375033",
     "start_time": "2017-02-16T15:27:40.793790"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 600)               565800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 400)               1600      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 34)                13634     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 34)                136       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 34)                0         \n",
      "=================================================================\n",
      "Total params: 821,570\n",
      "Trainable params: 820,702\n",
      "Non-trainable params: 868\n",
      "_________________________________________________________________\n",
      "Plain model.\n",
      "Running Fold 1 / 5\n",
      "6075/6075 [==============================] - 0s 73us/step\n",
      "\n",
      "Fold result:  [0.7893890525087898, 0.7787654321576342, 0.7787654320987655, 0.748464499985417, 0.7787654320987655]\n",
      "Plain model.\n",
      "Running Fold 2 / 5\n",
      "6074/6074 [==============================] - 0s 77us/step\n",
      "\n",
      "Fold result:  [0.8428262431134038, 0.7701679289164337, 0.7701679288771814, 0.7602052930761871, 0.7701679288771814]\n",
      "Plain model.\n",
      "Running Fold 3 / 5\n",
      "6074/6074 [==============================] - 0s 81us/step\n",
      "\n",
      "Fold result:  [0.83535985289964, 0.7708264734347007, 0.7708264734935794, 0.7455395481677568, 0.7708264734935792]\n",
      "Plain model.\n",
      "Running Fold 4 / 5\n",
      "6074/6074 [==============================] - 1s 88us/step\n",
      "\n",
      "Fold result:  [0.8298245645056126, 0.7704972012442588, 0.7704972011853803, 0.7404825669973516, 0.7704972011853803]\n",
      "Plain model.\n",
      "Running Fold 5 / 5\n",
      "6074/6074 [==============================] - 1s 110us/step\n",
      "\n",
      "Fold result:  [0.8211032497400039, 0.7795521895627188, 0.7795521896608495, 0.7562156829385229, 0.7795521896608495]\n",
      "[[0.78938905 0.77876543 0.77876543 0.7484645  0.77876543]\n",
      " [0.84282624 0.77016793 0.77016793 0.76020529 0.77016793]\n",
      " [0.83535985 0.77082647 0.77082647 0.74553955 0.77082647]\n",
      " [0.82982456 0.7704972  0.7704972  0.74048257 0.7704972 ]\n",
      " [0.82110325 0.77955219 0.77955219 0.75621568 0.77955219]]\n",
      "Mean\n",
      "       loss  keras_accur  micro_f1  macro_f1     accur\n",
      "0  0.823701     0.773962  0.773962  0.750182  0.773962\n",
      "Std\n",
      "       loss  keras_accur  micro_f1  macro_f1     accur\n",
      "0  0.018565     0.004256  0.004256  0.007148  0.004256\n"
     ]
    }
   ],
   "source": [
    "cv_res = custom_cross_val(lambda : construct_plain_model((plain_features.shape[1],)), \n",
    "                          [plain_features], \n",
    "                          y, cv = cv, epochs=13, batch_size=64,\n",
    "                          validation_split = 0., shuffle=True, verbose = 0)\n",
    "\n",
    "describe_cv_result(cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-16T14:48:33.877302",
     "start_time": "2017-02-16T14:45:18.196997"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 600)               925800    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 400)               1600      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 34)                13634     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 34)                136       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 34)                0         \n",
      "=================================================================\n",
      "Total params: 1,181,570\n",
      "Trainable params: 1,180,702\n",
      "Non-trainable params: 868\n",
      "_________________________________________________________________\n",
      "Plain model.\n",
      "Running Fold 1 / 5\n",
      "6075/6075 [==============================] - 1s 116us/step\n",
      "\n",
      "Fold result:  [0.765932907626462, 0.7988477365862685, 0.7988477366255144, 0.7734107816654796, 0.7988477366255144]\n",
      "Plain model.\n",
      "Running Fold 2 / 5\n",
      "6074/6074 [==============================] - 1s 122us/step\n",
      "\n",
      "Fold result:  [0.8090638996426668, 0.7945340796053939, 0.7945340796838986, 0.7772531206937506, 0.7945340796838986]\n",
      "Plain model.\n",
      "Running Fold 3 / 5\n",
      "6074/6074 [==============================] - 1s 136us/step\n",
      "\n",
      "Fold result:  [0.7897385406698253, 0.7950279880676923, 0.7950279881461969, 0.7735108065936008, 0.7950279881461969]\n",
      "Plain model.\n",
      "Running Fold 4 / 5\n",
      "6074/6074 [==============================] - 1s 134us/step\n",
      "\n",
      "Fold result:  [0.8049950259352814, 0.7886071780578141, 0.7886071781363188, 0.7700962084979931, 0.7886071781363188]\n",
      "Plain model.\n",
      "Running Fold 5 / 5\n",
      "6074/6074 [==============================] - 1s 149us/step\n",
      "\n",
      "Fold result:  [0.7746345994010896, 0.7945340797231509, 0.7945340796838986, 0.7741741222012968, 0.7945340796838986]\n",
      "[[0.76593291 0.79884774 0.79884774 0.77341078 0.79884774]\n",
      " [0.8090639  0.79453408 0.79453408 0.77725312 0.79453408]\n",
      " [0.78973854 0.79502799 0.79502799 0.77351081 0.79502799]\n",
      " [0.80499503 0.78860718 0.78860718 0.77009621 0.78860718]\n",
      " [0.7746346  0.79453408 0.79453408 0.77417412 0.79453408]]\n",
      "Mean\n",
      "       loss  keras_accur  micro_f1  macro_f1    accur\n",
      "0  0.788873      0.79431   0.79431  0.773689  0.79431\n",
      "Std\n",
      "       loss  keras_accur  micro_f1  macro_f1     accur\n",
      "0  0.016717     0.003278  0.003278  0.002278  0.003278\n"
     ]
    }
   ],
   "source": [
    "single_chunk = np.concatenate((embedded_args, embedded_verbs, plain_features), axis = 1)\n",
    "cv_res = custom_cross_val(lambda : construct_plain_model((single_chunk.shape[1],)), \n",
    "                          [single_chunk], \n",
    "                          y, cv = cv, epochs=13, batch_size=64,\n",
    "                          validation_split = 0., shuffle=True, verbose = 0)\n",
    "\n",
    "describe_cv_result(cv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T16:23:57.011641",
     "start_time": "2017-02-17T16:07:49.454278"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "pred_embed (InputLayer)         (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "arg_embed (InputLayer)          (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_categorical (InputLayer)  (None, 990)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 100)          30100       pred_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 100)          30100       arg_embed[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 400)          396400      input_categorical[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 100)          400         dense_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 100)          400         dense_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 400)          1600        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 100)          0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 100)          0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 400)          0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 600)          0           activation_77[0][0]              \n",
      "                                                                 activation_78[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 600)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 400)          240400      dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 400)          1600        dense_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 400)          0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 400)          0           activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 44)           17644       dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 44)           176         dense_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 44)           0           batch_normalization_80[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 718,820\n",
      "Trainable params: 716,732\n",
      "Non-trainable params: 2,088\n",
      "__________________________________________________________________________________________________\n",
      "Running Fold 1 / 5\n",
      "10541/10541 [==============================] - 2s 204us/step\n",
      "\n",
      "Fold result:  [0.6577002111221217, 0.8126363722606963, 0.8126363722606963, 0.7853088545072477, 0.8126363722606963]\n",
      "Running Fold 2 / 5\n",
      "10540/10540 [==============================] - 2s 212us/step\n",
      "\n",
      "Fold result:  [0.6710936888119301, 0.804838709654799, 0.8048387096774193, 0.7726367565472689, 0.8048387096774193]\n",
      "Running Fold 3 / 5\n",
      "10540/10540 [==============================] - 2s 223us/step\n",
      "\n",
      "Fold result:  [0.6850881543229608, 0.8060721062844799, 0.8060721062618595, 0.7772395776418514, 0.8060721062618595]\n",
      "Running Fold 4 / 5\n",
      "10540/10540 [==============================] - 2s 231us/step\n",
      "\n",
      "Fold result:  [0.6682090597767983, 0.8074952561443626, 0.8074952561669829, 0.770870075588247, 0.8074952561669829]\n",
      "Running Fold 5 / 5\n",
      "10540/10540 [==============================] - 3s 237us/step\n",
      "\n",
      "Fold result:  [0.6917032712777154, 0.8018026565238692, 0.8018026565464895, 0.7733449592452944, 0.8018026565464895]\n",
      "[[0.65770021 0.81263637 0.81263637 0.78530885 0.81263637]\n",
      " [0.67109369 0.80483871 0.80483871 0.77263676 0.80483871]\n",
      " [0.68508815 0.80607211 0.80607211 0.77723958 0.80607211]\n",
      " [0.66820906 0.80749526 0.80749526 0.77087008 0.80749526]\n",
      " [0.69170327 0.80180266 0.80180266 0.77334496 0.80180266]]\n",
      "Mean\n",
      "       loss  keras_accur  micro_f1  macro_f1     accur\n",
      "0  0.674759     0.806569  0.806569   0.77588  0.806569\n",
      "Std\n",
      "       loss  keras_accur  micro_f1  macro_f1     accur\n",
      "0  0.012175     0.003567  0.003567  0.005154  0.003567\n"
     ]
    }
   ],
   "source": [
    "cv_res = custom_cross_val(lambda : construct_plain_model_sparse(plain_features.shape[1], \n",
    "                                                                embeddings.vector_size, \n",
    "                                                                y.shape[1]), \n",
    "                          [embedded_args, embedded_verbs, plain_features], y, \n",
    "                          cv = cv, epochs=13, batch_size=300,\n",
    "                          validation_split = 0., shuffle=True, verbose = 0)\n",
    "\n",
    "describe_cv_result(cv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-16T14:16:02.109004",
     "start_time": "2017-02-16T13:49:33.683794"
    }
   },
   "outputs": [],
   "source": [
    "cv_res = custom_cross_val(lambda : construct_graph_lstm_model((plain_features.shape[1],)), \n",
    "                          [arg_context_embedded, \n",
    "                           pred_context_embedded, \n",
    "                           embedded_args, \n",
    "                           embedded_verbs,\n",
    "                           plain_features], y, \n",
    "                          cv = cv, epochs=6, batch_size=64, validation_split = 0., \n",
    "                          shuffle=True)\n",
    "\n",
    "describe_cv_result(cv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:59:05.065644",
     "start_time": "2017-02-18T12:59:05.006966"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ids, test_ids = train_test_split(X_orig.ex_id.unique(), test_size=0.2, random_state=42)\n",
    "train_ids = set(train_ids.tolist())\n",
    "test_ids = set(test_ids.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T13:04:58.313461",
     "start_time": "2017-02-18T13:04:58.267195"
    }
   },
   "outputs": [],
   "source": [
    "train_selector_pd = X_orig.ex_id.isin(train_ids)\n",
    "test_selector_pd = X_orig.ex_id.isin(test_ids)\n",
    "train_selector = train_selector_pd.values\n",
    "test_selector = test_selector_pd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T11:29:41.203903",
     "start_time": "2017-02-18T11:28:02.698301"
    }
   },
   "outputs": [],
   "source": [
    "train_data = {k : data[k] for k in train_ids}\n",
    "test_data = {k : data[k] for k in test_ids}\n",
    "\n",
    "with open(os.path.join(main_model_path, 'train_data.json'), 'w') as f:\n",
    "    json.dump(train_data, f)\n",
    "\n",
    "with open(os.path.join(main_model_path, 'test_data.json'), 'w') as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T13:00:50.036868",
     "start_time": "2017-02-18T12:59:10.294248"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37893 samples, validate on 4211 samples\n",
      "Epoch 1/10\n",
      "37893/37893 [==============================] - 11s 290us/step - loss: 1.9349 - acc: 0.5656 - val_loss: 1.1430 - val_acc: 0.7421\n",
      "Epoch 2/10\n",
      "37893/37893 [==============================] - 9s 232us/step - loss: 1.1200 - acc: 0.7305 - val_loss: 0.8598 - val_acc: 0.7727\n",
      "Epoch 3/10\n",
      "37893/37893 [==============================] - 9s 232us/step - loss: 0.9209 - acc: 0.7613 - val_loss: 0.7801 - val_acc: 0.7822\n",
      "Epoch 4/10\n",
      "37893/37893 [==============================] - 9s 231us/step - loss: 0.8213 - acc: 0.7741 - val_loss: 0.7397 - val_acc: 0.7903\n",
      "Epoch 5/10\n",
      "37893/37893 [==============================] - 9s 229us/step - loss: 0.7521 - acc: 0.7903 - val_loss: 0.7198 - val_acc: 0.7948\n",
      "Epoch 6/10\n",
      "37893/37893 [==============================] - 9s 230us/step - loss: 0.7003 - acc: 0.7981 - val_loss: 0.7003 - val_acc: 0.7920\n",
      "Epoch 7/10\n",
      "37893/37893 [==============================] - 9s 231us/step - loss: 0.6519 - acc: 0.8097 - val_loss: 0.6985 - val_acc: 0.8019\n",
      "Epoch 8/10\n",
      "37893/37893 [==============================] - 9s 232us/step - loss: 0.6229 - acc: 0.8151 - val_loss: 0.6913 - val_acc: 0.8024\n",
      "Epoch 9/10\n",
      "37893/37893 [==============================] - 9s 231us/step - loss: 0.5941 - acc: 0.8228 - val_loss: 0.7003 - val_acc: 0.7993\n",
      "Epoch 10/10\n",
      "37893/37893 [==============================] - 9s 230us/step - loss: 0.5611 - acc: 0.8335 - val_loss: 0.6884 - val_acc: 0.8027\n",
      "10597/10597 [==============================] - 1s 102us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6926666886275118, 0.8026800037746532]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_from_nparray_list(nparray_list, selector):\n",
    "    return [e[selector] for e in nparray_list]\n",
    "\n",
    "model = construct_plain_model_sparse(plain_features.shape[1], embeddings.vector_size, y.shape[1])\n",
    "model.fit(select_from_nparray_list([embedded_args, embedded_verbs, plain_features], train_selector),\n",
    "          select_from_nparray_list([y], train_selector), \n",
    "          epochs=10, batch_size=64, validation_split = 0.1, shuffle=True)\n",
    "\n",
    "model.evaluate(select_from_nparray_list([embedded_args, embedded_verbs, plain_features], test_selector), \n",
    "               select_from_nparray_list([y], test_selector))\n",
    "model.save(os.path.join(main_model_path, 'neural_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T15:55:42.486066",
     "start_time": "2017-02-18T15:55:39.780097"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10597/10597 [==============================] - 1s 108us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.69266669, 0.80268   , 0.80268   , 0.77108236, 0.80268   ])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hold-out evaluation.\n",
    "\n",
    "evaluate_model(model,\n",
    "               select_from_nparray_list([embedded_args, embedded_verbs, plain_features], test_selector), \n",
    "               select_from_nparray_list([y], test_selector)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T15:56:50.418354",
     "start_time": "2017-02-18T15:56:40.777599"
    }
   },
   "outputs": [],
   "source": [
    "pred = model.predict(select_from_nparray_list([embedded_args, embedded_verbs, plain_features], test_selector))\n",
    "\n",
    "test_examples_to_store = X_orig.loc[test_selector_pd[test_selector_pd].index, :].loc[:, ['arg_address', 'ex_id']]\n",
    "test_data = {k : data[k] for k in test_ids}\n",
    "\n",
    "\n",
    "for index, (pd_index, row) in enumerate(test_examples_to_store.iterrows()):\n",
    "    ex = test_data[row['ex_id']]\n",
    "    arg_addr = row['arg_address']\n",
    "    sent = ex[arg_addr[0]]\n",
    "    token = sent[arg_addr[1]]\n",
    "    cl = pred[index]\n",
    "    predicted_role = label_encoder.inverse_transform(np.array([cl]))[0]\n",
    "    actual_role = label_encoder.inverse_transform(np.array([select_from_nparray_list([y], test_selector)[0][index]]))[0]\n",
    "    \n",
    "    token['rolepred1'] = actual_role\n",
    "    token['rolepred2'] = predicted_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T15:59:40.060358",
     "start_time": "2017-02-18T15:59:26.421186"
    }
   },
   "outputs": [],
   "source": [
    "with open('./test_data_ann_1.json', 'w') as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brat convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts results to brat annotation for inspecting.\n",
    "# Needs framebank_preprocessing from http://nlp.isa.ru/framebank_parser/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T17:15:09.301844",
     "start_time": "2017-02-18T17:14:58.429103"
    }
   },
   "outputs": [],
   "source": [
    "!python2.7 ./framebank_preprocessing/convert_corpus_to_brat.py --inputFile=./test_data_ann_1.json --outputDir=./brat_ann2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T17:27:49.179234",
     "start_time": "2017-02-18T17:27:30.320938"
    }
   },
   "outputs": [],
   "source": [
    "!python2.7 ./framebank_preprocessing/convert_corpus_to_brat.py --inputFile=./test_data_ann_1.json --outputDir=./syntaxnet_1/ --converter=syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-11 20:56:20 - Loading corpus data...\n",
      "2018-03-11 20:56:22 - Done.\n",
      "2018-03-11 20:56:22 - Creating verb-example index...\n",
      "2018-03-11 20:56:22 - Done.\n",
      "2018-03-11 20:56:22 - Converting and saving...\n",
      "2018-03-11 20:56:23 - Done.\n",
      "2018-03-11 20:56:23 - Generating brat configuration files...\n",
      "2018-03-11 20:56:23 - Done.\n"
     ]
    }
   ],
   "source": [
    "!export PYTHONPATH=../ && python2.7 ./convert_corpus_to_brat.py --inputFile=./test_data_ann_1.json --outputDir=./brat_ann2/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "51px",
    "width": "313px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "505px",
    "left": "0px",
    "right": "1122px",
    "top": "110px",
    "width": "158px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
