{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:14:55.909843",
     "start_time": "2017-02-18T12:14:54.905927"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use only one GPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../isanlp/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress tensorflow memory appetites\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:14:56.607418",
     "start_time": "2017-02-18T12:14:55.911842"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check available GPUs\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import isanlp\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(31)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:43:32.199510",
     "start_time": "2017-02-18T12:42:24.396928"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:  59861\n"
     ]
    }
   ],
   "source": [
    "input_data_path = '../../data/preprocessed_framebank/annotated_corpus.json'\n",
    "\n",
    "with open(input_data_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "print('Number of examples: ', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:05.953030",
     "start_time": "2017-02-18T12:16:03.543901"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of verbs:  803\n",
      "Number of left verbs:  572\n"
     ]
    }
   ],
   "source": [
    "from convert_corpus_to_brat import make_text, create_verb_example_index\n",
    "\n",
    "min_n_examples = 10\n",
    "\n",
    "verb_index = create_verb_example_index(data)\n",
    "print('Original number of verbs: ', len(verb_index))\n",
    "\n",
    "stat = sorted([(verb, len(examples)) for verb, examples in verb_index.items()], \n",
    "              key = lambda x: x[1], reverse=True)\n",
    "\n",
    "verbs_to_keep = [verb for verb, count in stat if count >= min_n_examples]\n",
    "print('Number of left verbs: ', len(verbs_to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:06.010150",
     "start_time": "2017-02-18T12:16:05.954506"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of framebank examples left:  32612\n"
     ]
    }
   ],
   "source": [
    "examples = list()\n",
    "\n",
    "for verb in verbs_to_keep:\n",
    "    indexes = verb_index[verb]\n",
    "    \n",
    "    for ind in indexes:\n",
    "        examples.append((ind, data[ind]))\n",
    "\n",
    "print('Number of framebank examples left: ', len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_corpus_path = '../../data/cleared_corpus.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cleared_corpus_path, 'w') as f:\n",
    "    json.dump(examples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cleared_corpus_path, 'r') as f:\n",
    "    examples = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_data_path = '../../data/results_final_fixed.pckl'\n",
    "with open(ling_data_path, 'rb') as f:\n",
    "    ling_data = pickle.load(f)\n",
    "\n",
    "ling_data_cache = {k: v for k,v in ling_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp.annotation_repr import CSentence\n",
    "\n",
    "\n",
    "def find_address_by_offset(offset, ling_ann):\n",
    "    for tok_num, tok in enumerate(ling_ann['tokens']):\n",
    "        if tok.begin <= offset and offset < tok.end:\n",
    "            break\n",
    "    \n",
    "    for sent_num, sent in enumerate(ling_ann['sentences']):\n",
    "        if sent.begin <= tok_num and tok_num < sent.end:\n",
    "            break\n",
    "    \n",
    "    return sent_num, tok_num - sent.begin\n",
    "\n",
    "\n",
    "def process_arg_pred(feature_extractor, ling_cache, ex_id, pred, args, example):\n",
    "    feature_sets = list()\n",
    "    \n",
    "    text, offset_index = make_text(example, 0)\n",
    "    ling_ann = ling_cache[ex_id]\n",
    "    \n",
    "    pred_offset = offset_index[(pred[0], pred[1])]\n",
    "    pred_ling_sent, pred_ling_word = find_address_by_offset(pred_offset, ling_ann)\n",
    "    \n",
    "    for arg in args:\n",
    "        arg_offset = offset_index[(arg[0], arg[1])]\n",
    "        arg_ling_sent, arg_ling_word = find_address_by_offset(arg_offset, ling_ann)\n",
    "        \n",
    "        fb_pred_word = example[pred[0]][pred[1]]\n",
    "        fb_arg_word = example[arg[0]][arg[1]]\n",
    "        \n",
    "        role = fb_arg_word['rolepred1']\n",
    "\n",
    "        if arg_ling_sent != pred_ling_sent:\n",
    "            global num_of_errors\n",
    "            num_of_errors += 1\n",
    "            # We miss some examples due to mistakes in framebank or discrepancy in \n",
    "            # automatica annotation\n",
    "            print('Error #{}'.format(num_of_errors))\n",
    "            continue\n",
    "        \n",
    "        features = feature_extractor.extract_features(pred_ling_word, \n",
    "                                                      arg_ling_word, \n",
    "                                                      ling_ann['postag'][arg_ling_sent],\n",
    "                                                      ling_ann['morph'][arg_ling_sent],\n",
    "                                                      ling_ann['lemma'][arg_ling_sent],\n",
    "                                                      ling_ann['syntax_dep_tree'][arg_ling_sent])\n",
    "                    \n",
    "        feature_sets.append((features, role, ex_id, arg))\n",
    "    \n",
    "    return feature_sets\n",
    "\n",
    "\n",
    "def process_example(feature_extractor, ling_cache, ex_id, sentences):\n",
    "    pred = None\n",
    "    args = list()\n",
    "    for sent_num, sent in enumerate(sentences):\n",
    "        for word_num, word in enumerate(sent):\n",
    "            if 'rank' in word and word['rank'] == u'Предикат':\n",
    "                pred = (sent_num, word_num)\n",
    "            elif 'rolepred1' in word:\n",
    "                args.append((sent_num, word_num))\n",
    "    \n",
    "    return process_arg_pred(feature_extractor, ling_cache, ex_id, pred, args, sentences)\n",
    "\n",
    "\n",
    "num_of_errors = 0\n",
    "def prepare_train_data(examples, ling_data_cache, feature_extractor):\n",
    "    feature_sets = []\n",
    "    for ex_num, (ex_id, ex) in enumerate(examples):    \n",
    "        if ex_num % 100 == 0:\n",
    "            print('{0:.2f}%'.format((ex_num / len(examples)) * 100.))\n",
    "            \n",
    "        feature_sets += process_example(feature_extractor, ling_data_cache, ex_id, ex)\n",
    "\n",
    "    print('Number of training examples:', len(feature_sets))\n",
    "    return feature_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model_path_root = '../../data/models_new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!: Choose feature model here\n",
    "from isanlp_srl_framebank.processor_srl_framebank import FeatureModelDefault\n",
    "feature_model = FeatureModelDefault()\n",
    "main_model_path = os.path.join(main_model_path_root, 'known_preds')\n",
    "\n",
    "# from isanlp_srl_framebank.processor_srl_framebank import FeatureModelUnknownPredicates\n",
    "# feature_model = FeatureModelUnknownPredicates()\n",
    "# main_model_path = os.path.join(main_model_path_root, 'unknown_preds')\n",
    "\n",
    "with open(os.path.join(main_model_path, 'feature_model.pckl'), 'wb') as f:\n",
    "    pickle.dump(feature_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n",
      "Error #1\n",
      "0.31%\n",
      "Error #2\n",
      "0.61%\n",
      "0.92%\n",
      "Error #3\n",
      "1.23%\n",
      "Error #4\n",
      "1.53%\n",
      "1.84%\n",
      "2.15%\n",
      "Error #5\n",
      "2.45%\n",
      "2.76%\n",
      "3.07%\n",
      "3.37%\n",
      "3.68%\n",
      "3.99%\n",
      "4.29%\n",
      "4.60%\n",
      "4.91%\n",
      "Error #6\n",
      "Error #7\n",
      "5.21%\n",
      "5.52%\n",
      "5.83%\n",
      "Error #8\n",
      "Error #9\n",
      "Error #10\n",
      "Error #11\n",
      "Error #12\n",
      "Error #13\n",
      "Error #14\n",
      "Error #15\n",
      "Error #16\n",
      "Error #17\n",
      "Error #18\n",
      "Error #19\n",
      "Error #20\n",
      "Error #21\n",
      "Error #22\n",
      "Error #23\n",
      "Error #24\n",
      "Error #25\n",
      "Error #26\n",
      "Error #27\n",
      "Error #28\n",
      "Error #29\n",
      "Error #30\n",
      "Error #31\n",
      "Error #32\n",
      "Error #33\n",
      "Error #34\n",
      "Error #35\n",
      "Error #36\n",
      "6.13%\n",
      "Error #37\n",
      "Error #38\n",
      "Error #39\n",
      "Error #40\n",
      "Error #41\n",
      "Error #42\n",
      "Error #43\n",
      "Error #44\n",
      "Error #45\n",
      "Error #46\n",
      "Error #47\n",
      "Error #48\n",
      "Error #49\n",
      "Error #50\n",
      "Error #51\n",
      "Error #52\n",
      "Error #53\n",
      "Error #54\n",
      "Error #55\n",
      "Error #56\n",
      "Error #57\n",
      "Error #58\n",
      "Error #59\n",
      "Error #60\n",
      "Error #61\n",
      "Error #62\n",
      "Error #63\n",
      "Error #64\n",
      "Error #65\n",
      "Error #66\n",
      "Error #67\n",
      "Error #68\n",
      "Error #69\n",
      "Error #70\n",
      "Error #71\n",
      "Error #72\n",
      "Error #73\n",
      "Error #74\n",
      "Error #75\n",
      "Error #76\n",
      "Error #77\n",
      "Error #78\n",
      "Error #79\n",
      "Error #80\n",
      "Error #81\n",
      "Error #82\n",
      "Error #83\n",
      "Error #84\n",
      "Error #85\n",
      "Error #86\n",
      "Error #87\n",
      "Error #88\n",
      "Error #89\n",
      "Error #90\n",
      "Error #91\n",
      "Error #92\n",
      "Error #93\n",
      "Error #94\n",
      "Error #95\n",
      "Error #96\n",
      "Error #97\n",
      "Error #98\n",
      "Error #99\n",
      "Error #100\n",
      "Error #101\n",
      "Error #102\n",
      "Error #103\n",
      "6.44%\n",
      "Error #104\n",
      "6.75%\n",
      "Error #105\n",
      "7.05%\n",
      "Error #106\n",
      "Error #107\n",
      "Error #108\n",
      "Error #109\n",
      "Error #110\n",
      "Error #111\n",
      "7.36%\n",
      "7.67%\n",
      "Error #112\n",
      "7.97%\n",
      "8.28%\n",
      "Error #113\n",
      "8.59%\n",
      "Error #114\n",
      "Error #115\n",
      "8.89%\n",
      "9.20%\n",
      "9.51%\n",
      "Error #116\n",
      "9.81%\n",
      "Error #117\n",
      "10.12%\n",
      "10.43%\n",
      "Error #118\n",
      "Error #119\n",
      "10.73%\n",
      "Error #120\n",
      "11.04%\n",
      "Error #121\n",
      "11.35%\n",
      "11.65%\n",
      "11.96%\n",
      "12.27%\n",
      "Error #122\n",
      "Error #123\n",
      "Error #124\n",
      "12.57%\n",
      "Error #125\n",
      "12.88%\n",
      "Error #126\n",
      "13.19%\n",
      "Error #127\n",
      "Error #128\n",
      "13.49%\n",
      "Error #129\n",
      "Error #130\n",
      "13.80%\n",
      "Error #131\n",
      "14.11%\n",
      "Error #132\n",
      "Error #133\n",
      "Error #134\n",
      "Error #135\n",
      "Error #136\n",
      "Error #137\n",
      "Error #138\n",
      "Error #139\n",
      "Error #140\n",
      "Error #141\n",
      "Error #142\n",
      "Error #143\n",
      "14.41%\n",
      "Error #144\n",
      "Error #145\n",
      "14.72%\n",
      "15.03%\n",
      "15.33%\n",
      "15.64%\n",
      "Error #146\n",
      "Error #147\n",
      "Error #148\n",
      "15.95%\n",
      "Error #149\n",
      "Error #150\n",
      "Error #151\n",
      "16.25%\n",
      "Error #152\n",
      "16.56%\n",
      "Error #153\n",
      "16.86%\n",
      "17.17%\n",
      "Error #154\n",
      "Error #155\n",
      "17.48%\n",
      "17.78%\n",
      "Error #156\n",
      "18.09%\n",
      "Error #157\n",
      "Error #158\n",
      "Error #159\n",
      "Error #160\n",
      "18.40%\n",
      "18.70%\n",
      "19.01%\n",
      "19.32%\n",
      "Error #161\n",
      "19.62%\n",
      "Error #162\n",
      "Error #163\n",
      "Error #164\n",
      "Error #165\n",
      "Error #166\n",
      "Error #167\n",
      "19.93%\n",
      "Error #168\n",
      "Error #169\n",
      "Error #170\n",
      "20.24%\n",
      "20.54%\n",
      "20.85%\n",
      "Error #171\n",
      "Error #172\n",
      "21.16%\n",
      "Error #173\n",
      "21.46%\n",
      "21.77%\n",
      "22.08%\n",
      "Error #174\n",
      "Error #175\n",
      "22.38%\n",
      "22.69%\n",
      "Error #176\n",
      "23.00%\n",
      "23.30%\n",
      "Error #177\n",
      "Error #178\n",
      "23.61%\n",
      "23.92%\n",
      "Error #179\n",
      "Error #180\n",
      "24.22%\n",
      "Error #181\n",
      "24.53%\n",
      "24.84%\n",
      "25.14%\n",
      "25.45%\n",
      "25.76%\n",
      "26.06%\n",
      "26.37%\n",
      "Error #182\n",
      "Error #183\n",
      "26.68%\n",
      "Error #184\n",
      "26.98%\n",
      "Error #185\n",
      "27.29%\n",
      "27.60%\n",
      "27.90%\n",
      "Error #186\n",
      "Error #187\n",
      "Error #188\n",
      "Error #189\n",
      "Error #190\n",
      "Error #191\n",
      "Error #192\n",
      "Error #193\n",
      "28.21%\n",
      "28.52%\n",
      "28.82%\n",
      "Error #194\n",
      "29.13%\n",
      "Error #195\n",
      "29.44%\n",
      "29.74%\n",
      "30.05%\n",
      "Error #196\n",
      "Error #197\n",
      "Error #198\n",
      "Error #199\n",
      "30.36%\n",
      "Error #200\n",
      "Error #201\n",
      "30.66%\n",
      "Error #202\n",
      "30.97%\n",
      "31.28%\n",
      "Error #203\n",
      "31.58%\n",
      "31.89%\n",
      "32.20%\n",
      "Error #204\n",
      "32.50%\n",
      "Error #205\n",
      "Error #206\n",
      "Error #207\n",
      "Error #208\n",
      "Error #209\n",
      "Error #210\n",
      "Error #211\n",
      "Error #212\n",
      "Error #213\n",
      "Error #214\n",
      "32.81%\n",
      "Error #215\n",
      "Error #216\n",
      "Error #217\n",
      "Error #218\n",
      "Error #219\n",
      "33.12%\n",
      "Error #220\n",
      "33.42%\n",
      "Error #221\n",
      "Error #222\n",
      "33.73%\n",
      "34.04%\n",
      "34.34%\n",
      "34.65%\n",
      "34.96%\n",
      "35.26%\n",
      "35.57%\n",
      "35.88%\n",
      "36.18%\n",
      "36.49%\n",
      "Error #223\n",
      "Error #224\n",
      "36.80%\n",
      "37.10%\n",
      "Error #225\n",
      "Error #226\n",
      "37.41%\n",
      "Error #227\n",
      "37.72%\n",
      "38.02%\n",
      "38.33%\n",
      "38.64%\n",
      "38.94%\n",
      "Error #228\n",
      "Error #229\n",
      "Error #230\n",
      "Error #231\n",
      "39.25%\n",
      "Error #232\n",
      "39.56%\n",
      "39.86%\n",
      "Error #233\n",
      "40.17%\n",
      "40.48%\n",
      "Error #234\n",
      "Error #235\n",
      "Error #236\n",
      "Error #237\n",
      "Error #238\n",
      "40.78%\n",
      "41.09%\n",
      "Error #239\n",
      "41.40%\n",
      "41.70%\n",
      "42.01%\n",
      "42.32%\n",
      "Error #240\n",
      "42.62%\n",
      "42.93%\n",
      "43.24%\n",
      "Error #241\n",
      "Error #242\n",
      "43.54%\n",
      "43.85%\n",
      "Error #243\n",
      "Error #244\n",
      "44.16%\n",
      "Error #245\n",
      "Error #246\n",
      "Error #247\n",
      "44.46%\n",
      "44.77%\n",
      "45.08%\n",
      "45.38%\n",
      "Error #248\n",
      "Error #249\n",
      "Error #250\n",
      "45.69%\n",
      "46.00%\n",
      "46.30%\n",
      "46.61%\n",
      "Error #251\n",
      "46.92%\n",
      "Error #252\n",
      "47.22%\n",
      "47.53%\n",
      "Error #253\n",
      "Error #254\n",
      "Error #255\n",
      "Error #256\n",
      "Error #257\n",
      "Error #258\n",
      "Error #259\n",
      "Error #260\n",
      "47.84%\n",
      "Error #261\n",
      "48.14%\n",
      "Error #262\n",
      "Error #263\n",
      "48.45%\n",
      "Error #264\n",
      "Error #265\n",
      "Error #266\n",
      "48.76%\n",
      "Error #267\n",
      "49.06%\n",
      "Error #268\n",
      "49.37%\n",
      "Error #269\n",
      "49.67%\n",
      "Error #270\n",
      "Error #271\n",
      "49.98%\n",
      "Error #272\n",
      "50.29%\n",
      "50.59%\n",
      "50.90%\n",
      "Error #273\n",
      "Error #274\n",
      "Error #275\n",
      "Error #276\n",
      "51.21%\n",
      "51.51%\n",
      "51.82%\n",
      "Error #277\n",
      "52.13%\n",
      "Error #278\n",
      "Error #279\n",
      "52.43%\n",
      "Error #280\n",
      "52.74%\n",
      "53.05%\n",
      "Error #281\n",
      "Error #282\n",
      "53.35%\n",
      "Error #283\n",
      "53.66%\n",
      "53.97%\n",
      "Error #284\n",
      "54.27%\n",
      "Error #285\n",
      "Error #286\n",
      "54.58%\n",
      "Error #287\n",
      "54.89%\n",
      "55.19%\n",
      "Error #288\n",
      "55.50%\n",
      "Error #289\n",
      "Error #290\n",
      "Error #291\n",
      "55.81%\n",
      "56.11%\n",
      "Error #292\n",
      "56.42%\n",
      "Error #293\n",
      "56.73%\n",
      "57.03%\n",
      "Error #294\n",
      "57.34%\n",
      "57.65%\n",
      "Error #295\n",
      "Error #296\n",
      "Error #297\n",
      "Error #298\n",
      "Error #299\n",
      "Error #300\n",
      "Error #301\n",
      "57.95%\n",
      "58.26%\n",
      "58.57%\n",
      "58.87%\n",
      "59.18%\n",
      "Error #302\n",
      "59.49%\n",
      "Error #303\n",
      "59.79%\n",
      "60.10%\n",
      "Error #304\n",
      "Error #305\n",
      "Error #306\n",
      "Error #307\n",
      "60.41%\n",
      "Error #308\n",
      "60.71%\n",
      "Error #309\n",
      "61.02%\n",
      "61.33%\n",
      "Error #310\n",
      "Error #311\n",
      "Error #312\n",
      "61.63%\n",
      "Error #313\n",
      "61.94%\n",
      "Error #314\n",
      "Error #315\n",
      "Error #316\n",
      "62.25%\n",
      "62.55%\n",
      "62.86%\n",
      "Error #317\n",
      "Error #318\n",
      "63.17%\n",
      "63.47%\n",
      "63.78%\n",
      "64.09%\n",
      "Error #319\n",
      "64.39%\n",
      "64.70%\n",
      "65.01%\n",
      "Error #320\n",
      "Error #321\n",
      "65.31%\n",
      "Error #322\n",
      "65.62%\n",
      "65.93%\n",
      "66.23%\n",
      "Error #323\n",
      "Error #324\n",
      "Error #325\n",
      "Error #326\n",
      "Error #327\n",
      "Error #328\n",
      "Error #329\n",
      "Error #330\n",
      "Error #331\n",
      "Error #332\n",
      "Error #333\n",
      "Error #334\n",
      "66.54%\n",
      "66.85%\n",
      "67.15%\n",
      "67.46%\n",
      "Error #335\n",
      "67.77%\n",
      "68.07%\n",
      "Error #336\n",
      "Error #337\n",
      "68.38%\n",
      "Error #338\n",
      "Error #339\n",
      "Error #340\n",
      "Error #341\n",
      "Error #342\n",
      "Error #343\n",
      "Error #344\n",
      "Error #345\n",
      "Error #346\n",
      "Error #347\n",
      "Error #348\n",
      "Error #349\n",
      "Error #350\n",
      "Error #351\n",
      "Error #352\n",
      "Error #353\n",
      "68.69%\n",
      "Error #354\n",
      "Error #355\n",
      "Error #356\n",
      "68.99%\n",
      "Error #357\n",
      "69.30%\n",
      "69.61%\n",
      "69.91%\n",
      "70.22%\n",
      "70.53%\n",
      "Error #358\n",
      "Error #359\n",
      "70.83%\n",
      "71.14%\n",
      "Error #360\n",
      "Error #361\n",
      "Error #362\n",
      "71.45%\n",
      "71.75%\n",
      "72.06%\n",
      "Error #363\n",
      "72.37%\n",
      "72.67%\n",
      "Error #364\n",
      "72.98%\n",
      "Error #365\n",
      "73.29%\n",
      "73.59%\n",
      "73.90%\n",
      "Error #366\n",
      "Error #367\n",
      "74.21%\n",
      "74.51%\n",
      "Error #368\n",
      "74.82%\n",
      "75.13%\n",
      "Error #369\n",
      "Error #370\n",
      "Error #371\n",
      "Error #372\n",
      "75.43%\n",
      "Error #373\n",
      "75.74%\n",
      "76.05%\n",
      "Error #374\n",
      "Error #375\n",
      "76.35%\n",
      "Error #376\n",
      "Error #377\n",
      "76.66%\n",
      "Error #378\n",
      "76.97%\n",
      "Error #379\n",
      "77.27%\n",
      "Error #380\n",
      "77.58%\n",
      "Error #381\n",
      "Error #382\n",
      "Error #383\n",
      "Error #384\n",
      "77.89%\n",
      "78.19%\n",
      "78.50%\n",
      "78.81%\n",
      "Error #385\n",
      "79.11%\n",
      "79.42%\n",
      "79.73%\n",
      "80.03%\n",
      "80.34%\n",
      "Error #386\n",
      "80.65%\n",
      "80.95%\n",
      "81.26%\n",
      "Error #387\n",
      "Error #388\n",
      "81.57%\n",
      "Error #389\n",
      "81.87%\n",
      "Error #390\n",
      "82.18%\n",
      "82.48%\n",
      "82.79%\n",
      "Error #391\n",
      "Error #392\n",
      "83.10%\n",
      "Error #393\n",
      "Error #394\n",
      "Error #395\n",
      "Error #396\n",
      "Error #397\n",
      "83.40%\n",
      "Error #398\n",
      "83.71%\n",
      "84.02%\n",
      "Error #399\n",
      "Error #400\n",
      "84.32%\n",
      "84.63%\n",
      "Error #401\n",
      "84.94%\n",
      "Error #402\n",
      "Error #403\n",
      "Error #404\n",
      "85.24%\n",
      "85.55%\n",
      "Error #405\n",
      "85.86%\n",
      "86.16%\n",
      "Error #406\n",
      "86.47%\n",
      "86.78%\n",
      "87.08%\n",
      "87.39%\n",
      "Error #407\n",
      "Error #408\n",
      "87.70%\n",
      "Error #409\n",
      "Error #410\n",
      "88.00%\n",
      "Error #411\n",
      "88.31%\n",
      "Error #412\n",
      "Error #413\n",
      "88.62%\n",
      "88.92%\n",
      "Error #414\n",
      "Error #415\n",
      "Error #416\n",
      "89.23%\n",
      "Error #417\n",
      "89.54%\n",
      "89.84%\n",
      "90.15%\n",
      "90.46%\n",
      "Error #418\n",
      "Error #419\n",
      "90.76%\n",
      "91.07%\n",
      "91.38%\n",
      "Error #420\n",
      "Error #421\n",
      "Error #422\n",
      "91.68%\n",
      "91.99%\n",
      "Error #423\n",
      "Error #424\n",
      "92.30%\n",
      "92.60%\n",
      "Error #425\n",
      "92.91%\n",
      "Error #426\n",
      "Error #427\n",
      "93.22%\n",
      "93.52%\n",
      "Error #428\n",
      "93.83%\n",
      "Error #429\n",
      "Error #430\n",
      "Error #431\n",
      "Error #432\n",
      "Error #433\n",
      "94.14%\n",
      "Error #434\n",
      "Error #435\n",
      "94.44%\n",
      "Error #436\n",
      "Error #437\n",
      "Error #438\n",
      "Error #439\n",
      "94.75%\n",
      "Error #440\n",
      "Error #441\n",
      "95.06%\n",
      "Error #442\n",
      "95.36%\n",
      "Error #443\n",
      "Error #444\n",
      "Error #445\n",
      "Error #446\n",
      "95.67%\n",
      "95.98%\n",
      "Error #447\n",
      "Error #448\n",
      "Error #449\n",
      "Error #450\n",
      "96.28%\n",
      "96.59%\n",
      "Error #451\n",
      "Error #452\n",
      "96.90%\n",
      "Error #453\n",
      "97.20%\n",
      "97.51%\n",
      "Error #454\n",
      "Error #455\n",
      "Error #456\n",
      "97.82%\n",
      "Error #457\n",
      "98.12%\n",
      "Error #458\n",
      "98.43%\n",
      "Error #459\n",
      "98.74%\n",
      "Error #460\n",
      "Error #461\n",
      "Error #462\n",
      "Error #463\n",
      "99.04%\n",
      "Error #464\n",
      "Error #465\n",
      "Error #466\n",
      "Error #467\n",
      "99.35%\n",
      "99.66%\n",
      "99.96%\n",
      "Number of training examples: 57499\n"
     ]
    }
   ],
   "source": [
    "feature_sets = prepare_train_data(examples, ling_data_cache, feature_model)\n",
    "\n",
    "data_for_pandas = []\n",
    "for example in feature_sets:\n",
    "    data_for_pandas_ex = {}\n",
    "    data_for_pandas_ex['role'] = example[1]\n",
    "    data_for_pandas_ex['ex_id'] = example[2]\n",
    "    data_for_pandas_ex['arg_address'] = example[3]\n",
    "    for elem in example[0]:\n",
    "        for subelem in elem:\n",
    "            if subelem is not None:\n",
    "                data_for_pandas_ex.update(subelem)\n",
    "    \n",
    "    data_for_pandas.append(data_for_pandas_ex)\n",
    "    \n",
    "pd_data = pd.DataFrame(data_for_pandas)\n",
    "pd_data = pd_data.sample(frac=1)\n",
    "pd_data[:10]\n",
    "del data_for_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:28.046180",
     "start_time": "2017-02-18T12:16:27.932519"
    }
   },
   "outputs": [],
   "source": [
    "y_stat = pd_data.loc[:, 'role'].value_counts()\n",
    "drop_ys = y_stat[y_stat < 180].index\n",
    "clear_data = pd_data.drop(pd_data[pd_data.loc[:, 'role'].isin(drop_ys)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:28.523645",
     "start_time": "2017-02-18T12:16:28.047978"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of roles:  44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "агенс                                 6142\n",
       "пациенс                               5357\n",
       "тема                                  3649\n",
       "субъект психологического состояния    3249\n",
       "субъект перемещения                   3008\n",
       "причина                               2501\n",
       "говорящий                             2356\n",
       "место                                 2183\n",
       "содержание действия                   1873\n",
       "содержание мысли                      1817\n",
       "содержание высказывания               1789\n",
       "конечная точка                        1772\n",
       "результат                             1451\n",
       "пациенс перемещения                   1355\n",
       "стимул                                1271\n",
       "субъект ментального состояния         1223\n",
       "адресат                                940\n",
       "субъект восприятия                     901\n",
       "контрагент                             829\n",
       "эффектор                               738\n",
       "субъект социального отношения          598\n",
       "начальная точка                        588\n",
       "предмет высказывания                   547\n",
       "способ                                 530\n",
       "конечный посессор                      505\n",
       "цель                                   454\n",
       "сфера                                  375\n",
       "признак                                366\n",
       "источник звука                         359\n",
       "субъект поведения                      339\n",
       "ситуация в фокусе                      322\n",
       "контрагент социального отношения       318\n",
       "субъект физиологической реакции        310\n",
       "предмет мысли                          302\n",
       "потенциальный пациенс                  290\n",
       "статус                                 265\n",
       "пациенс социального отношения          260\n",
       "эталон                                 255\n",
       "срок                                   255\n",
       "признак действия                       243\n",
       "каузатор                               223\n",
       "исходный посессор                      216\n",
       "потенциальная угроза                   197\n",
       "траектория                             180\n",
       "Name: role, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl_roles = {\n",
    "    'агенс - субъект восприятия' : 'субъект восприятия',\n",
    "    'агенс - субъект ментального состояния' : 'субъект ментального состояния',\n",
    "    'результат / цель' : 'результат',\n",
    "    'место - пациенс' : 'место',\n",
    "    'говорящий - субъект психологического состояния' : 'субъект психологического состояния'\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_single_region(data, rep, val):\n",
    "    data.loc[:, 'role'] = data.loc[:, 'role'].str.replace(rep, val)\n",
    "\n",
    "\n",
    "for rep, val in repl_roles.items():\n",
    "    normalize_single_region(clear_data, rep, val)\n",
    "    \n",
    "number_of_roles = len(clear_data.loc[:, 'role'].value_counts().index)\n",
    "print('Number of roles: ', number_of_roles)\n",
    "clear_data.loc[:, 'role'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:28.578144",
     "start_time": "2017-02-18T12:16:28.525204"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52701, 18)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_orig = clear_data.loc[:, 'role']\n",
    "X_orig = clear_data.drop('role', axis = 1)\n",
    "X_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:29.690583",
     "start_time": "2017-02-18T12:16:28.580765"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pickle\n",
    "\n",
    "label_encoder = LabelBinarizer()\n",
    "y = label_encoder.fit_transform(y_orig)\n",
    "\n",
    "with open(main_model_path + '/label_encoder.pckl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:36.643690",
     "start_time": "2017-02-18T12:16:29.701186"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size:  300\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "embeddings_path = '/notebook/data/embeddings/ruscorpora_upos_skipgram_300_5_2018.vec'\n",
    "embeddings = KeyedVectors.load_word2vec_format(embeddings_path, binary=False)\n",
    "print('Embedding size: ', embeddings.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:16:36.671658",
     "start_time": "2017-02-18T12:16:36.645470"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def make_embeded_form(word):\n",
    "    if word:\n",
    "        #return word[1].encode('utf8')\n",
    "        return u\"{}_{}\".format(word[1], word[0])\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "\n",
    "class Embedder_map:\n",
    "    def __init__(self, embeddings, X):\n",
    "        self.X_ = X\n",
    "        self.embeddings_ = embeddings\n",
    "\n",
    "    def __call__(self, i):  \n",
    "        result = np.zeros((len(self.X_[0]), \n",
    "                           self.embeddings_.vector_size))\n",
    "\n",
    "        for j in range(len(self.X_[0])):\n",
    "            word = self.X_[i][j]\n",
    "            tag = word[0] if word else str()\n",
    "            \n",
    "            if tag == ARG_SPECIAL_TAG or tag == ARG_SPECIAL_TAG:\n",
    "                result[j, :] = np.ones(self.embeddings_.vector_size)\n",
    "            elif word and word in embeddings:\n",
    "                result[j, :] = self.embeddings_[word]\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def embed(X):\n",
    "    pool = mp.Pool(4)\n",
    "    result = pool.map(Embedder_map(embeddings, X), X.index, 1000)\n",
    "    pool.close()\n",
    "    return np.asarray(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:18:10.418972",
     "start_time": "2017-02-18T12:16:36.673158"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#arg_context_embedded = embed(X_orig.loc[:, 'arg_context_lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:33.028839",
     "start_time": "2017-02-18T12:18:10.420741"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#pred_context_embedded = embed(X_orig.loc[:, 'pred_context_lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:33.045522",
     "start_time": "2017-02-18T12:22:33.030953"
    }
   },
   "outputs": [],
   "source": [
    "class Embedder_single_map:\n",
    "    def __init__(self, embeddings, X):\n",
    "        self.X_ = X\n",
    "        self.embeddings_ = embeddings\n",
    "\n",
    "    def __call__(self, i):\n",
    "        #word = make_embeded_form(self.X_[i])\n",
    "        word = self.X_[i]\n",
    "        if word in self.embeddings_:\n",
    "            return self.embeddings_[word]\n",
    "        else:\n",
    "            return np.zeros((self.embeddings_.vector_size,))\n",
    "\n",
    "        \n",
    "def embed_single(embeddings, X):\n",
    "    pool = mp.Pool(4)\n",
    "    result = pool.map(Embedder_single_map(embeddings, X), X.index, 1000)\n",
    "    pool.close()\n",
    "        \n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:40.521526",
     "start_time": "2017-02-18T12:22:33.047988"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52701, 300)\n",
      "609\n",
      "(65,)\n",
      "CPU times: user 28.1 s, sys: 14.7 s, total: 42.8 s\n",
      "Wall time: 48.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# embedded_verbs = embed_single(pd.Series(list(zip(X_orig.pred_pos, X_orig.pred_lemma)), \n",
    "#                                         index = X_orig.index))\n",
    "embedded_verbs = embed_single(embeddings, X_orig.pred_lemma)\n",
    "print(embedded_verbs.shape)\n",
    "print((np.linalg.norm(embedded_verbs, axis = 1) < 0.001).sum())\n",
    "print(clear_data[(np.linalg.norm(embedded_verbs, axis = 1) < 0.001)].pred_lemma.value_counts().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:48.662074",
     "start_time": "2017-02-18T12:22:40.817873"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52701, 300)\n",
      "19029\n",
      "CPU times: user 28 s, sys: 14.8 s, total: 42.9 s\n",
      "Wall time: 48.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# embedded_args = embed_single(pd.Series(list(zip(X_orig.arg_pos, X_orig.arg_lemma)), \n",
    "#                                        index = X_orig.index))\n",
    "embedded_args = embed_single(embeddings, X_orig.arg_lemma)\n",
    "print(embedded_args.shape)\n",
    "print((np.linalg.norm(embedded_args, axis = 1) < 0.001).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing categorial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Animacy_arg', 'Aspect_arg', 'Gender_arg', 'Number_arg', 'Tense_arg',\n",
       "       'Valency_arg', 'VerbForm_arg', 'arg_address', 'arg_case', 'arg_lemma',\n",
       "       'arg_pos', 'dist', 'ex_id', 'pred_lemma', 'pred_pos', 'prepos',\n",
       "       'rel_pos', 'syn_link_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_orig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:52.653831",
     "start_time": "2017-02-18T12:22:48.759036"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category features:\n",
      " ['Animacy_arg', 'Aspect_arg', 'Gender_arg', 'Number_arg', 'Tense_arg', 'Valency_arg', 'VerbForm_arg', 'arg_case', 'arg_pos', 'dist', 'pred_lemma', 'pred_pos', 'prepos', 'syn_link_name']\n",
      "Not category features:\n",
      " ['rel_pos']\n",
      "(52701, 989)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "#morph_feats = ['pos', 'case', 'anim', 'vform', 'zform', 'shform', 'pform', 'vvform', 'nform', 'time']\n",
    "\n",
    "# all_feats = (['pred_lemma', 'rel_pos'] + \n",
    "#              ['arg_' + e for e in morph_feats] + \n",
    "#              ['pred_' + e for e in morph_feats])\n",
    "\n",
    "# all_feats = (['pred_lemma', 'rel_pos', 'arg_prep'] + \n",
    "#              ['arg_' + e for e in morph_feats] + \n",
    "#              ['pred_' + e for e in morph_feats])\n",
    "\n",
    "# all_feats = (['pred_lemma', 'rel_pos', 'arg_prep', 'link_name'] + \n",
    "#              ['arg_' + e for e in morph_feats] + \n",
    "#              ['pred_' + e for e in morph_feats])\n",
    "\n",
    "#all_feats = ['pred_lemma', 'rel_pos', 'pred_pos', 'arg_case', 'syn_link_name', 'arg_pos', 'prepos', 'dist']\n",
    "\n",
    "#categ_feats = [e for e in all_feats if X_orig[e].dtype in [str, object]]\n",
    "#not_categ = [e for e in all_feats if e not in categ_feats]\n",
    "\n",
    "#pred_lemma_vectorizer.fit_transform(X_orig.loc[:, ['pred_lemma']].to_dict(orient = 'records'))\n",
    "\n",
    "not_categ_features = {'arg_address', 'ex_id', 'rel_pos', 'arg_lemma'}\n",
    "categ_feats = [name for name in X_orig.columns if name not in not_categ_features] \n",
    "not_categ = ['rel_pos']\n",
    "print('Category features:\\n', categ_feats)\n",
    "print('Not category features:\\n', not_categ)\n",
    "\n",
    "vectorizer = DictVectorizer(sparse = False)\n",
    "one_hot_feats = vectorizer.fit_transform(X_orig.loc[:, categ_feats].to_dict(orient = 'records'))\n",
    "print(one_hot_feats.shape)\n",
    "\n",
    "with open(main_model_path + '/feature_encoder.pckl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:52.924596",
     "start_time": "2017-02-18T12:22:52.655580"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.4/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(52701, 990)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_categ_columns = np.concatenate(tuple(X_orig.loc[:, e].as_matrix().reshape(-1, 1) for e in not_categ), axis =1)\n",
    "plain_features = np.concatenate((one_hot_feats, not_categ_columns), axis = 1)\n",
    "plain_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:52.938339",
     "start_time": "2017-02-18T12:22:52.926218"
    }
   },
   "outputs": [],
   "source": [
    "del not_categ_columns\n",
    "del one_hot_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, LSTM, Convolution1D, Dropout, MaxPooling1D\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.layers import TimeDistributed\n",
    "from tensorflow.python.keras.layers import Activation\n",
    "from tensorflow.python.keras.layers import RepeatVector\n",
    "from tensorflow.python.keras.layers import Permute\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.layers import Concatenate\n",
    "from tensorflow.python.keras.layers import Bidirectional\n",
    "from tensorflow.python.keras.layers import Masking\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:59.798574",
     "start_time": "2017-02-18T12:22:59.779209"
    }
   },
   "outputs": [],
   "source": [
    "def construct_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(nb_filter=128, \n",
    "                            filter_length=2, \n",
    "                            border_mode='same', \n",
    "                            activation='relu', \n",
    "                            input_shape = (seq_embeded.shape[1], \n",
    "                                           get_embeddings_length(embeddings))))\n",
    "\n",
    "    #model.add(MaxPooling1D(pool_length=2))\n",
    "    model.add(LSTM(80))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(60, activation='tanh'))\n",
    "    model.add(Dense(number_of_roles, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:59.838778",
     "start_time": "2017-02-18T12:22:59.800378"
    }
   },
   "outputs": [],
   "source": [
    "def construct_simple_attentional_model():\n",
    "    units = 80\n",
    "    _input = Input(shape = (arg_context_embedded.shape[1], \n",
    "                            get_embeddings_length(embeddings)), dtype = 'float')\n",
    "\n",
    "    conv = Convolution1D(nb_filter=128, \n",
    "                        filter_length=2, \n",
    "                        border_mode='same', \n",
    "                        activation='relu')(_input)\n",
    "\n",
    "    activations = LSTM(units, return_sequences=True)(conv)\n",
    "\n",
    "    # compute importance for each step\n",
    "    attention = TimeDistributed(Dense(1, activation='tanh'))(activations) \n",
    "    #attention = Dense(6, activation='tanh')(activations) \n",
    "    attention = Flatten()(attention)\n",
    "    attention = Activation('softmax')(attention)\n",
    "    attention = RepeatVector(units)(attention)\n",
    "    attention = Permute([2, 1])(attention)\n",
    "\n",
    "    # apply the attention\n",
    "    sent_representation = merge([activations, attention], mode='mul')\n",
    "    sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n",
    "\n",
    "    #dn = Dense(100, activation = 'tanh')(sent_representation)\n",
    "    #probabilities = Dense(number_of_roles, activation='softmax')(dn)\n",
    "    probabilities = Dense(number_of_roles, activation='softmax')(sent_representation)\n",
    "\n",
    "    model = Model(input=_input, output=probabilities)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:59.886182",
     "start_time": "2017-02-18T12:22:59.840571"
    }
   },
   "outputs": [],
   "source": [
    "def construct_graph_bidirectional_model():\n",
    "    print('Bidirectional model.')\n",
    "    \n",
    "    arg_context_model = Sequential()\n",
    "    arg_context_model.add(Convolution1D(nb_filter=150, \n",
    "                                        filter_length=2, \n",
    "                                        border_mode='same', \n",
    "                                        activation='relu',\n",
    "                                        input_shape = (arg_context_embedded.shape[1], \n",
    "                                                       get_embeddings_length(embeddings))))\n",
    "    arg_context_model.add(Bidirectional(LSTM(100), merge_mode = 'sum'))\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    plain_model = Sequential()\n",
    "    plain_model.add(Dense(700, \n",
    "                          input_shape=(plain_features.shape[1],), \n",
    "                          activation = 'relu'))\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    final = Sequential()\n",
    "    final.add(Merge([arg_context_model, plain_model], mode = 'concat', concat_axis=1))\n",
    "    final.add(Dropout(0.3))\n",
    "    \n",
    "    #final.add(Dense(300, activation = 'relu'))\n",
    "    final.add(Dense(300))\n",
    "    final.add(BatchNormalization())\n",
    "    final.add(Activation('relu'))\n",
    "    final.add(Dropout(0.3))\n",
    "    \n",
    "    final.add(Dense(number_of_roles))\n",
    "    final.add(BatchNormalization())\n",
    "    final.add(Activation('softmax'))\n",
    "    \n",
    "    final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:22:59.952522",
     "start_time": "2017-02-18T12:22:59.887939"
    }
   },
   "outputs": [],
   "source": [
    "def construct_graph_attentional_model():\n",
    "    print('Context attentional model.')\n",
    "    \n",
    "    def construct_attentional_part(context_length):\n",
    "        _input = Input(shape = (context_length, \n",
    "                                get_embeddings_length(embeddings)), dtype = 'float')\n",
    "\n",
    "        conv = Convolution1D(nb_filter=200, \n",
    "                            filter_length=2, \n",
    "                            border_mode='same', \n",
    "                            activation='relu')(_input)\n",
    "\n",
    "        units = 100\n",
    "        activations = LSTM(units, return_sequences=True)(conv)\n",
    "\n",
    "        # compute importance for each step\n",
    "        attention = TimeDistributed(Dense(1, activation='tanh'))(activations)  \n",
    "        attention = Flatten()(attention)\n",
    "        attention = Activation('softmax')(attention)\n",
    "        attention = RepeatVector(units)(attention)\n",
    "        attention = Permute([2, 1])(attention)\n",
    "\n",
    "        # apply the attention\n",
    "        seq_repr = merge([activations, attention], mode='mul')\n",
    "        seq_repr = Lambda(lambda xin: K.sum(xin, axis=1))(seq_repr)\n",
    "        seq_model = Model(input=_input, output=seq_repr)\n",
    "        \n",
    "        return seq_model\n",
    "    \n",
    "    arg_context_model = construct_attentional_part(arg_context_embedded.shape[1])\n",
    "    pred_context_model = construct_attentional_part(pred_context_embedded.shape[1])\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    plain_model = Sequential()\n",
    "    plain_model.add(Dense(800, \n",
    "                          input_shape=(plain_features.shape[1],), \n",
    "                          activation = 'relu'))\n",
    "    \n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    final = Sequential()\n",
    "    final.add(Merge([arg_context_model, pred_context_model, plain_model], \n",
    "                    mode = 'concat', concat_axis=1))\n",
    "    final.add(Dropout(0.3))\n",
    "    \n",
    "    #final.add(Dense(300, activation = 'relu'))\n",
    "    final.add(Dense(400))\n",
    "    final.add(BatchNormalization())\n",
    "    final.add(Activation('relu'))\n",
    "    final.add(Dropout(0.3))\n",
    "    \n",
    "    final.add(Dense(number_of_roles))\n",
    "    final.add(BatchNormalization())\n",
    "    final.add(Activation('softmax'))\n",
    "    #final.add(Dense(number_of_roles, activation = 'softmax'))\n",
    "#    final.add(BatchNormalization())\n",
    "    #final.add(Activation('softmax'), W_regularizer=l2(0.01))\n",
    "    #final.add(Dense(number_of_roles, activation='softmax', W_regularizer = l2(0.01)))\n",
    "    \n",
    "    final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:23:00.015195",
     "start_time": "2017-02-18T12:22:59.954295"
    }
   },
   "outputs": [],
   "source": [
    "def construct_graph_lstm_model(plain_features_shape):\n",
    "    print('Context model.')\n",
    "    \n",
    "    def create_embed_model():\n",
    "        embed_model = Sequential()\n",
    "        embed_model.add(Dense(100, input_shape = (get_embeddings_length(embeddings), )))\n",
    "        embed_model.add(BatchNormalization())\n",
    "        embed_model.add(Activation('relu'))\n",
    "        return embed_model\n",
    "    \n",
    "    def construct_attentional_part(context_length):\n",
    "        seq_model = Sequential()\n",
    "        seq_model.add(Convolution1D(nb_filter=50, \n",
    "                                    filter_length=1, \n",
    "                                    border_mode='same', \n",
    "                                    activation='relu',\n",
    "                                    input_shape = (context_length, \n",
    "                                                   get_embeddings_length(embeddings))))\n",
    "#         seq_model.add(Masking(mask_value=0., input_shape = (context_length, \n",
    "#                                                             get_embeddings_length(embeddings))))\n",
    "        #seq_model.add(Masking(mask_value=1.))\n",
    "        seq_model.add(Bidirectional(LSTM(50), merge_mode='sum'))\n",
    "        #seq_model.add(LSTM(100))\n",
    "        seq_model.add(Dense(50))\n",
    "        seq_model.add(BatchNormalization())\n",
    "        seq_model.add(Activation('relu'))\n",
    "        \n",
    "        return seq_model\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    #arg_context_model = construct_attentional_part(arg_context_embedded.shape[1])\n",
    "    pred_context_model = construct_attentional_part(pred_context_embedded.shape[1])\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    plain_model = Sequential()\n",
    "    plain_model.add(Dense(400, input_shape = plain_features_shape))\n",
    "    plain_model.add(BatchNormalization())\n",
    "    plain_model.add(Activation('relu'))\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    arg_embed_model = create_embed_model()\n",
    "    pred_embed_model = create_embed_model()\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    final1 = Sequential()\n",
    "    final1.add(Merge([\n",
    "  #              arg_context_model, \n",
    "                     #pred_context_model,\n",
    "                     arg_embed_model,\n",
    "                     pred_embed_model,\n",
    "                     plain_model], \n",
    "                    mode = 'concat', concat_axis=1))\n",
    "    final1.add(Dropout(0.3))\n",
    "    \n",
    "    final1.add(Dense(400))\n",
    "    final1.add(BatchNormalization())\n",
    "    final1.add(Activation('relu'))\n",
    "    final1.add(Dropout(0.3))\n",
    "    \n",
    "    final = Sequential()\n",
    "    final.add(Merge([final1, pred_context_model], mode = 'concat', concat_axis = 1))\n",
    "    \n",
    "    final.add(Dense(number_of_roles))\n",
    "    final.add(BatchNormalization())\n",
    "    final.add(Activation('softmax'))\n",
    "    \n",
    "    final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:23:00.054095",
     "start_time": "2017-02-18T12:23:00.016955"
    }
   },
   "outputs": [],
   "source": [
    "def construct_plain_model(input_shape):\n",
    "    print('Plain model.')\n",
    "    \n",
    "    plain_model = Sequential()\n",
    "    plain_model.add(Dense(600, \n",
    "                          #input_shape=(plain_features.shape[1],), \n",
    "                          input_shape = input_shape,\n",
    "                          activation = 'relu'))\n",
    "    plain_model.add(Dropout(0.3))\n",
    "    \n",
    "    plain_model.add(Dense(400))\n",
    "    plain_model.add(BatchNormalization())\n",
    "    plain_model.add(Activation('relu'))\n",
    "    plain_model.add(Dropout(0.3))\n",
    "    \n",
    "    plain_model.add(Dense(number_of_roles))\n",
    "    plain_model.add(BatchNormalization())\n",
    "    plain_model.add(Activation('softmax'))\n",
    "    \n",
    "    plain_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return plain_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:23:00.102016",
     "start_time": "2017-02-18T12:23:00.055842"
    }
   },
   "outputs": [],
   "source": [
    "def construct_plain_model_sparse(categ_size, emb_size, number_of_roles):    \n",
    "    input_plain = Input(shape=(categ_size,), name = 'input_categorical')\n",
    "    input_pred_embed = Input(shape=(emb_size,), name = 'pred_embed')\n",
    "    input_arg_embed = Input(shape=(emb_size,), name = 'arg_embed')\n",
    "    \n",
    "    plain = Dense(400)(input_plain)\n",
    "    plain = BatchNormalization()(plain)\n",
    "    plain = Activation('relu')(plain)\n",
    "    \n",
    "    def embed_submodel(inpt):\n",
    "        embed = Dense(100)(inpt)\n",
    "        embed = BatchNormalization()(embed)\n",
    "        embed = Activation('relu')(embed)\n",
    "        return embed\n",
    "    \n",
    "    embed_pred = embed_submodel(input_pred_embed)\n",
    "    embed_arg = embed_submodel(input_arg_embed)\n",
    "    \n",
    "    final = Concatenate(axis = 1)([embed_pred, embed_arg, plain])\n",
    "    final = Dropout(0.3)(final)\n",
    "    final = Dense(400)(final)\n",
    "    final = BatchNormalization()(final)\n",
    "    final = Activation('relu')(final)\n",
    "    final = Dropout(0.3)(final)\n",
    "    final = Dense(number_of_roles)(final)\n",
    "    final = BatchNormalization()(final)\n",
    "    final = Activation('softmax')(final)\n",
    "    \n",
    "    model = Model([input_arg_embed, input_pred_embed, input_plain], final)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with in-domain test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only for experiments with in-domain test. Do not use for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-15T10:45:48.365172",
     "start_time": "2017-02-15T10:45:04.358434"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 600)               594600    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 400)               1600      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 44)                17644     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 44)                176       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 44)                0         \n",
      "=================================================================\n",
      "Total params: 854,420\n",
      "Trainable params: 853,532\n",
      "Non-trainable params: 888\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 47430 samples, validate on 5271 samples\n",
      "Epoch 1/15\n",
      "47430/47430 [==============================] - 3s 71us/step - loss: 2.5622 - acc: 0.4084 - val_loss: 3.1365 - val_acc: 0.5185\n",
      "Epoch 2/15\n",
      "47430/47430 [==============================] - 2s 35us/step - loss: 1.3056 - acc: 0.7328 - val_loss: 2.3115 - val_acc: 0.7336\n",
      "Epoch 3/15\n",
      "47430/47430 [==============================] - 2s 35us/step - loss: 1.0168 - acc: 0.7721 - val_loss: 1.3678 - val_acc: 0.7665\n",
      "Epoch 4/15\n",
      "47430/47430 [==============================] - 2s 35us/step - loss: 0.8849 - acc: 0.7865 - val_loss: 0.9385 - val_acc: 0.7773\n",
      "Epoch 5/15\n",
      "47430/47430 [==============================] - 2s 35us/step - loss: 0.7945 - acc: 0.8009 - val_loss: 0.8247 - val_acc: 0.7771\n",
      "Epoch 6/15\n",
      "47430/47430 [==============================] - 2s 35us/step - loss: 0.7310 - acc: 0.8075 - val_loss: 0.8066 - val_acc: 0.7849\n",
      "Epoch 7/15\n",
      "47430/47430 [==============================] - 2s 35us/step - loss: 0.6820 - acc: 0.8171 - val_loss: 0.7754 - val_acc: 0.7877\n",
      "Epoch 8/15\n",
      "47430/47430 [==============================] - 2s 35us/step - loss: 0.6429 - acc: 0.8229 - val_loss: 0.7520 - val_acc: 0.7847\n",
      "Epoch 9/15\n",
      "47430/47430 [==============================] - 2s 36us/step - loss: 0.6124 - acc: 0.8263 - val_loss: 0.7591 - val_acc: 0.7841\n",
      "Epoch 10/15\n",
      "47430/47430 [==============================] - 2s 34us/step - loss: 0.5788 - acc: 0.8332 - val_loss: 0.7537 - val_acc: 0.7862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f12d77d4390>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = construct_plain_model((plain_features.shape[1],))\n",
    "print(model.summary())\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit(plain_features, y, epochs=15, batch_size=300, validation_split = 0.1, \n",
    "          shuffle=True, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-16T10:49:20.090543",
     "start_time": "2017-02-16T10:49:19.585615"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47430 samples, validate on 5271 samples\n",
      "Epoch 1/16\n",
      "47430/47430 [==============================] - 5s 104us/step - loss: 2.2671 - acc: 0.5028 - val_loss: 2.8854 - val_acc: 0.6137\n",
      "Epoch 2/16\n",
      "47430/47430 [==============================] - 3s 56us/step - loss: 1.2952 - acc: 0.7335 - val_loss: 1.8836 - val_acc: 0.7393\n",
      "Epoch 3/16\n",
      "47430/47430 [==============================] - 3s 56us/step - loss: 1.0198 - acc: 0.7741 - val_loss: 1.1514 - val_acc: 0.7737\n",
      "Epoch 4/16\n",
      "47430/47430 [==============================] - 3s 54us/step - loss: 0.8779 - acc: 0.7930 - val_loss: 0.8753 - val_acc: 0.7898\n",
      "Epoch 5/16\n",
      "47430/47430 [==============================] - 3s 56us/step - loss: 0.7870 - acc: 0.8046 - val_loss: 0.7914 - val_acc: 0.7923\n",
      "Epoch 6/16\n",
      "47430/47430 [==============================] - 3s 55us/step - loss: 0.7176 - acc: 0.8146 - val_loss: 0.7401 - val_acc: 0.7989\n",
      "Epoch 7/16\n",
      "47430/47430 [==============================] - 3s 56us/step - loss: 0.6633 - acc: 0.8249 - val_loss: 0.7204 - val_acc: 0.8052\n",
      "Epoch 8/16\n",
      "47430/47430 [==============================] - 3s 55us/step - loss: 0.6211 - acc: 0.8297 - val_loss: 0.7050 - val_acc: 0.7997\n",
      "Epoch 9/16\n",
      "47430/47430 [==============================] - 3s 56us/step - loss: 0.5851 - acc: 0.8384 - val_loss: 0.6933 - val_acc: 0.8038\n",
      "Epoch 10/16\n",
      "47430/47430 [==============================] - 3s 56us/step - loss: 0.5507 - acc: 0.8464 - val_loss: 0.6885 - val_acc: 0.8065\n",
      "Epoch 11/16\n",
      "47430/47430 [==============================] - 3s 56us/step - loss: 0.5220 - acc: 0.8509 - val_loss: 0.6731 - val_acc: 0.8097\n",
      "Epoch 12/16\n",
      "47430/47430 [==============================] - 3s 56us/step - loss: 0.4949 - acc: 0.8551 - val_loss: 0.6720 - val_acc: 0.8088\n",
      "Epoch 13/16\n",
      "47430/47430 [==============================] - 3s 55us/step - loss: 0.4811 - acc: 0.8570 - val_loss: 0.6727 - val_acc: 0.8074\n",
      "Epoch 14/16\n",
      "47430/47430 [==============================] - 3s 55us/step - loss: 0.4556 - acc: 0.8657 - val_loss: 0.6743 - val_acc: 0.8059\n"
     ]
    }
   ],
   "source": [
    "model = construct_plain_model_sparse(plain_features.shape[1], embeddings.vector_size, y.shape[1])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit([embedded_args, embedded_verbs, plain_features], y, epochs=16, batch_size=300, \n",
    "          validation_split = 0.1, shuffle=True, callbacks = [early_stopping])\n",
    "model.save(os.path.join(main_model_path, 'neural_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-15T23:18:09.873456",
     "start_time": "2017-02-15T23:07:16.496170"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = construct_graph_lstm_model((plain_features.shape[1],))\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit([arg_context_embedded, pred_context_embedded, embedded_args, embedded_verbs, plain_features], y, \n",
    "          epochs=15, batch_size=64, validation_split = 0.1, \n",
    "          shuffle=True, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiements with out-of-domain test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only for out of domain experiments. Do not use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T14:21:13.954628",
     "start_time": "2017-02-17T14:21:13.936038"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_out_of_domain(model, X_train, y_train, X_test, y_test):\n",
    "    final_res = list()\n",
    "    N_ITERATIONS = 5\n",
    "    for i in xrange(N_ITERATIONS):\n",
    "        print('Eval iter:', i + 1, '/', N_ITERATIONS)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, \n",
    "                                       patience=2, verbose=0, mode='auto')\n",
    "        model.fit(X_train, y_train, nb_epoch=15, \n",
    "                  batch_size=64, validation_split = 0.1, \n",
    "                  shuffle=True, callbacks = [early_stopping],\n",
    "                 verbose = 0)\n",
    "\n",
    "        ev_res = evaluate_model(model, X_test, y_test)\n",
    "        print()\n",
    "        print(pd.DataFrame([ev_res], columns = ['keras_accur', 'keras_loss', 'f1_micro', 'f1_macro', 'accur']))\n",
    "        final_res.append(ev_res)\n",
    "    \n",
    "    return np.array(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:26:02.646008",
     "start_time": "2017-02-18T12:26:02.630666"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    keras_eval = model.evaluate(X_test, y_test)\n",
    "    pred = model.predict(X_test).argmax(axis = 1)\n",
    "    f1_micro = f1_score(pred, y_test.argmax(axis = 1), average = 'micro')\n",
    "    f1_macro = f1_score(pred, y_test.argmax(axis = 1), average = 'macro')\n",
    "    accur = accuracy_score(pred, y_test.argmax(axis = 1))\n",
    "    \n",
    "    return np.array(list(keras_eval) + [f1_micro, f1_macro, accur])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T10:15:31.636957",
     "start_time": "2017-02-17T10:13:07.614626"
    }
   },
   "outputs": [],
   "source": [
    "model = construct_plain_model((ind_plain_features.shape[1],))\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit(ind_plain_features, ind_y, nb_epoch=15, batch_size=64, validation_split = 0.1, \n",
    "          shuffle=True, callbacks = [early_stopping])\n",
    "\n",
    "#model.evaluate(ood_plain_features, ood_y)\n",
    "ev_res = evaluate_model(model, [ood_plain_features], ood_y)\n",
    "print()\n",
    "print(pd.DataFrame([ev_res], columns = ['keras_accur', 'keras_loss', 'f1_micro', 'f1_macro', 'accur']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T11:32:19.012435",
     "start_time": "2017-02-17T11:26:21.034200"
    }
   },
   "outputs": [],
   "source": [
    "model = construct_plain_model((ind_plain_features.shape[1],))\n",
    "model_eval = evaluate_out_of_domain(model, ind_plain_features, ind_y, ood_plain_features, ood_y)\n",
    "print(model_eval)\n",
    "describe_cv_result(model_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T11:51:12.792397",
     "start_time": "2017-02-17T11:50:35.226172"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = construct_plain_model_sparse((ind_plain_features.shape[1],))\n",
    "model.summary()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit([ind_arg_embed, ind_pred_embed, ind_plain_features], ind_y, nb_epoch=20, batch_size=64, validation_split = 0.1, \n",
    "          shuffle=True, callbacks = [early_stopping])\n",
    "#model.evaluate([ood_arg_embed, ood_pred_embed, ood_plain_features], ood_y)\n",
    "\n",
    "ev_res = evaluate_model(model, [ood_arg_embed, ood_pred_embed, ood_plain_features], ood_y)\n",
    "print()\n",
    "print(pd.DataFrame([ev_res], columns = ['keras_accur', 'keras_loss', 'f1_micro', 'f1_macro', 'accur']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T16:02:37.654028",
     "start_time": "2017-02-17T15:54:39.172343"
    }
   },
   "outputs": [],
   "source": [
    "model = construct_plain_model_sparse((ind_plain_features.shape[1],))\n",
    "model.summary()\n",
    "model_eval = evaluate_out_of_domain(model, \n",
    "                                    [ind_arg_embed, ind_pred_embed, ind_plain_features], ind_y, \n",
    "                                    [ood_arg_embed, ood_pred_embed, ood_plain_features], ood_y)\n",
    "print(model_eval)\n",
    "describe_cv_result(model_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T13:21:40.582402",
     "start_time": "2017-02-17T13:21:21.643939"
    }
   },
   "outputs": [],
   "source": [
    "model = construct_graph_lstm_model((ind_plain_features.shape[1],))\n",
    "model.summary()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit([\n",
    "           #ind_arg_context, \n",
    "        #ind_pred_context,   \n",
    "        ind_arg_embed, \n",
    "        ind_pred_embed, \n",
    "        ind_plain_features,\n",
    "        ind_pred_context], \n",
    "#model.fit([ind_arg_context, ind_pred_context, ind_arg_embed, ind_pred_embed, ind_plain_features], \n",
    "           ind_y, nb_epoch=6, batch_size=64, validation_split = 0.1, \n",
    "          shuffle=True, callbacks = [early_stopping])\n",
    "\n",
    "#model.evaluate([ood_arg_context, ood_pred_context, ood_arg_embed, ood_pred_embed, ood_plain_features], ood_y)\n",
    "model.evaluate([\n",
    "    #    ood_arg_context, \n",
    "    #    ood_pred_context,\n",
    "        ood_arg_embed, \n",
    "        ood_pred_embed,\n",
    "        ood_plain_features,\n",
    "        ood_pred_context\n",
    "    ], ood_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T15:41:36.049234",
     "start_time": "2017-02-17T15:25:34.248413"
    }
   },
   "outputs": [],
   "source": [
    "model = construct_graph_lstm_model((ind_plain_features.shape[1],))\n",
    "model.summary()\n",
    "model_eval = evaluate_out_of_domain(model, \n",
    "                                    [ind_arg_embed, ind_pred_embed, ind_plain_features, ind_pred_context], ind_y, \n",
    "                                    [ood_arg_embed, ood_pred_embed, ood_plain_features, ood_pred_context], ood_y)\n",
    "print(model_eval)\n",
    "describe_cv_result(model_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only for model comparision. Do not use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T11:43:55.066960",
     "start_time": "2017-02-17T11:43:54.950449"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, *args, **kwargs):\n",
    "    model.fit(X_train, y_train, *args, **kwargs)\n",
    "    \n",
    "    keras_eval = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    pred = model.predict(X_test).argmax(axis = 1)\n",
    "    f1_micro = f1_score(pred, y_test.argmax(axis = 1), average = 'micro')\n",
    "    f1_macro = f1_score(pred, y_test.argmax(axis = 1), average = 'macro')\n",
    "    accur = accuracy_score(pred, y_test.argmax(axis = 1))\n",
    "    \n",
    "    return list(keras_eval) + [f1_micro, f1_macro, accur]\n",
    "    \n",
    "\n",
    "def custom_cross_val(cr_f, X, y, cv, *args, **kwargs):\n",
    "    cr_f().summary()\n",
    "    eval_res = list()\n",
    "    for i, (train, test) in enumerate(cv.split(y)):\n",
    "        model = cr_f()\n",
    "        print('Running Fold', i+1, '/', cv.n_splits)\n",
    "        eval1 = train_and_evaluate_model(model, \n",
    "                                         [X[j][train] for j in range(len(X))], y[train], \n",
    "                                         [X[j][test] for j in range(len(X))], y[test], \n",
    "                                         *args, **kwargs)\n",
    "        \n",
    "        print()\n",
    "        print('Fold result: ', eval1)\n",
    "        eval_res.append(eval1)\n",
    "    \n",
    "    return np.array(eval_res)\n",
    "\n",
    "\n",
    "def describe_cv_result(cv_res):\n",
    "    print(cv_res)\n",
    "    mean_cv_res = cv_res.mean(axis = 0)\n",
    "    std_cv_res = cv_res.std(axis = 0)\n",
    "    print('Mean')\n",
    "    print(pd.DataFrame([mean_cv_res], columns = ['loss', 'keras_accur', 'micro_f1', 'macro_f1', 'accur']))\n",
    "    print('Std')\n",
    "    print(pd.DataFrame([std_cv_res], columns = ['loss', 'keras_accur', 'micro_f1', 'macro_f1', 'accur']))\n",
    "    \n",
    "    \n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-16T16:16:18.702196",
     "start_time": "2017-02-16T16:07:42.457676"
    }
   },
   "outputs": [],
   "source": [
    "curr_features = np.concatenate((no_lemma_plain_features, embedded_verbs), axis = 1)\n",
    "cv_res = custom_cross_val(lambda : construct_plain_model((curr_features.shape[1],)), \n",
    "                          [curr_features], \n",
    "                          y, cv = cv, epochs=13, batch_size=64,\n",
    "                          validation_split = 0., shuffle=True, verbose = 0)\n",
    "\n",
    "describe_cv_result(cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-16T15:36:12.375033",
     "start_time": "2017-02-16T15:27:40.793790"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 600)               7200600   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 400)               1600      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 44)                17644     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 44)                176       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 44)                0         \n",
      "=================================================================\n",
      "Total params: 7,460,420\n",
      "Trainable params: 7,459,532\n",
      "Non-trainable params: 888\n",
      "_________________________________________________________________\n",
      "Plain model.\n",
      "Running Fold 1 / 5\n",
      "10541/10541 [==============================] - 1s 141us/step\n",
      "\n",
      "Fold result:  [0.8487707857258484, 0.7890143250222564, 0.7890143250166018, 0.7673059043091115, 0.7890143250166018]\n",
      "Plain model.\n",
      "Running Fold 2 / 5\n",
      "10540/10540 [==============================] - 2s 142us/step\n",
      "\n",
      "Fold result:  [0.8319323760056179, 0.7877609108385596, 0.7877609108159392, 0.7592714001062905, 0.7877609108159392]\n",
      "Plain model.\n",
      "Running Fold 3 / 5\n",
      "10540/10540 [==============================] - 2s 146us/step\n",
      "\n",
      "Fold result:  [0.8737749538905707, 0.7829222011611403, 0.78292220113852, 0.7567430752326177, 0.78292220113852]\n",
      "Plain model.\n",
      "Running Fold 4 / 5\n",
      "10540/10540 [==============================] - 2s 147us/step\n",
      "\n",
      "Fold result:  [0.8426276506237559, 0.7925996204933586, 0.7925996204933585, 0.7536432782969409, 0.7925996204933586]\n",
      "Plain model.\n",
      "Running Fold 5 / 5\n",
      "10540/10540 [==============================] - 2s 149us/step\n",
      "\n",
      "Fold result:  [0.8629502669457466, 0.7827324477952164, 0.7827324478178367, 0.7531360399854179, 0.7827324478178368]\n",
      "[[0.84877079 0.78901433 0.78901433 0.7673059  0.78901433]\n",
      " [0.83193238 0.78776091 0.78776091 0.7592714  0.78776091]\n",
      " [0.87377495 0.7829222  0.7829222  0.75674308 0.7829222 ]\n",
      " [0.84262765 0.79259962 0.79259962 0.75364328 0.79259962]\n",
      " [0.86295027 0.78273245 0.78273245 0.75313604 0.78273245]]\n",
      "Mean\n",
      "       loss  keras_accur  micro_f1  macro_f1     accur\n",
      "0  0.852011     0.787006  0.787006   0.75802  0.787006\n",
      "Std\n",
      "       loss  keras_accur  micro_f1  macro_f1     accur\n",
      "0  0.014799     0.003764  0.003764  0.005147  0.003764\n"
     ]
    }
   ],
   "source": [
    "cv_res = custom_cross_val(lambda : construct_plain_model((plain_features.shape[1],)), \n",
    "                          [plain_features], \n",
    "                          y, cv = cv, epochs=13, batch_size=64,\n",
    "                          validation_split = 0., shuffle=True, verbose = 0)\n",
    "\n",
    "describe_cv_result(cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-16T14:48:33.877302",
     "start_time": "2017-02-16T14:45:18.196997"
    }
   },
   "outputs": [],
   "source": [
    "single_chunk = np.concatenate((embedded_args, embedded_verbs, plain_features), axis = 1)\n",
    "cv_res = custom_cross_val(lambda : construct_plain_model((single_chunk.shape[1],)), \n",
    "                          [single_chunk], \n",
    "                          y, cv = cv, epochs=13, batch_size=64,\n",
    "                          validation_split = 0., shuffle=True, verbose = 0)\n",
    "\n",
    "describe_cv_result(cv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T16:23:57.011641",
     "start_time": "2017-02-17T16:07:49.454278"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "pred_embed (InputLayer)         (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "arg_embed (InputLayer)          (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_categorical (InputLayer)  (None, 990)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 100)          30100       pred_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 100)          30100       arg_embed[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 400)          396400      input_categorical[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 100)          400         dense_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 100)          400         dense_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 400)          1600        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 100)          0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 100)          0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 400)          0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 600)          0           activation_77[0][0]              \n",
      "                                                                 activation_78[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 600)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 400)          240400      dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 400)          1600        dense_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 400)          0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 400)          0           activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 44)           17644       dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 44)           176         dense_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 44)           0           batch_normalization_80[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 718,820\n",
      "Trainable params: 716,732\n",
      "Non-trainable params: 2,088\n",
      "__________________________________________________________________________________________________\n",
      "Running Fold 1 / 5\n",
      "10541/10541 [==============================] - 2s 204us/step\n",
      "\n",
      "Fold result:  [0.6577002111221217, 0.8126363722606963, 0.8126363722606963, 0.7853088545072477, 0.8126363722606963]\n",
      "Running Fold 2 / 5\n",
      "10540/10540 [==============================] - 2s 212us/step\n",
      "\n",
      "Fold result:  [0.6710936888119301, 0.804838709654799, 0.8048387096774193, 0.7726367565472689, 0.8048387096774193]\n",
      "Running Fold 3 / 5\n",
      "10540/10540 [==============================] - 2s 223us/step\n",
      "\n",
      "Fold result:  [0.6850881543229608, 0.8060721062844799, 0.8060721062618595, 0.7772395776418514, 0.8060721062618595]\n",
      "Running Fold 4 / 5\n",
      "10540/10540 [==============================] - 2s 231us/step\n",
      "\n",
      "Fold result:  [0.6682090597767983, 0.8074952561443626, 0.8074952561669829, 0.770870075588247, 0.8074952561669829]\n",
      "Running Fold 5 / 5\n",
      "10540/10540 [==============================] - 3s 237us/step\n",
      "\n",
      "Fold result:  [0.6917032712777154, 0.8018026565238692, 0.8018026565464895, 0.7733449592452944, 0.8018026565464895]\n",
      "[[0.65770021 0.81263637 0.81263637 0.78530885 0.81263637]\n",
      " [0.67109369 0.80483871 0.80483871 0.77263676 0.80483871]\n",
      " [0.68508815 0.80607211 0.80607211 0.77723958 0.80607211]\n",
      " [0.66820906 0.80749526 0.80749526 0.77087008 0.80749526]\n",
      " [0.69170327 0.80180266 0.80180266 0.77334496 0.80180266]]\n",
      "Mean\n",
      "       loss  keras_accur  micro_f1  macro_f1     accur\n",
      "0  0.674759     0.806569  0.806569   0.77588  0.806569\n",
      "Std\n",
      "       loss  keras_accur  micro_f1  macro_f1     accur\n",
      "0  0.012175     0.003567  0.003567  0.005154  0.003567\n"
     ]
    }
   ],
   "source": [
    "cv_res = custom_cross_val(lambda : construct_plain_model_sparse(plain_features.shape[1], \n",
    "                                                                embeddings.vector_size, \n",
    "                                                                y.shape[1]), \n",
    "                          [embedded_args, embedded_verbs, plain_features], y, \n",
    "                          cv = cv, epochs=13, batch_size=300,\n",
    "                          validation_split = 0., shuffle=True, verbose = 0)\n",
    "\n",
    "describe_cv_result(cv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-16T14:16:02.109004",
     "start_time": "2017-02-16T13:49:33.683794"
    }
   },
   "outputs": [],
   "source": [
    "cv_res = custom_cross_val(lambda : construct_graph_lstm_model((plain_features.shape[1],)), \n",
    "                          [arg_context_embedded, \n",
    "                           pred_context_embedded, \n",
    "                           embedded_args, \n",
    "                           embedded_verbs,\n",
    "                           plain_features], y, \n",
    "                          cv = cv, epochs=6, batch_size=64, validation_split = 0., \n",
    "                          shuffle=True)\n",
    "\n",
    "describe_cv_result(cv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T12:59:05.065644",
     "start_time": "2017-02-18T12:59:05.006966"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ids, test_ids = train_test_split(X_orig.ex_id.unique(), test_size=0.2, random_state=42)\n",
    "train_ids = set(train_ids.tolist())\n",
    "test_ids = set(test_ids.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T13:04:58.313461",
     "start_time": "2017-02-18T13:04:58.267195"
    }
   },
   "outputs": [],
   "source": [
    "train_selector_pd = X_orig.ex_id.isin(train_ids)\n",
    "test_selector_pd = X_orig.ex_id.isin(test_ids)\n",
    "train_selector = train_selector_pd.values\n",
    "test_selector = test_selector_pd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T11:29:41.203903",
     "start_time": "2017-02-18T11:28:02.698301"
    }
   },
   "outputs": [],
   "source": [
    "train_data = {k : data[k] for k in train_ids}\n",
    "test_data = {k : data[k] for k in test_ids}\n",
    "\n",
    "with open(os.path.join(main_model_path, 'train_data.json'), 'w') as f:\n",
    "    json.dump(train_data, f)\n",
    "\n",
    "with open(os.path.join(main_model_path, 'test_data.json'), 'w') as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T13:00:50.036868",
     "start_time": "2017-02-18T12:59:10.294248"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37893 samples, validate on 4211 samples\n",
      "Epoch 1/10\n",
      "37893/37893 [==============================] - 11s 290us/step - loss: 1.9349 - acc: 0.5656 - val_loss: 1.1430 - val_acc: 0.7421\n",
      "Epoch 2/10\n",
      "37893/37893 [==============================] - 9s 232us/step - loss: 1.1200 - acc: 0.7305 - val_loss: 0.8598 - val_acc: 0.7727\n",
      "Epoch 3/10\n",
      "37893/37893 [==============================] - 9s 232us/step - loss: 0.9209 - acc: 0.7613 - val_loss: 0.7801 - val_acc: 0.7822\n",
      "Epoch 4/10\n",
      "37893/37893 [==============================] - 9s 231us/step - loss: 0.8213 - acc: 0.7741 - val_loss: 0.7397 - val_acc: 0.7903\n",
      "Epoch 5/10\n",
      "37893/37893 [==============================] - 9s 229us/step - loss: 0.7521 - acc: 0.7903 - val_loss: 0.7198 - val_acc: 0.7948\n",
      "Epoch 6/10\n",
      "37893/37893 [==============================] - 9s 230us/step - loss: 0.7003 - acc: 0.7981 - val_loss: 0.7003 - val_acc: 0.7920\n",
      "Epoch 7/10\n",
      "37893/37893 [==============================] - 9s 231us/step - loss: 0.6519 - acc: 0.8097 - val_loss: 0.6985 - val_acc: 0.8019\n",
      "Epoch 8/10\n",
      "37893/37893 [==============================] - 9s 232us/step - loss: 0.6229 - acc: 0.8151 - val_loss: 0.6913 - val_acc: 0.8024\n",
      "Epoch 9/10\n",
      "37893/37893 [==============================] - 9s 231us/step - loss: 0.5941 - acc: 0.8228 - val_loss: 0.7003 - val_acc: 0.7993\n",
      "Epoch 10/10\n",
      "37893/37893 [==============================] - 9s 230us/step - loss: 0.5611 - acc: 0.8335 - val_loss: 0.6884 - val_acc: 0.8027\n",
      "10597/10597 [==============================] - 1s 102us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6926666886275118, 0.8026800037746532]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_from_nparray_list(nparray_list, selector):\n",
    "    return [e[selector] for e in nparray_list]\n",
    "\n",
    "model = construct_plain_model_sparse(plain_features.shape[1], embeddings.vector_size, y.shape[1])\n",
    "model.fit(select_from_nparray_list([embedded_args, embedded_verbs, plain_features], train_selector),\n",
    "          select_from_nparray_list([y], train_selector), \n",
    "          epochs=10, batch_size=64, validation_split = 0.1, shuffle=True)\n",
    "\n",
    "model.evaluate(select_from_nparray_list([embedded_args, embedded_verbs, plain_features], test_selector), \n",
    "               select_from_nparray_list([y], test_selector))\n",
    "model.save(os.path.join(main_model_path, 'neural_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T15:55:42.486066",
     "start_time": "2017-02-18T15:55:39.780097"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10597/10597 [==============================] - 1s 108us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.69266669, 0.80268   , 0.80268   , 0.77108236, 0.80268   ])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hold-out evaluation.\n",
    "\n",
    "evaluate_model(model,\n",
    "               select_from_nparray_list([embedded_args, embedded_verbs, plain_features], test_selector), \n",
    "               select_from_nparray_list([y], test_selector)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T15:56:50.418354",
     "start_time": "2017-02-18T15:56:40.777599"
    }
   },
   "outputs": [],
   "source": [
    "pred = model.predict(select_from_nparray_list([embedded_args, embedded_verbs, plain_features], test_selector))\n",
    "\n",
    "test_examples_to_store = X_orig.loc[test_selector_pd[test_selector_pd].index, :].loc[:, ['arg_address', 'ex_id']]\n",
    "test_data = {k : data[k] for k in test_ids}\n",
    "\n",
    "\n",
    "for index, (pd_index, row) in enumerate(test_examples_to_store.iterrows()):\n",
    "    ex = test_data[row['ex_id']]\n",
    "    arg_addr = row['arg_address']\n",
    "    sent = ex[arg_addr[0]]\n",
    "    token = sent[arg_addr[1]]\n",
    "    cl = pred[index]\n",
    "    predicted_role = label_encoder.inverse_transform(np.array([cl]))[0]\n",
    "    actual_role = label_encoder.inverse_transform(np.array([select_from_nparray_list([y], test_selector)[0][index]]))[0]\n",
    "    \n",
    "    token['rolepred1'] = actual_role\n",
    "    token['rolepred2'] = predicted_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T15:59:40.060358",
     "start_time": "2017-02-18T15:59:26.421186"
    }
   },
   "outputs": [],
   "source": [
    "with open('./test_data_ann_1.json', 'w') as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brat convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts results to brat annotation for inspecting.\n",
    "# Needs framebank_preprocessing from http://nlp.isa.ru/framebank_parser/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T17:15:09.301844",
     "start_time": "2017-02-18T17:14:58.429103"
    }
   },
   "outputs": [],
   "source": [
    "!python2.7 ./framebank_preprocessing/convert_corpus_to_brat.py --inputFile=./test_data_ann_1.json --outputDir=./brat_ann2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T17:27:49.179234",
     "start_time": "2017-02-18T17:27:30.320938"
    }
   },
   "outputs": [],
   "source": [
    "!python2.7 ./framebank_preprocessing/convert_corpus_to_brat.py --inputFile=./test_data_ann_1.json --outputDir=./syntaxnet_1/ --converter=syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-11 20:56:20 - Loading corpus data...\n",
      "2018-03-11 20:56:22 - Done.\n",
      "2018-03-11 20:56:22 - Creating verb-example index...\n",
      "2018-03-11 20:56:22 - Done.\n",
      "2018-03-11 20:56:22 - Converting and saving...\n",
      "2018-03-11 20:56:23 - Done.\n",
      "2018-03-11 20:56:23 - Generating brat configuration files...\n",
      "2018-03-11 20:56:23 - Done.\n"
     ]
    }
   ],
   "source": [
    "!export PYTHONPATH=../ && python2.7 ./convert_corpus_to_brat.py --inputFile=./test_data_ann_1.json --outputDir=./brat_ann2/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "51px",
    "width": "313px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "505px",
    "left": "0px",
    "right": "1122px",
    "top": "110px",
    "width": "158px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
